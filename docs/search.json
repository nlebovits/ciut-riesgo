[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CIUT Riesgo",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "exposicion.html",
    "href": "exposicion.html",
    "title": "1  Exposición",
    "section": "",
    "text": "1.1 Introducion\nEn este flujo de trabajo aplicamos mapeo dasimétrico para redistribuir proporcionalmente datos censales argentinos de 2022 desde el nivel de radio censal hasta una resolución de 100 metros para la localidad de Esperanza en la provincia de Santa Fe, Argentina, utilizando datos auxiliares de la Capa Global de Asentamientos Humanos (GHSL) de 2023. Este método representa una forma razonablemente efectiva de reducir la escala de datos censales a mayor resolución para su uso en modelado de riesgo climático con fuentes de datos abiertos.\nMostrar código\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rasterstats\nfrom rasterio.features import rasterize\nfrom io import BytesIO\nfrom owslib.wfs import WebFeatureService\n\nimport rioxarray\nimport contextily as ctx\nfrom shapely.geometry import box\nimport xarray as xr\n\n\nUSE_CRS = \"EPSG:5347\"  # posgar para esperanza\nWEB_MERCATOR_CRS = \"EPSG:3857\"\n\nDEFAULT_FIGSIZE = (12, 10)\nMAP_PADDING = 500\nPLASMA_CMAP = plt.cm.plasma\n\n\ndef setup_base_map(\n    figsize=None, bounds=None, boundary_gdf=None, padding_x=None, padding_y=None\n):\n    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n    if figsize is None:\n        figsize = DEFAULT_FIGSIZE\n    if padding_x is None:\n        padding_x = MAP_PADDING\n    if padding_y is None:\n        padding_y = MAP_PADDING\n\n    if bounds is None and boundary_gdf is not None:\n        bounds = boundary_gdf.total_bounds\n\n    # Convert bounds to Web Mercator for basemap compatibility\n    if bounds is not None:\n        # Create a temporary GeoDataFrame with the bounds to reproject\n        temp_bounds = gpd.GeoDataFrame(\n            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS\n        )\n        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds\n    else:\n        bounds_3857 = bounds\n\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)\n    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)\n    return fig, ax\n\n\ndef add_basemap(ax, zoom=13):\n    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n\n    ctx.add_basemap(\n        ax,\n        source=ctx.providers.CartoDB.PositronNoLabels,\n        zorder=0,\n        zoom=zoom,\n    )\n\n    return ax\n\n\ndef add_north_arrow(ax, x=0.95, y=0.05, arrow_length=0.04):\n    \"\"\"Add a north arrow to the map.\"\"\"\n    ax.annotate(\n        \"N\",\n        xy=(x, y),\n        xytext=(x, y - arrow_length),\n        arrowprops=dict(facecolor=\"black\", width=3, headwidth=10),\n        ha=\"center\",\n        va=\"center\",\n        fontsize=14,\n        xycoords=ax.transAxes,\n    )\n\n\ndef add_boundary_outline(ax, boundary_gdf, crs=\"EPSG:3857\"):\n    \"\"\"Add the outline of a boundary geodataframe to a map.\"\"\"\n    boundary_3857 = boundary_gdf.to_crs(crs)\n    boundary_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"black\",\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=5,\n    )\n\n\ndef create_consistent_map(title, boundary_gdf, bounds=None):\n    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n    fig, ax = setup_base_map(bounds=bounds, boundary_gdf=boundary_gdf)\n\n    add_basemap(ax)\n\n    add_north_arrow(ax)\n\n    add_boundary_outline(ax, boundary_gdf)\n\n    ax.set_title(title, fontsize=16, fontweight=\"bold\", pad=20)\n\n    ax.set_axis_off()\n\n    return fig, ax\n\n\ndef wfs_to_gdf(\n    wfs_url: str, layer_name: str, srs: str = \"EPSG:4326\"\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Descarga una capa WFS y la devuelve como GeoDataFrame.\n\n    Args:\n        wfs_url (str): URL del servicio WFS.\n        layer_name (str): Nombre de la capa (typename).\n        srs (str): Código EPSG del sistema de referencia de coordenadas.\n\n    Returns:\n        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.\n    \"\"\"\n    wfs = WebFeatureService(url=wfs_url, version=\"2.0.0\")\n    response = wfs.getfeature(typename=layer_name, srsname=srs)\n    gdf = gpd.read_file(BytesIO(response.read()))\n    return gdf\n\n\nbase_url = \"https://wms.ign.gob.ar/geoserver/ign/ows\"\n\nmunis = wfs_to_gdf(wfs_url=base_url, layer_name=\"ign:municipio\", srs=\"EPSG:4326\")\n\nesperanza = munis[munis[\"nam\"] == \"Esperanza\"]\nesperanza = esperanza.to_crs(USE_CRS)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#introducción-a-la-exposición",
    "href": "exposicion.html#introducción-a-la-exposición",
    "title": "1  Exposición",
    "section": "2.1 Introducción a la Exposición",
    "text": "2.1 Introducción a la Exposición\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#análisis-de-exposición",
    "href": "exposicion.html#análisis-de-exposición",
    "title": "1  Exposición",
    "section": "2.2 Análisis de Exposición",
    "text": "2.2 Análisis de Exposición\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#evaluación-de-riesgos",
    "href": "exposicion.html#evaluación-de-riesgos",
    "title": "1  Exposición",
    "section": "2.3 Evaluación de Riesgos",
    "text": "2.3 Evaluación de Riesgos\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.\n\n\nMostrar código\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nimport xarray as xr\nimport rioxarray\nfrom rioxarray.merge import merge_arrays\nimport xdem\nimport tempfile\nimport numpy as np\nfrom matplotlib import colors\nimport leafmap.leafmap as leafmap\nfrom pysheds.grid import Grid\nfrom jenkspy import jenks_breaks\n\nCRS_ARGENTINA = \"EPSG:5349\"\nCRS_WGS84 = \"EPSG:4326\"\n\nRUTA_BASE = Path(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo\")\nRUTA_DATOS = RUTA_BASE / \"notebooks/data\"\nRUTA_PARTIDOS = RUTA_DATOS / \"pba_partidos.geojson\"\n\nCMAP = \"BuPu\"\n\nruta_peligro = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/peligro_raster_10m.tif\"\npeligro_xarray = rioxarray.open_rasterio(ruta_peligro)\n\nm = leafmap.Map()\nm.add_raster(peligro_xarray, colormap=CMAP, layer_name=\"Peligrosidad\", nodata=peligro_xarray.rio.nodata)\n\nm.add_layer_control()\nm",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "suavizacion.html",
    "href": "suavizacion.html",
    "title": "2  Suavización",
    "section": "",
    "text": "2.1 Conceptos de Suavización\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#métodos-de-suavización",
    "href": "suavizacion.html#métodos-de-suavización",
    "title": "2  Suavización",
    "section": "2.2 Métodos de Suavización",
    "text": "2.2 Métodos de Suavización\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#aplicaciones-prácticas",
    "href": "suavizacion.html#aplicaciones-prácticas",
    "title": "2  Suavización",
    "section": "2.3 Aplicaciones Prácticas",
    "text": "2.3 Aplicaciones Prácticas\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "renabap.html",
    "href": "renabap.html",
    "title": "3  RENABAP",
    "section": "",
    "text": "3.1 Resumen ejecutivo\nEste análisis utiliza datos globales abiertos de huellas de edificios para lograr una estimación más precisa de la exposición a peligros de inundación en asentamientos informales en La Plata. Este método mejora significativamente las estimaciones previas utilizando datos del RENABAP y revela una subestimación dramática en los datos oficiales. Encontramos que los datos del RENABAP subestiman el número de edificios en un promedio del 41%, lo que equivale a aproximadamente 41,000 viviendas faltantes que no están contabilizadas en las estadísticas oficiales. Tomando un promedio razonable de 3 a 5 personas por vivienda, esto representa entre 120,000 y 205,000 personas que podrían estar no contabilizadas en los asentamientos informales. El conjunto de datos globales de huellas de edificios representa, por tanto, una herramienta crítica para comprender la verdadera magnitud de la exposición a peligros de inundación en La Plata.\nEncontramos que Villa Montoro tiene el mayor número de edificios expuestos a peligro alto bajo la precipitación máxima probable, con 555 edificios. La Cuenca Arroyo del Gato presenta el mayor número total de edificios expuestos con 2,662, seguida por la Cuenca Maldonado con 1,000. Además, un análisis comparativo de exposición bajo diferentes períodos de retorno para la Cuenca Maldonado revela diferencias significativas en la exposición estimada dependiendo del período de retorno considerado. Mientras que la precipitación máxima probable estima un total de 1,000 edificios expuestos para la cuenca, el período de retorno de 25 años estima 77 edificios expuestos y el período de retorno de 100 años estima 141 edificios expuestos a peligro alto, planteando así interrogantes sobre cuál de estos es más útil para iniciar el proceso de reubicación de viviendas en áreas de alto peligro en asentamientos informales.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#objetivos",
    "href": "renabap.html#objetivos",
    "title": "3  RENABAP",
    "section": "3.2 Objetivos",
    "text": "3.2 Objetivos\nEste proyecto tiene como objetivo principal mejorar el mapeo de la exposición a peligros de inundación en asentamientos informales del Partido de La Plata. El análisis se realiza específicamente con el propósito de preparar un plan para la reubicación gradual de las estructuras, viviendas o familias en mayor riesgo dentro de estos asentamientos informales hacia lugares más seguros.\nEl trabajo busca cuantificar la exposición a peligros de inundación en asentamientos informales como herramienta para la toma de decisiones a nivel municipal, desarrollando metodologías de análisis espacial que permitan identificar las áreas y poblaciones de mayor riesgo. Asimismo, se propone proporcionar información técnica que ayude a mitigar el riesgo de inundación en asentamientos informales y obtener estimaciones más precisas de la población expuesta utilizando datos de huellas de edificios, complementando las limitaciones conocidas de los datos del RENABAP.\nUn objetivo adicional de este análisis es obtener estimaciones más precisas de exposición utilizando datos abiertos de huellas de edificios en lugar de depender únicamente de los datos del RENABAP. Los últimos datos del RENABAP fueron publicados en 2023 y están basados en proyecciones derivadas del censo de 2010, por lo que no se espera que sean especialmente precisos para las condiciones actuales.\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\nfrom io import BytesIO, StringIO\nfrom owslib.wfs import WebFeatureService\nfrom shapely.geometry import box\nimport geopandas as gpd\nimport requests\nimport pandas as pd\nimport os\n\nimport boto3\nimport duckdb\n\n\nimport numpy as np\nimport s2sphere\nfrom botocore.config import Config\nimport itables\nfrom itables import show\nfrom IPython.display import HTML, display\n\n# For scale bars and north arrows\nfrom matplotlib_map_utils import north_arrow, scale_bar, ScaleBar\n\n\n# =============================================================================\n# ITABLES SPANISH CONFIGURATION\n# =============================================================================\n\n# Configure Argentine Spanish for itables\ntry:\n    spanish_url = \"https://cdn.datatables.net/plug-ins/2.3.3/i18n/es-AR.json\"\n    response = requests.get(spanish_url)\n    response.raise_for_status()\n    spanish_config = response.json()\n    itables.options.language = spanish_config\nexcept Exception:\n    pass  # Fall back to English if configuration fails\n\n# Configure smaller font size for all itables\ncss = \"\"\"\n.dt-container {\n  font-size: small;\n}\n\"\"\"\ndisplay(HTML(f\"&lt;style&gt;{css}&lt;/style&gt;\"))\n\n\n# Helper function to round numeric columns for display\ndef round_numeric_columns(df, decimals=0):\n    \"\"\"Round all numeric columns in a DataFrame to specified decimal places.\"\"\"\n    df_display = df.copy()\n    numeric_columns = df_display.select_dtypes(include=[np.number]).columns\n    df_display[numeric_columns] = df_display[numeric_columns].round(decimals)\n    return df_display\n\n\n# =============================================================================\n# CONSTANTS AND CONFIGURATION\n# =============================================================================\n\n# Coordinate Reference Systems\nUSE_CRS = \"EPSG:5349\"  # POSGAR 2007 / Argentina 4\nWEB_MERCATOR_CRS = \"EPSG:3857\"  # Web Mercator for visualization\nWGS84_CRS = \"EPSG:4326\"  # WGS84 for API calls\n\n# File paths\nBASE_PATH = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo\"\nDATA_PATH = f\"{BASE_PATH}/notebooks/data\"\nPELIGRO_PATH = f\"{DATA_PATH}/la_plata_pelig_2023_datos_originales.geojson\"\nPARTIDOS_PATH = f\"{DATA_PATH}/pba_partidos.geojson\"\nCUENCAS_PATH = f\"{BASE_PATH}/notebooks/cuencas_buenos_aires.geojson\"\nBUILDINGS_PATH = f\"{BASE_PATH}/notebooks/buildings_filtered.parquet\"\n\n# Data URLs\nRENABAP_URL = (\n    \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\n)\nPARTIDOS_WFS_URL = \"https://geo.arba.gov.ar/geoserver/idera/wfs\"\nCUENCAS_API_URL = \"https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query\"\n\n# Data processing constants\nHAZARD_LEVELS = [\"baja\", \"media\", \"alta\"]\nMETHOD_NAMES = [\"edificios\", \"ghsl\", \"areal\"]\nEXPOSURE_COLUMNS = [\n    \"fam_exp_edificios\",\n    \"fam_exp_ghsl\",\n    \"fam_exp_areal\",\n]\nNON_HAZARD_VALUE = \"none\"\nNODATA_VALUE = -200\n\n# Column mappings and renaming\nCOLUMN_MAPPINGS = {\n    \"buildings_to_edificios\": {\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"},\n    \"method_cleanup_prefix\": \"fam_expuestas_\",\n}\n\n# Basic visualization settings (only for repeated values)\nDEFAULT_FIGSIZE = (12, 10)\nMAP_PADDING = 500\nPLASMA_CMAP = plt.cm.plasma\n\n# Color schemes for visualization\nPELIGROSIDAD_COLORS = {\n    \"alta\": PLASMA_CMAP(0.8),\n    \"media\": PLASMA_CMAP(0.5),\n    \"baja\": PLASMA_CMAP(0.2),\n}\n\nMETHOD_COLORS = {\n    \"fam_exp_areal\": PLASMA_CMAP(0.8),\n    \"fam_exp_ghsl\": PLASMA_CMAP(0.5),\n    \"fam_exp_edificios\": PLASMA_CMAP(0.2),\n}\n\n# Eje mapping for watershed analysis\nEJE_MAPPING = {\n    \"noreste\": [\"Area de Bañados\", \"Cuenca Arroyo Rodriguez-Don Carlos\"],\n    \"noroeste\": [\"Cuenca Arroyo Martín-Carnaval\", \"Cuenca Arroyo Pereyra\"],\n    \"central\": [\"Cuenca Arroyo del Gato\"],\n    \"sudoeste\": [\"Cuenca A° Maldonado\", \"Cuenca Río Samborombón\"],\n    \"sudeste\": [\"Cuenca Arroyo El Pescado\"],\n}\n\n\ndef setup_base_map(\n    figsize=None, bounds=None, boundary_gdf=None, padding_x=None, padding_y=None\n):\n    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n    if figsize is None:\n        figsize = DEFAULT_FIGSIZE\n    if padding_x is None:\n        padding_x = MAP_PADDING\n    if padding_y is None:\n        padding_y = MAP_PADDING\n\n    if bounds is None and boundary_gdf is not None:\n        bounds = boundary_gdf.total_bounds\n    elif bounds is None:\n        bounds = renabap_pba_intersect.total_bounds\n\n    # Convert bounds to Web Mercator for basemap compatibility\n    if bounds is not None:\n        # Create a temporary GeoDataFrame with the bounds to reproject\n        temp_bounds = gpd.GeoDataFrame(\n            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS\n        )\n        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds\n    else:\n        bounds_3857 = bounds\n\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)\n    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)\n    return fig, ax\n\n\ndef add_basemap(ax, zoom=13):\n    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n\n    ctx.add_basemap(\n        ax,\n        source=ctx.providers.CartoDB.PositronNoLabels,\n        zorder=0,\n        zoom=zoom,\n    )\n\n    return ax\n\n\nScaleBar.set_size(\"xs\")\n\ndef add_scale_bar_and_north_arrow(ax, location=\"upper right\", scale_color=\"black\", arrow_color=\"black\"):\n    \"\"\"Add a scale bar and north arrow to the map using matplotlib_map_utils.\"\"\"\n    # Add scale bar using matplotlib_map_utils ScaleBar class with ticks style\n    scalebar = ScaleBar(\n        location=\"upper left\",\n        style=\"ticks\",\n        bar={\n            \"projection\": \"EPSG:3857\",\n            \"tickcolors\": scale_color,\n            \"basecolors\": scale_color,\n            \"minor_type\": \"none\"\n        },\n        labels={\"style\": \"first_last\"}\n    )\n    ax.add_artist(scalebar)\n    \n    # Add north arrow using matplotlib_map_utils\n    north_arrow(\n        ax,\n        location=location,\n        scale=0.3,  # Small size\n        rotation={\"degrees\": 0},\n        base={\"facecolor\": \"none\", \"edgecolor\": arrow_color, \"linewidth\": 1},\n        fancy=True,\n        shadow=True,\n        label=False  # Hide the \"N\" text\n    )\n\n\ndef add_la_plata_outline(ax, color=\"black\"):\n    \"\"\"Add the outline of Partido de La Plata to a map as the top layer.\"\"\"\n    la_plata_3857 = la_plata.to_crs(WEB_MERCATOR_CRS)\n    la_plata_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=color,\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=100,  # Ensure it's always on top\n    )\n\n\ndef add_boundary_outline(ax, boundary_gdf, crs=\"EPSG:3857\"):\n    \"\"\"Add the outline of a boundary geodataframe to a map.\"\"\"\n    boundary_3857 = boundary_gdf.to_crs(crs)\n    boundary_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"black\",\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=5,\n    )\n\n\ndef create_consistent_map(title, boundary_gdf=None, bounds=None):\n    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n    fig, ax = setup_base_map(bounds=bounds, boundary_gdf=boundary_gdf)\n\n    add_basemap(ax)\n\n    add_scale_bar_and_north_arrow(ax)\n\n    if boundary_gdf is not None:\n        add_boundary_outline(ax, boundary_gdf)\n    else:\n        add_la_plata_outline(ax)\n\n    ax.set_title(title, fontsize=16, fontweight=\"bold\", pad=20)\n\n    ax.set_axis_off()\n\n    return fig, ax\n\n\ndef wfs_to_gdf(\n    wfs_url: str, layer_name: str, srs: str = \"EPSG:4326\"\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Descarga una capa WFS y la devuelve como GeoDataFrame.\n\n    Args:\n        wfs_url (str): URL del servicio WFS.\n        layer_name (str): Nombre de la capa (typename).\n        srs (str): Código EPSG del sistema de referencia de coordenadas.\n\n    Returns:\n        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.\n    \"\"\"\n    wfs = WebFeatureService(url=wfs_url, version=\"2.0.0\")\n    response = wfs.getfeature(typename=layer_name, srsname=srs)\n    gdf = gpd.read_file(BytesIO(response.read()))\n    return gdf\n\n\ndef create_exposure_tidy_data(\n    data,\n    id_column,\n    peligrosidad_column,\n    method_suffix,\n    exposure_values,\n    exclude_zero=True,\n):\n    \"\"\"\n    Create tidy exposure dataset in a standardized format.\n\n    Args:\n        data: DataFrame containing the base data\n        id_column: Column name for the identifier (e.g., 'id_renabap', 'Cuenca', 'eje')\n        peligrosidad_column: Column name for hazard level\n        method_suffix: Suffix for the exposure column (e.g., 'areal', 'ghsl', 'edificios')\n        exposure_values: Series or array of exposure values matching data rows\n        exclude_zero: Whether to exclude zero exposure values\n\n    Returns:\n        pd.DataFrame: Tidy format dataframe with id, peligrosidad, and exposure columns\n    \"\"\"\n    tidy_data = []\n    for idx, (_, row) in enumerate(data.iterrows()):\n        exposure_value = (\n            exposure_values.iloc[idx]\n            if hasattr(exposure_values, \"iloc\")\n            else exposure_values[idx]\n        )\n\n        if exclude_zero and exposure_value &lt;= 0:\n            continue\n\n        tidy_data.append(\n            {\n                id_column: row[id_column],\n                \"peligrosidad\": row[peligrosidad_column],\n                f\"fam_expuestas_{method_suffix}\": exposure_value,\n            }\n        )\n\n    return pd.DataFrame(tidy_data)\n\n\ndef create_wide_exposure_dataframe(\n    areal_data, ghsl_data, buildings_data, id_columns, exclude_hazard_value=\"none\"\n):\n    \"\"\"\n    Create wide format exposure dataframe by merging tidy datasets.\n\n    Args:\n        areal_data: Tidy dataframe with areal interpolation results\n        ghsl_data: Tidy dataframe with GHSL dasymetric results\n        buildings_data: Tidy dataframe with buildings dasymetric results\n        id_columns: List of columns to merge on (e.g., ['id_renabap', 'peligrosidad'])\n        exclude_hazard_value: Hazard value to exclude from results\n\n    Returns:\n        pd.DataFrame: Wide format dataframe with all exposure methods\n    \"\"\"\n    # Filter out non-hazard values\n    areal_filtered = areal_data[areal_data[\"peligrosidad\"] != exclude_hazard_value]\n    ghsl_filtered = ghsl_data[ghsl_data[\"peligrosidad\"] != exclude_hazard_value]\n    buildings_filtered = buildings_data[\n        buildings_data[\"peligrosidad\"] != exclude_hazard_value\n    ]\n\n    # Apply column mapping for buildings if needed\n    if \"fam_expuestas_buildings\" in buildings_filtered.columns:\n        buildings_filtered = buildings_filtered.rename(\n            columns={\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"}\n        )\n\n    # Merge all datasets\n    wide_data = areal_filtered.merge(ghsl_filtered, on=id_columns, how=\"outer\").merge(\n        buildings_filtered, on=id_columns, how=\"outer\"\n    )\n\n    # Fill NaN values with 0\n    wide_data = wide_data.fillna(0)\n\n    # Rename columns to shorter format\n    column_mapping = {\n        \"fam_expuestas_areal\": \"fam_exp_areal\",\n        \"fam_expuestas_ghsl\": \"fam_exp_ghsl\",\n        \"fam_expuestas_edificios\": \"fam_exp_edificios\",\n    }\n    wide_data = wide_data.rename(columns=column_mapping)\n\n    return wide_data\n\n\nresponse = requests.get(RENABAP_URL)\nrenabap = gpd.read_file(StringIO(response.text))\nrenabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\nrenabap_pba = renabap_pba.to_crs(USE_CRS)\n\npeligro = gpd.read_file(PELIGRO_PATH)\npeligro = peligro.to_crs(USE_CRS)\n\npeligro_bounds = peligro.total_bounds\npeligro_bbox = box(*peligro_bounds)\n\nif os.path.exists(PARTIDOS_PATH):\n    partidos = gpd.read_file(PARTIDOS_PATH)\nelse:\n    partidos = wfs_to_gdf(\n        wfs_url=PARTIDOS_WFS_URL,\n        layer_name=\"idera:Departamento\",\n        srs=\"EPSG:5347\",\n    )\n\n    partidos.to_file(PARTIDOS_PATH, driver=\"GeoJSON\")\n\npartidos = partidos.to_crs(USE_CRS)\nla_plata = partidos[partidos[\"fna\"] == \"Partido de La Plata\"]\n\n# Obtener la geometría principal\nmain_geom = la_plata.geometry.iloc[0]\n\n# Si es un MultiPolygon, mantener solo el polígono más grande (el partido principal)\n# Esto elimina la pequeña isla que aparece en los datos\nif main_geom.geom_type == \"MultiPolygon\":\n    # Obtener todos los polígonos y mantener el que tenga mayor área\n    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)\n    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning\n    la_plata.loc[la_plata.index[0], \"geometry\"] = largest_polygon\n\nla_plata_bbox = la_plata.geometry.iloc[0]\n\nrenabap_pba_intersect = renabap_pba[\n    renabap_pba.geometry.intersects(la_plata_bbox)\n].copy()\n\n\nif os.path.exists(CUENCAS_PATH):\n    cuencas = gpd.read_file(CUENCAS_PATH)\nelse:\n    params = {\"where\": \"1=1\", \"outFields\": \"*\", \"f\": \"geojson\"}\n\n    cuencas_response = requests.get(CUENCAS_API_URL, params=params)\n    with open(CUENCAS_PATH, \"w\", encoding=\"utf-8\") as f:\n        f.write(cuencas_response.text)\n\n    cuencas = gpd.read_file(StringIO(cuencas_response.text))\n\ncuencas = cuencas.to_crs(USE_CRS)\ncuencas = cuencas.clip(la_plata)\n\n# Map watershed names to axes based on the EJE_MAPPING\ncuencas[\"eje\"] = (\n    cuencas[\"Cuenca\"]\n    .map(\n        {\n            cuenca: eje\n            for eje, cuencas_list in EJE_MAPPING.items()\n            for cuenca in cuencas_list\n        }\n    )\n    .fillna(\"otro\")\n)\n\n# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)\nrenabap_total_area_ha = (\n    renabap_pba_intersect.geometry.area.sum() / 10000\n)  # Convert m² to hectares\nla_plata_area_ha = la_plata.geometry.iloc[0].area / 10000\npercentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100\n\n# Get common bounds for all maps\ncommon_bounds = la_plata.total_bounds\n\n# Intersect settlements with hazard zones\nsettlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n\nsettle_hazard_cuencas = gpd.overlay(\n    settlement_hazard, cuencas, how=\"intersection\", keep_geom_type=True\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#contexto",
    "href": "renabap.html#contexto",
    "title": "3  RENABAP",
    "section": "3.4 Contexto",
    "text": "3.4 Contexto\n\n\nMostrar código\n# Calcular variables para el contexto\ntotal_barrios = int(len(renabap_pba_intersect))\ntotal_familias = int(renabap_pba_intersect['familias_aproximadas'].sum())\narea_barrios_ha = int(renabap_total_area_ha)\nporcentaje_cobertura = float(round(percentage_coverage, 1))\n\n# Obtener total de edificaciones en La Plata\ntotal_buildings_la_plata = len(buildings_proj)\n\n# Obtener todas las edificaciones que intersectan con los barrios (corregir warning de deprecación)\nbuildings_in_barrios = buildings_proj[\n    buildings_proj.geometry.intersects(renabap_pba_intersect.union_all())\n]\ntotal_buildings_in_barrios = len(buildings_in_barrios)\n\n# Calcular porcentaje de edificaciones en barrios\nbuildings_percentage = float(round((total_buildings_in_barrios / total_buildings_la_plata) * 100, 1))\n\n# Helper function to format numbers with commas\ndef format_number(num):\n    return f\"{num:,}\"\n\n# Recortar peligro por la plata\npeligro_la_plata = peligro.clip(la_plata)\n\n# Calcular área para cada tipo de peligro en hectáreas\npeligro_areas = (\n    peligro_la_plata.groupby(\"PELIGROSID\")[\"geometry\"]\n    .apply(\n        lambda x: x.area.sum() / 10000  # Convertir m² a hectáreas\n    )\n    .reset_index()\n)\npeligro_areas.columns = [\"tipo_peligro\", \"area_ha\"]\n\n# Calcular porcentajes\npeligro_areas[\"porcentaje\"] = (peligro_areas[\"area_ha\"] / la_plata_area_ha) * 100\n\n# Variables para cada nivel de peligro (convertir a float Python nativo)\npeligro_alta_ha = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"alta\"][\"area_ha\"].iloc[0], 1))\npeligro_alta_pct = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"alta\"][\"porcentaje\"].iloc[0], 1))\npeligro_media_ha = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"media\"][\"area_ha\"].iloc[0], 1))\npeligro_media_pct = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"media\"][\"porcentaje\"].iloc[0], 1))\npeligro_baja_ha = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"baja\"][\"area_ha\"].iloc[0], 1))\npeligro_baja_pct = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"baja\"][\"porcentaje\"].iloc[0], 1))\n\n# Área total cubierta por zonas de peligro (convertir a float Python nativo)\narea_total_peligro_ha = float(round(peligro_areas['area_ha'].sum(), 1))\nporcentaje_total_peligro = float(round(peligro_areas['porcentaje'].sum(), 1))\n\n\nHay un total de 166 barrios populares en el Partido de La Plata, que representan 33,888 familias y 30,753 edificios. Estos barrios ocupan 1,760 hectáreas del Partido de La Plata, o 2.0 por ciento del partido. El análisis de edificios revela un total de 604,237 edificios en La Plata, de los cuales 71,898 se encuentran en barrios populares (11.9% del total). En cuanto a las zonas de peligro de inundación, el territorio incluye 4,202 hectáreas de peligro alto (4.7% del partido), 19,515 hectáreas de peligro medio (21.8% del partido), y 5,885 hectáreas de peligro bajo (6.6% del partido). El área total cubierta por zonas de peligro es de 29,603 hectáreas, representando 33.0% del partido.\n\nMostrar código\nfig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", boundary_gdf=la_plata, bounds=common_bounds)\n\nrenabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(WEB_MERCATOR_CRS)\n\nrenabap_pba_intersect_3857.plot(\n    ax=ax1, facecolor=\"none\", edgecolor=\"black\", linewidth=0.5, legend=False, zorder=10\n)\n\nplt.tight_layout()\nplt.show()\n\npeligro_clipped = gpd.clip(peligro, la_plata)\n\npeligro_clipped_3857 = peligro_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Reorder the categories so they map correctly to plasma colormap\npeligro_clipped_3857[\"PELIGROSID_ordered\"] = pd.Categorical(\n    peligro_clipped_3857[\"PELIGROSID\"],\n    categories=[\"baja\", \"media\", \"alta\"],\n    ordered=True,\n)\n\n\nfig2, ax2 = create_consistent_map(\"Zonas de Peligro en La Plata\", boundary_gdf=la_plata, bounds=common_bounds)\n\n\npeligro_clipped_3857.plot(\n    ax=ax2,\n    column=\"PELIGROSID_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    legend_kwds={\"loc\": \"lower right\"},\n    zorder=5,\n)\n\nplt.tight_layout()\nplt.show()\n\n\nfig3, ax3 = create_consistent_map(\"Huellas de edificios\", boundary_gdf=la_plata, bounds=common_bounds)\n\nbuildings_3857 = buildings_proj.to_crs(WEB_MERCATOR_CRS)\n\nbuildings_3857.plot(ax=ax3, facecolor=\"grey\", edgecolor=\"none\", alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Asentamientos RENABAP en La Plata\n\n\n\n\n\n\n\n\n\n\n\n(b) Zonas de Peligro en La Plata\n\n\n\n\n\n\n\n\n\n\n\n(c) Huellas de edificios\n\n\n\n\n\n\n\nFigure 3.1: Fuentes de datos para análisis de exposición",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#fuentes-de-datos",
    "href": "renabap.html#fuentes-de-datos",
    "title": "3  RENABAP",
    "section": "3.3 Fuentes de datos",
    "text": "3.3 Fuentes de datos\n\n3.3.1 RENABAP\nEl Registro Nacional de Barrios Populares (RENABAP) es producido por la Subsecretaría de Integración Socio Urbana y proporciona información sobre asentamientos informales en Argentina, incluyendo estimaciones de población y delimitaciones geográficas de estos barrios. Más información sobre el RENABAP está disponible en el Observatorio de Barrios Populares. Los datos fueron obtenidos a través del Mapa de Barrios Populares y están disponibles para descarga como GeoJSON.\n\n\n3.3.2 Peligro de inundación\nLos datos de peligro de inundación utilizados en este análisis fueron desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata (Romanazzi et al. 2019). Estos datos fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que permitió simular la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. El modelo calcula las principales variables hidráulicas (altura del agua, velocidad y caudal) a lo largo del tiempo, y a partir de estos resultados se generaron los mapas de peligrosidad que combinan el efecto de la profundidad con la velocidad de la corriente, ofreciendo un indicador más completo que los mapas tradicionales de máximas profundidades.\n\n\n3.3.3 Google-Microsoft-OSM Open Buildings\nLos datos de Google-Microsoft-OSM Open Buildings - combined by VIDA (VIDA 2023) representan una forma más precisa de evaluar dónde se ubican los asentamientos humanos. Este conjunto de datos combina Google’s V3 Open Buildings, Microsoft’s GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo más de 2.7 mil millones de huellas de edificios. Estos datos han sido exitosamente aplicados a evaluaciones de riesgo de inundación por empresas globales de riesgo financiero como ICE, demostrando su utilidad para mapear la exposición climática a nivel de huella de edificio individual. Sin embargo, en ausencia de información sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el número total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de dónde se ubican las personas, sin tener una comprensión precisa de quién vive realmente allí y cuántas personas.\n\n\nMostrar código\ndef fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n\n    # Get S2 cell and bounds\n    center = geodataframe.to_crs(WEB_MERCATOR_CRS).union_all().centroid\n    center_wgs84 = (\n        gpd.GeoDataFrame(geometry=[center], crs=WEB_MERCATOR_CRS)\n        .to_crs(WGS84_CRS)\n        .geometry.iloc[0]\n    )\n    cell = s2sphere.CellId.from_lat_lng(\n        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n    ).parent(10)\n    bounds = geodataframe.to_crs(WGS84_CRS).total_bounds\n\n    # Find matching S2 partition\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=\"https://data.source.coop\",\n        aws_access_key_id=\"\",\n        aws_secret_access_key=\"\",\n        config=Config(s3={\"addressing_style\": \"path\"}),\n    )\n\n    partitions = {\n        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n        for obj in s3.list_objects_v2(\n            Bucket=\"vida\",\n            Prefix=\"google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n        ).get(\"Contents\", [])\n    }\n\n    parent_id = next(\n        str(cell.parent(level).id())\n        for level in range(10, 0, -1)\n        if str(cell.parent(level).id()) in partitions\n    )\n\n    # Setup DuckDB and query\n    con = duckdb.connect()\n    for cmd in [\n        \"INSTALL spatial\",\n        \"LOAD spatial\",\n        \"INSTALL httpfs\",\n        \"LOAD httpfs\",\n        \"SET s3_region='us-east-1'\",\n        \"SET s3_endpoint='data.source.coop'\",\n        \"SET s3_use_ssl=true\",\n        \"SET s3_url_style='path'\",\n    ]:\n        con.execute(cmd)\n\n    # Export and read back\n    query = f\"\"\"\n    COPY (SELECT * FROM 's3://vida/google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n          WHERE bbox.xmax &gt;= {bounds[0]} AND bbox.xmin &lt;= {bounds[2]} AND\n                bbox.ymax &gt;= {bounds[1]} AND bbox.ymin &lt;= {bounds[3]}\n    ) TO '{temp_file}' (FORMAT PARQUET);\n    \"\"\"\n\n    con.execute(query)\n    df = pd.read_parquet(temp_file)\n    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n\n    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=WGS84_CRS)\n\n\nif os.path.exists(BUILDINGS_PATH):\n    buildings = gpd.read_parquet(BUILDINGS_PATH)\nelse:\n    buildings = fetch_buildings(renabap_pba_intersect)\n\n\nbuildings_proj = buildings.to_crs(USE_CRS)\n\nbuildings_proj = buildings_proj.clip(la_plata)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#metodología-y-procesamiento",
    "href": "renabap.html#metodología-y-procesamiento",
    "title": "3  RENABAP",
    "section": "3.5 Metodología y procesamiento",
    "text": "3.5 Metodología y procesamiento\n\n3.5.1 Interpolación por area\nLa interpolación areal es un método simple en el que las variables de los datos fuente se ponderan según la superposición entre polígonos fuente y objetivo, luego se reagregan para ajustarse a las geometrías de los polígonos objetivo. En nuestro análisis, esto significa distribuir proporcionalmente la población de cada barrio popular según el área de intersección con diferentes niveles de peligro de inundación. El analasis original de la exposición poblacional a peligros de inundación en la región del Partido de La Plata se realizó utilizando este método.\n\n\nMostrar código\nif renabap_pba_intersect.crs != peligro.crs:\n    peligro = peligro.to_crs(renabap_pba_intersect.crs)\n\nhazard_levels = peligro[\"PELIGROSID\"].unique()\n\nrenabap_with_porciones = renabap_pba_intersect.copy()\nfor level in hazard_levels:\n    renabap_with_porciones[f\"porcion_{level}\"] = 0.0\n\nrenabap_with_porciones[\"total_area\"] = renabap_with_porciones.geometry.area\n\nfor idx, barrio in renabap_with_porciones.iterrows():\n    barrio_geom = barrio.geometry\n    barrio_total_area = barrio_geom.area\n\n    if barrio_total_area == 0:\n        continue\n\n    for level in hazard_levels:\n        hazard_subset = peligro[peligro[\"PELIGROSID\"] == level]\n\n        if hazard_subset.empty:\n            continue\n\n        intersection_area = 0\n        for _, hazard_row in hazard_subset.iterrows():\n            try:\n                intersection = barrio_geom.intersection(hazard_row.geometry)\n                if not intersection.is_empty:\n                    intersection_area += intersection.area\n            except Exception as e:\n                print(\n                    f\"Error calculating intersection for {barrio.get('nombre_barrio', idx)}: {e}\"\n                )\n                continue\n\n        proportion = (\n            intersection_area / barrio_total_area if barrio_total_area &gt; 0 else 0\n        )\n        renabap_with_porciones.at[idx, f\"porcion_{level}\"] = proportion\n\n# Create barrio tidy format using consolidated function\nbarrio_areal_rows = []\nfor idx, row in renabap_with_porciones.iterrows():\n    for level in hazard_levels:\n        familias_expuestas = row[f\"porcion_{level}\"] * row[\"familias_aproximadas\"]\n        if familias_expuestas &gt; 0:\n            barrio_areal_rows.append(\n                {\n                    \"id_renabap\": row[\"id_renabap\"],\n                    \"PELIGROSID\": level,\n                    \"fam_expuestas\": familias_expuestas,\n                }\n            )\n\nbarrio_areal_temp = pd.DataFrame(barrio_areal_rows)\nbarrio_areal_tidy = create_exposure_tidy_data(\n    data=barrio_areal_temp,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"areal\",\n    exposure_values=barrio_areal_temp[\"fam_expuestas\"],\n    exclude_zero=True,\n)\n\n# 2. CUENCA AREAL EXPOSURE - aggregate from barrio level, avoiding double counting\n# Get the cuenca for each settlement - but handle settlements that cross cuenca boundaries\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\n\n# Check if any settlements appear in multiple cuencas\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\n\nif len(multi_cuenca_settlements) &gt; 0:\n    # For settlements in multiple cuencas, assign to the cuenca with largest intersection\n    # For now, just take the first occurrence\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\ncuenca_areal_tidy = barrio_areal_tidy[\n    barrio_areal_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE\n].merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\ncuenca_areal_tidy = (\n    cuenca_areal_tidy.groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n# 3. EJE AREAL EXPOSURE - same fix\ncuenca_eje_mapping = settle_hazard_cuencas[[\"Cuenca\", \"eje\"]].drop_duplicates()\n\neje_areal_tidy = cuenca_areal_tidy.merge(cuenca_eje_mapping, on=\"Cuenca\")\neje_areal_tidy = (\n    eje_areal_tidy.groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n\n\n\n3.5.2 Mapeo dasymetrico\nEl mapeo dasimétrico reorganiza datos cartográficos de una unidad de recolección en áreas más precisas, modificando los límites originales usando datos de apoyo relacionados. Por ejemplo, un atributo de población organizado por tracto censal se vuelve más significativo cuando se eliminan áreas donde es razonable inferir que la gente no vive (cuerpos de agua, terrenos vacíos). En nuestro caso, utilizamos datos GHSL y huellas de edificios como información auxiliar para mejorar la precisión de las estimaciones de distribución poblacional.\n\n\nMostrar código\n### BUILDINGS\n\n# Get ALL buildings per settlement (not just hazard-intersected ones)\nbuildings_settlement = gpd.overlay(\n    buildings_proj, renabap_pba_intersect, how=\"intersection\"\n)\ntotal_buildings_per_settlement = (\n    buildings_settlement.groupby(\"id_renabap\")\n    .size()\n    .reset_index(name=\"total_buildings\")\n)\n\n# Get buildings intersected with hazard zones\nbuildings_hazard = gpd.overlay(\n    buildings_proj, settle_hazard_cuencas, how=\"intersection\"\n)\n\n# 1. Buildings per barrio-hazard (including non-hazard areas)\nbuildings_barrio_hazard = (\n    buildings_hazard.groupby([\"id_renabap\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\n\n# Calculate ratios using TOTAL buildings per settlement (not just hazard buildings)\nbarrio_ratios = buildings_barrio_hazard.merge(\n    total_buildings_per_settlement, on=\"id_renabap\"\n)\nbarrio_ratios[\"ratio\"] = (\n    barrio_ratios[\"buildings_count\"] / barrio_ratios[\"total_buildings\"]\n)\nbarrio_pop = renabap_pba_intersect[\n    [\"id_renabap\", \"familias_aproximadas\"]\n].drop_duplicates()\nbarrio_exposure = barrio_ratios.merge(barrio_pop, on=\"id_renabap\")\nbarrio_exposure[\"fam_expuestas\"] = (\n    barrio_exposure[\"ratio\"] * barrio_exposure[\"familias_aproximadas\"]\n)\n\n# Add non-hazard population for each settlement\nsettlements_with_hazards = barrio_exposure[\"id_renabap\"].unique()\nall_settlements = total_buildings_per_settlement[\"id_renabap\"].unique()\n\nfor settlement in all_settlements:\n    if settlement in settlements_with_hazards:\n        # Calculate non-hazard population\n        hazard_pop = barrio_exposure[barrio_exposure[\"id_renabap\"] == settlement][\n            \"fam_expuestas\"\n        ].sum()\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        non_hazard_pop = total_pop - hazard_pop\n\n        if non_hazard_pop &gt; 0:\n            barrio_exposure = pd.concat(\n                [\n                    barrio_exposure,\n                    pd.DataFrame(\n                        [\n                            {\n                                \"id_renabap\": settlement,\n                                \"PELIGROSID\": \"none\",\n                                \"buildings_count\": 0,\n                                \"total_buildings\": total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0],\n                                \"ratio\": (\n                                    total_buildings_per_settlement[\n                                        total_buildings_per_settlement[\"id_renabap\"]\n                                        == settlement\n                                    ][\"total_buildings\"].iloc[0]\n                                    - buildings_hazard[\n                                        buildings_hazard[\"id_renabap\"] == settlement\n                                    ].shape[0]\n                                )\n                                / total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                if total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                &gt; 0\n                                else 0,\n                                \"familias_aproximadas\": total_pop,\n                                \"fam_expuestas\": non_hazard_pop,\n                            }\n                        ]\n                    ),\n                ],\n                ignore_index=True,\n            )\n    else:\n        # Settlement with no hazard intersection - all population is non-hazard\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        barrio_exposure = pd.concat(\n            [\n                barrio_exposure,\n                pd.DataFrame(\n                    [\n                        {\n                            \"id_renabap\": settlement,\n                            \"PELIGROSID\": \"none\",\n                            \"buildings_count\": 0,\n                            \"total_buildings\": total_buildings_per_settlement[\n                                total_buildings_per_settlement[\"id_renabap\"]\n                                == settlement\n                            ][\"total_buildings\"].iloc[0],\n                            \"ratio\": 1.0,\n                            \"familias_aproximadas\": total_pop,\n                            \"fam_expuestas\": total_pop,\n                        }\n                    ]\n                ),\n            ],\n            ignore_index=True,\n        )\n\n# Create buildings tidy dataframe for barrio level using consolidated function\nbuildings_barrio_tidy = create_exposure_tidy_data(\n    data=barrio_exposure,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\",\n    exposure_values=barrio_exposure[\"fam_expuestas\"],\n    exclude_zero=False,  # Keep all values including zeros for completeness\n)\n\n# 2. Cuenca exposure - using total buildings across all settlements in cuenca\nbuildings_cuenca_hazard = (\n    buildings_hazard.groupby([\"Cuenca\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_cuenca_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"Cuenca\"]].drop_duplicates(),\n        on=\"id_renabap\",\n    )\n    .groupby(\"Cuenca\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\ncuenca_ratios = buildings_cuenca_hazard.merge(buildings_cuenca_total, on=\"Cuenca\")\ncuenca_ratios[\"ratio\"] = (\n    cuenca_ratios[\"buildings_count\"] / cuenca_ratios[\"total_buildings_all\"]\n)\n\ncuenca_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"Cuenca\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\ncuenca_exposure = cuenca_ratios.merge(cuenca_pop, on=\"Cuenca\")\ncuenca_exposure[\"fam_expuestas\"] = (\n    cuenca_exposure[\"ratio\"] * cuenca_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for cuenca level using consolidated function\nbuildings_cuenca_tidy = create_exposure_tidy_data(\n    data=cuenca_exposure,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\",\n    exposure_values=cuenca_exposure[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n# 3. Eje exposure - using total buildings across all settlements in eje\nbuildings_eje_hazard = (\n    buildings_hazard.groupby([\"eje\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_eje_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates(), on=\"id_renabap\"\n    )\n    .groupby(\"eje\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\neje_ratios = buildings_eje_hazard.merge(buildings_eje_total, on=\"eje\")\neje_ratios[\"ratio\"] = eje_ratios[\"buildings_count\"] / eje_ratios[\"total_buildings_all\"]\n\neje_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"eje\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\neje_exposure = eje_ratios.merge(eje_pop, on=\"eje\")\neje_exposure[\"fam_expuestas\"] = (\n    eje_exposure[\"ratio\"] * eje_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for eje level using consolidated function\nbuildings_eje_tidy = create_exposure_tidy_data(\n    data=eje_exposure,\n    id_column=\"eje\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\",\n    exposure_values=eje_exposure[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n\n### GHSL \n\n# Convert to the format expected by rasterstats\ngeometries = [geom for geom in renabap_pba_intersect.geometry]\n\n# Use rasterstats for vectorized zonal statistics\nstats = rasterstats.zonal_stats(\n    geometries,\n    ghsl_clipped.values[0],  # rasterstats expects 2D array\n    affine=ghsl_clipped.rio.transform(),\n    stats=[\"sum\"],\n    nodata=ghsl_clipped.rio.nodata,\n)\n\n# Extract the sum values\nghsl_totals = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n\n# Add the GHSL population estimates as a new column\nrenabap_pba_intersect[\"ghsl_pop_est\"] = ghsl_totals\n\n\n# Get the reference raster properties from GHSL data\nreference_raster = ghsl_clipped\nreference_transform = reference_raster.rio.transform()\nreference_crs = reference_raster.rio.crs\nreference_shape = reference_raster.shape[1:]  # Get 2D shape (height, width)\n\n\n# Prepare geometries and values for rasterization\ngeometries_ghsl = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"ghsl_pop_est\"]\n    )\n]\ngeometries_familias = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"familias_aproximadas\"]\n    )\n]\n\n# Create GHSL population raster\nghsl_pop_raster = rasterize(\n    geometries_ghsl,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Create familias aproximadas raster\nfamilias_raster = rasterize(\n    geometries_familias,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n\n# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n# Use masking to avoid division on invalid cells\nmask = (ghsl_clipped.values[0] != NODATA_VALUE) & (ghsl_pop_raster &gt; 0.1)\nghsl_fractional = np.full_like(ghsl_clipped.values[0], NODATA_VALUE, dtype=np.float64)\nghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n\n# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\nmask2 = (ghsl_fractional != NODATA_VALUE) & (familias_raster &gt; 0)\nfamilias_downscaled = np.full_like(\n    ghsl_clipped.values[0], NODATA_VALUE, dtype=np.float64\n)\nfamilias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n\n# Verify the results - exclude NODATA_VALUE from range calculations\nghsl_valid = ghsl_clipped.values[0] != NODATA_VALUE\nfractional_valid = ghsl_fractional != NODATA_VALUE\ndownscaled_valid = familias_downscaled != NODATA_VALUE\n\n# GHSL downscaling for all three levels using the same approach\n\n# 1. BARRIO-HAZARD EXPOSURE using consolidated approach\nghsl_barrio_exposure = []\nfor idx, row in settlement_hazard.iterrows():\n    stats = zonal_stats(\n        [row.geometry],\n        familias_downscaled,\n        affine=reference_transform,\n        stats=[\"sum\"],\n        nodata=NODATA_VALUE,\n    )[0]\n\n    ghsl_barrio_exposure.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"PELIGROSID\": row[\"PELIGROSID\"],\n            \"fam_expuestas\": stats[\"sum\"] if stats[\"sum\"] is not None else 0,\n        }\n    )\n\nghsl_barrio_temp = pd.DataFrame(ghsl_barrio_exposure)\nghsl_barrio_tidy = create_exposure_tidy_data(\n    data=ghsl_barrio_temp,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_barrio_temp[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n# 2. CUENCA-HAZARD EXPOSURE using consolidated approach\nghsl_cuenca_exposure = []\nfor cuenca in settle_hazard_cuencas[\"Cuenca\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this cuenca-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"Cuenca\"] == cuenca)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=NODATA_VALUE,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_cuenca_exposure.append(\n                {\n                    \"Cuenca\": cuenca,\n                    \"PELIGROSID\": peligro,\n                    \"fam_expuestas\": total_pop,\n                }\n            )\n\nghsl_cuenca_temp = pd.DataFrame(ghsl_cuenca_exposure)\nghsl_cuenca_tidy = create_exposure_tidy_data(\n    data=ghsl_cuenca_temp,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_cuenca_temp[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n# 3. EJE-HAZARD EXPOSURE using consolidated approach\nghsl_eje_exposure = []\nfor eje in settle_hazard_cuencas[\"eje\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this eje-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"eje\"] == eje)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=NODATA_VALUE,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_eje_exposure.append(\n                {\n                    \"eje\": eje,\n                    \"PELIGROSID\": peligro,\n                    \"fam_expuestas\": total_pop,\n                }\n            )\n\nghsl_eje_temp = pd.DataFrame(ghsl_eje_exposure)\nghsl_eje_tidy = create_exposure_tidy_data(\n    data=ghsl_eje_temp,\n    id_column=\"eje\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_eje_temp[\"fam_expuestas\"],\n    exclude_zero=False,\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#resultados",
    "href": "renabap.html#resultados",
    "title": "3  RENABAP",
    "section": "3.6 Resultados",
    "text": "3.6 Resultados\n\n3.6.1 Comparación de métodos\n\nMostrar código\n# 1. BARRIO-LEVEL WIDE DATAFRAME using consolidated function\nrenabap_info = renabap_pba_intersect[[\"id_renabap\", \"nombre_barrio\"]].drop_duplicates()\n\nbarrio_wide = create_wide_exposure_dataframe(\n    areal_data=barrio_areal_tidy,\n    ghsl_data=ghsl_barrio_tidy,\n    buildings_data=buildings_barrio_tidy,\n    id_columns=[\"id_renabap\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE,\n)\n\n# Add barrio names and reorder columns\nbarrio_wide = barrio_wide.merge(renabap_info, on=\"id_renabap\", how=\"left\")\nbarrio_wide = barrio_wide[\n    [\n        \"id_renabap\",\n        \"nombre_barrio\",\n        \"peligrosidad\",\n    ]\n    + EXPOSURE_COLUMNS\n]\n\n# 2. CUENCA-LEVEL WIDE DATAFRAME using consolidated function\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\nif len(multi_cuenca_settlements) &gt; 0:\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\n# Aggregate buildings data from barrio to cuenca level\ncuenca_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE]\n    .merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\n\n# Convert to tidy format for the consolidated function\ncuenca_buildings_tidy_for_merge = create_exposure_tidy_data(\n    data=cuenca_buildings_wide,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"peligrosidad\",\n    method_suffix=\"buildings\",\n    exposure_values=cuenca_buildings_wide[\"fam_expuestas_buildings\"],\n    exclude_zero=False,\n)\n\ncuenca_wide = create_wide_exposure_dataframe(\n    areal_data=cuenca_areal_tidy,\n    ghsl_data=ghsl_cuenca_tidy,\n    buildings_data=cuenca_buildings_tidy_for_merge,\n    id_columns=[\"Cuenca\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE,\n)\n\ncuenca_wide[\"cuenca\"] = cuenca_wide[\"Cuenca\"].str.lower()\ncuenca_wide = cuenca_wide[\n    [\n        \"cuenca\",\n        \"peligrosidad\",\n    ]\n    + EXPOSURE_COLUMNS\n]\n\n# 3. EJE-LEVEL WIDE DATAFRAME using consolidated function\nsettlement_eje_mapping = settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates()\neje_settlement_counts = settlement_eje_mapping[\"id_renabap\"].value_counts()\nmulti_eje_settlements = eje_settlement_counts[eje_settlement_counts &gt; 1].index\nif len(multi_eje_settlements) &gt; 0:\n    settlement_eje_mapping = settlement_eje_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\n# Aggregate buildings data from barrio to eje level\neje_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE]\n    .merge(settlement_eje_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\n\n# Convert to tidy format for the consolidated function\neje_buildings_tidy_for_merge = create_exposure_tidy_data(\n    data=eje_buildings_wide,\n    id_column=\"eje\",\n    peligrosidad_column=\"peligrosidad\",\n    method_suffix=\"buildings\",\n    exposure_values=eje_buildings_wide[\"fam_expuestas_buildings\"],\n    exclude_zero=False,\n)\n\neje_wide = create_wide_exposure_dataframe(\n    areal_data=eje_areal_tidy,\n    ghsl_data=ghsl_eje_tidy,\n    buildings_data=eje_buildings_tidy_for_merge,\n    id_columns=[\"eje\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE,\n)\n\neje_wide = eje_wide[\n    [\n        \"eje\",\n        \"peligrosidad\",\n    ]\n    + EXPOSURE_COLUMNS\n]\n\nbarrio_tidy = pd.melt(\n    barrio_wide,\n    id_vars=[\"id_renabap\", \"nombre_barrio\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\nbarrio_tidy[\"metodo\"] = barrio_tidy[\"metodo\"].str.replace(\n    COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\"\n)\n\nbarrio_tidy = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"geometry\"]], on=\"id_renabap\", how=\"left\"\n)\n\nbarrio_tidy[\"area\"] = barrio_tidy.geometry.apply(lambda geom: geom.area)\n\n\n# Group by id_renabap and peligro, then find which method has the highest fam_expuestas\nhighest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmax()\n\n# Get the method names for the highest estimates\nmethod_counts = barrio_tidy.loc[highest_methods, \"metodo\"].value_counts()\n\nplt.figure(figsize=(12, 7))\nsns.barplot(x=method_counts.index, y=method_counts.values, hue=method_counts.index, palette=\"viridis\", legend=False)\nplt.title(\n    \"Métodos que Más Frecuentemente Devuelven la Mayor Estimación de Familias Expuestas\",\n    fontsize=14,\n    fontweight=\"bold\",\n    pad=20,\n)\nplt.xlabel(\"Método\", fontsize=12, fontweight=\"bold\")\nplt.ylabel(\"Frecuencia\", fontsize=12, fontweight=\"bold\")\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.tight_layout()\nplt.show()\n\n\n# Group by id_renabap and peligro, then find which method has the lowest fam_expuestas\nlowest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmin()\n\n# Get the method names for the lowest estimates\nlowest_method_counts = barrio_tidy.loc[lowest_methods, \"metodo\"].value_counts()\n\n# Crear gráfico de barras para métodos con menor estimación\nplt.figure(figsize=(12, 7))\nsns.barplot(\n    x=lowest_method_counts.index, y=lowest_method_counts.values, hue=lowest_method_counts.index, palette=\"viridis\", legend=False\n)\nplt.title(\n    \"Métodos que Más Frecuentemente Devuelven la Menor Estimación de Familias Expuestas\",\n    fontsize=14,\n    fontweight=\"bold\",\n    pad=20,\n)\nplt.xlabel(\"Método\", fontsize=12, fontweight=\"bold\")\nplt.ylabel(\"Frecuencia\", fontsize=12, fontweight=\"bold\")\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.tight_layout()\nplt.show()\n\n\n# First, left join familias_aproximadas from renabap_pba_intersect\nfinal_tidy_with_pop = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"familias_aproximadas\"]],\n    on=\"id_renabap\",\n    how=\"left\",\n)\n\n# Calculate the range (highest - lowest) per id_renabap and peligro\nrange_by_barrio = final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].agg([\"max\", \"min\"])\nrange_by_barrio[\"range\"] = range_by_barrio[\"max\"] - range_by_barrio[\"min\"]\n\n# Merge back to get the total population for each barrio\nrange_by_barrio = range_by_barrio.reset_index().merge(\n    final_tidy_with_pop[[\"id_renabap\", \"familias_aproximadas\"]].drop_duplicates(),\n    on=\"id_renabap\",\n)\n\n# Calculate absolute percent difference as fraction of total barrio population\nrange_by_barrio[\"abs_pct_diff\"] = (\n    range_by_barrio[\"range\"] / range_by_barrio[\"familias_aproximadas\"]\n) * 100\n\n# Calculate average absolute percent difference per peligro level\navg_pct_diff_by_peligro = range_by_barrio.groupby(\"peligrosidad\")[\"abs_pct_diff\"].mean()\n\n# Calculate absolute percent difference by method\nmethod_errors = final_tidy_with_pop.copy()\n\n\n# Calculate absolute error as percent of total population for each method\nmethod_errors[\"abs_error_pct\"] = (\n    abs(\n        method_errors[\"fam_expuestas\"]\n        - method_errors.groupby([\"id_renabap\", \"peligrosidad\"])[\n            \"fam_expuestas\"\n        ].transform(\"mean\")\n    )\n    / method_errors[\"familias_aproximadas\"]\n    * 100\n)\n\n# Calculate coefficient of variation for each barrio-peligro combination\nbarrio_reliability = (\n    final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"])\n    .agg({\"fam_expuestas\": [\"mean\", \"std\"], \"familias_aproximadas\": \"first\"})\n    .reset_index()\n)\n\nbarrio_reliability.columns = [\n    \"id_renabap\",\n    \"peligrosidad\",\n    \"mean_estimate\",\n    \"std_estimate\",\n    \"familias_aproximadas\",\n]\nbarrio_reliability[\"coefficient_variation\"] = (\n    barrio_reliability[\"std_estimate\"] / barrio_reliability[\"mean_estimate\"]\n)\n\n# Create box plot\nplt.figure(figsize=(12, 3))\nsns.boxplot(\n    data=barrio_reliability,\n    y=\"peligrosidad\",\n    x=\"coefficient_variation\",\n    hue=\"peligrosidad\",\n    palette=\"viridis\",\n    legend=False,\n    width=0.4,\n)\nplt.title(\n    \"Variabilidad de Estimaciones entre Métodos\", fontsize=16, fontweight=\"bold\", pad=20\n)\nplt.ylabel(\"Peligrosidad\", fontsize=14, fontweight=\"bold\")\nplt.xlabel(\n    \"Coeficiente de Variación (0 = estimaciones idénticas, 1 = muy variables)\",\n    fontsize=12,\n    fontweight=\"bold\",\n)\nplt.tight_layout()\nplt.show()\n\n\n# Create scatter plot colored by peligrosidad\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio[range_by_barrio[\"peligrosidad\"] == peligro]\n\n    plt.scatter(\n        peligro_data[\"familias_aproximadas\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Familias Aproximadas (Total Barrio Population)\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Barrio Size (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# First, get the area data from final_tidy\narea_data = barrio_tidy[[\"id_renabap\", \"area\"]].drop_duplicates()\n\n# Merge area back into range_by_barrio\nrange_by_barrio_with_area = range_by_barrio.merge(\n    area_data, on=\"id_renabap\", how=\"left\"\n)\n\n\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio_with_area[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio_with_area[\n        range_by_barrio_with_area[\"peligrosidad\"] == peligro\n    ]\n\n    plt.scatter(\n        peligro_data[\"area\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Area\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Area (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n# Filter for high exposure (alta peligrosidad) using the joined dataframe\nalta_data = barrio_tidy[barrio_tidy[\"peligrosidad\"] == \"alta\"].copy()\n\n# Aggregate by nombre_barrio and sum fam_expuestas for each method\n# This handles cases where there are multiple geometries with the same barrio name\nalta_aggregated = (\n    alta_data.groupby([\"nombre_barrio\", \"metodo\"])[\"fam_expuestas\"].sum().reset_index()\n)\n\n# Remove cases where the barrio name is \"Sin Nombre\"\nalta_aggregated = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"] != \"Sin Nombre\"\n].copy()\n\n# Calculate total exposure per barrio across all methods\ntotal_exposure = (\n    alta_aggregated.groupby(\"nombre_barrio\")[\"fam_expuestas\"]\n    .sum()\n    .sort_values(ascending=False)\n)\ntop_10_barrios = total_exposure.head(10).index\n\n# Filter aggregated data for top 10 barrios\ntop_10_data = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"].isin(top_10_barrios)\n].copy()\n\n# Create range plot showing min, max, and individual points\nplt.figure(figsize=(14, 10))  # Increased height to accommodate longer barrio names\n\n\nfor i, barrio in enumerate(top_10_barrios):\n    barrio_data = top_10_data[top_10_data[\"nombre_barrio\"] == barrio]\n    if len(barrio_data) &gt; 0:\n        values = barrio_data[\"fam_expuestas\"].values\n        min_val = values.min()\n        max_val = values.max()\n\n        # Plot range line\n        plt.plot([min_val, max_val], [i, i], \"k-\", alpha=0.5, linewidth=2)\n\n        # Plot individual points colored by method\n        for _, row in barrio_data.iterrows():\n            color = METHOD_COLORS[row[\"metodo\"]]\n            plt.plot(row[\"fam_expuestas\"], i, \"o\", color=color, markersize=6, alpha=0.8)\n\nplt.yticks(range(len(top_10_barrios)), top_10_barrios)\nplt.xlabel(\"Familias Expuestas\")\nplt.ylabel(\"Barrio\")\nplt.title(\"Range of High Exposure Estimates for Top 10 Barrios\", fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# Add legend\nlegend_elements = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=color,\n        markersize=8,\n        label=method,\n    )\n    for method, color in METHOD_COLORS.items()\n]\nplt.legend(handles=legend_elements, title=\"Método\")\n\nplt.tight_layout()\nplt.show()\n\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_areal\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_exp_areal\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_exp_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_exp_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Discrepancia vs población total del barrio\n\n\n\n\n\n\n\n\n\n\n\n(b) Discrepancia vs área del barrio\n\n\n\n\n\n\n\n\n\n\n\n(c) Rango de estimaciones para barrios con mayor exposición\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n\n\n\n\n(f)\n\n\n\n\n\n\n\nFigure 3.2: Análisis comparativo de métodos de estimación por barrio\n\n\n\n\n\nMostrar código\ndef plot_method_map(\n    method_name,\n    final_tidy,\n    la_plata,\n    PELIGROSIDAD_COLORS,\n    common_bounds,\n    create_consistent_map,\n):\n    fig, ax = create_consistent_map(\n        f\"Barrios por población expuesta estimada - {method_name.capitalize()}\",\n        common_bounds,\n    )\n\n    method_data = final_tidy[\n        (final_tidy[\"metodo\"] == method_name)\n        & (final_tidy[\"peligrosidad\"].isin([\"alta\", \"media\"]))\n    ].copy()\n\n    method_gdf = gpd.GeoDataFrame(method_data, geometry=\"geometry\", crs=USE_CRS)\n    method_gdf = method_gdf.clip(la_plata)\n    method_gdf_3857 = method_gdf.to_crs(WEB_MERCATOR_CRS)\n\n    plotting_order = [\"media\", \"alta\"]\n\n    np.random.seed(42)\n    for peligrosidad in plotting_order:\n        level_data = method_gdf_3857[method_gdf_3857[\"peligrosidad\"] == peligrosidad]\n        for _, row in level_data.iterrows():\n            centroid = row[\"geometry\"].centroid\n            jitter_x = np.random.uniform(-200, 200)\n            jitter_y = np.random.uniform(-200, 200)\n            x_pos = centroid.x + jitter_x\n            y_pos = centroid.y + jitter_y\n            color = PELIGROSIDAD_COLORS[row[\"peligrosidad\"]]\n            size = max(10, row[\"fam_expuestas\"] * 2 + 15)\n            ax.scatter(\n                x_pos,\n                y_pos,\n                s=size,\n                color=color,\n                alpha=0.9,\n                edgecolors=\"white\",\n                linewidth=1.0,\n            )\n\n    legend_elements = [\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"o\",\n            color=\"w\",\n            markerfacecolor=color,\n            markersize=8,\n            label=level.capitalize(),\n        )\n        for level, color in PELIGROSIDAD_COLORS.items()\n    ]\n    ax.legend(handles=legend_elements, title=\"Nivel de Peligrosidad\", loc=\"upper right\")\n    plt.tight_layout()\n    plt.show()\n\n\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_areal\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_exp_areal\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_exp_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_exp_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n\n\n3.6.2 Exposición por barrio\n\nMostrar código\nmethods = barrio_tidy[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        barrio_tidy,\n        la_plata,\n        PELIGROSIDAD_COLORS,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.3: Comparación de métodos de estimación de exposición por barrio\n\n\n\n\n\nMostrar código\nshow(round_numeric_columns(barrio_summary))\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.3 Exposición por cuenca\n\nMostrar código\ncuencas_centroids = cuencas.copy()\ncuencas_centroids[\"geometry\"] = cuencas_centroids[\"geometry\"].centroid\n\n# Create a lowercase version of Cuenca for matching\ncuencas_centroids[\"cuenca_lower\"] = cuencas_centroids[\"Cuenca\"].str.lower()\n\ncuenca_tidy = pd.melt(\n    cuenca_wide,\n    id_vars=[\"cuenca\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\ncuenca_tidy[\"metodo\"] = cuenca_tidy[\"metodo\"].str.replace(\n    COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\"\n)\n\ncuenca_tidy_with_geometry = cuenca_tidy.merge(\n    cuencas_centroids[[\"cuenca_lower\", \"geometry\"]],\n    left_on=\"cuenca\",\n    right_on=\"cuenca_lower\",\n    how=\"left\",\n)\n\ncuenca_tidy_gdf = gpd.GeoDataFrame(\n    cuenca_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = cuenca_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        cuenca_tidy_gdf,\n        la_plata,\n        PELIGROSIDAD_COLORS,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.4: Comparación de métodos de estimación de exposición por cuenca\n\n\n\n\n\nMostrar código\nshow(round_numeric_columns(cuenca_wide))\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.4 Exposición por eje\n\nMostrar código\neje_tidy = pd.melt(\n    eje_wide,\n    id_vars=[\"eje\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\neje_tidy[\"metodo\"] = eje_tidy[\"metodo\"].str.replace(\n    COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\"\n)\n\n# Create eje geodataframe by dissolving cuencas by eje and then taking centroids\nejes = cuencas.dissolve(by=\"eje\").reset_index()\nejes_centroids = ejes.copy()\nejes_centroids[\"geometry\"] = ejes_centroids[\"geometry\"].centroid\n\neje_tidy_with_geometry = eje_tidy.merge(\n    ejes_centroids[[\"eje\", \"geometry\"]], on=\"eje\", how=\"left\"\n)\n\neje_tidy_gdf = gpd.GeoDataFrame(\n    eje_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = eje_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        eje_tidy_gdf,\n        la_plata,\n        PELIGROSIDAD_COLORS,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.5: Comparación de métodos de estimación de exposición por eje de cuenca\n\n\n\n\n\nMostrar código\nshow(round_numeric_columns(eje_wide))\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#conclusiones",
    "href": "renabap.html#conclusiones",
    "title": "3  RENABAP",
    "section": "3.8 Conclusiones",
    "text": "3.8 Conclusiones\nLos datos de huellas de edificios nos permiten realizar evaluaciones significativamente más precisas de la exposición en asentamientos informales en todo el partido y revelan una subestimación crítica en los datos oficiales. Este análisis identifica aproximadamente 41,000 viviendas faltantes que no están contabilizadas en los datos del RENABAP, lo que representa potencialmente entre 120,000 y 205,000 personas no contabilizadas en los asentamientos informales (usando un rango razonable de 3 a 5 personas por vivienda). Esta discrepancia tiene implicaciones profundas para la planificación de gestión de riesgo y la asignación de recursos.\nNuestros resultados muestran que Villa Montoro presenta el mayor número de edificios expuestos a peligro alto con 555 edificios, seguido por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. A nivel de cuencas hidrográficas, la Cuenca Arroyo del Gato concentra la mayor exposición con 2,662 edificios expuestos a peligro alto, seguida por la Cuenca A° Maldonado con 1,000. En términos de ejes territoriales, el central presenta 2,662 edificios expuestos y el sudoeste 1,000.\nEste enfoque basado en edificios no solo proporciona estimaciones más precisas y actualizadas que los métodos tradicionales de interpolación areal, sino que también demuestra la necesidad urgente de actualizar los registros oficiales de asentamientos informales. Los datos globales de huellas de edificios representan una herramienta esencial para comprender la verdadera magnitud de la población en riesgo y para la planificación efectiva de políticas de reducción de riesgo de inundación.\n\n\n\n\nRomanazzi, Pablo et al. 2019. Plan de Reducción Del Riesgo Por Inundaciones En La Región de La Plata. Edited by Sebastián Guerrini, Pablo Morosi, Eduardo Pablo Spinelli, and Josefina López MacKenzie. 1st ed. La Plata: Universidad Nacional de La Plata. Facultad de Ingeniería; Municipalidad de La Plata. https://sedici.unlp.edu.ar/bitstream/handle/10915/165109/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of Flood Exposure in Developing Countries Using High-Resolution Population Data.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by VIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "twi.html",
    "href": "twi.html",
    "title": "4  TWI y HAND",
    "section": "",
    "text": "4.1 Resumen\nEste documento evalúa dos métricas topográficas simples para el mapeo de peligro de inundación: el Índice de Humedad Topográfica (TWI) y la Altura Sobre Drenaje Más Cercano (HAND). Utilizando el Partido de La Plata como caso de estudio, desarrollamos ambos índices mediante metodologías consolidadas con datos de elevación FABDEM de acceso libre y las bibliotecas pysheds y xDEM. Los resultados se contrastan con modelado hidrológico oficial disponible de la Facultad de Ingeniería como punto de comparación, evidenciando que tanto el TWI como el HAND representan alternativas viables para contextos con limitaciones de datos donde no existe modelado hidrológico avanzado disponible. Ambos enfoques, respaldados científicamente pero con limitaciones reconocidas, constituyen soluciones prácticas para evaluaciones preliminares de riesgo de inundación a escala municipal cuando se carece de información más detallada.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TWI y HAND</span>"
    ]
  },
  {
    "objectID": "twi.html#introducción",
    "href": "twi.html#introducción",
    "title": "4  TWI y HAND",
    "section": "4.2 Introducción",
    "text": "4.2 Introducción\n\n4.2.1 ¿Qué es el TWI?\nEl TWI es un índice establecido que combina la pendiente del terreno con el área de drenaje aguas arriba para identificar zonas propensas a la acumulación de agua e inundaciones. Calcula valores distribuidos espacialmente donde números más altos indican mayor potencial de encharcamiento y valores más bajos sugieren condiciones más secas. Es una herramienta ampliamente reconocida en hidrología para modelar condiciones de humedad del paisaje (Atlas 2025).\n\n\n4.2.2 ¿Qué es HAND?\nHAND (Altura Sobre Drenaje Más Cercano) es un descriptor cuantitativo del terreno que representa la diferencia de elevación entre cada pixel en la ladera y el punto más cercano en la red de drenaje hacia donde fluye (Johnson et al. 2019). Este método ha sido ampliamente utilizado para la predicción de extensión de inundaciones porque produce resultados comparables a marcos de modelado más complejos como HEC-RAS, pero con menores requerimientos computacionales (Johnson et al. 2019). HAND ha demostrado ser especialmente efectivo como indicador computacionalmente eficiente de susceptibilidad a inundaciones, requiriendo únicamente datos topográficos como entrada (Watson et al. 2024).\n\n\n4.2.3 ¿Por qué usar estas métricas?\nTanto el TWI como HAND son métodos establecidos que han demostrado su validez científica en múltiples aplicaciones. El TWI ha sido utilizado por agencias como el Illinois State Water Survey para identificar áreas urbanas con riesgo de inundación (Ballerine 2017), mientras que HAND ha sido implementado por el Centro Nacional del Agua de Estados Unidos para mapeo de inundaciones a escala nacional (Johnson et al. 2019). La principal ventaja de ambas métricas es que proporcionan información valiosa sobre riesgo de inundaciones a un costo extremadamente bajo comparado con estudios hidrológicos detallados. Son gratuitos, rápidos de calcular usando datos topográficos que suelen estar disponibles, y fáciles de interpretar, convirtiéndolos en excelentes herramientas de planificación inicial. Estudios recientes han demostrado que estas metodologías pueden replicar mapas de inundación de alta resolución como indicadores de susceptibilidad a inundaciones (Watson et al. 2024; Li et al. 2023).\n\n\n4.2.4 Limitaciones\nEs fundamental entender que tanto el TWI como HAND son medidas derivadas puramente del terreno y no consideran factores como infraestructura urbana, sistemas de drenaje, vegetación, o patrones climáticos locales. Por tanto, son herramientas que solo proporcionan una noción del riesgo relativo de inundación. No deben utilizarse para tomar decisiones a nivel de parcela específica. Para HAND específicamente, las diferencias en las características del terreno y las incertidumbres asociadas con la estimación óptima de parámetros pueden afectar la precisión de los resultados (Thalakkottukara et al. 2024). Ambas métricas se correlacionan principalmente con flujo superficial y no pueden capturar interacciones complejas con aguas subterráneas o la dinámica completa de sistemas hidrológicos urbanos.\n\n\n4.2.5 Uso apropiado\nLas investigaciones han confirmado que existe correlación entre valores altos de TWI y reportes ciudadanos de inundaciones urbanas menores, validando su utilidad en contextos urbanizados (Kelleher and McPhillips 2020). Similarmente, HAND ha demostrado ser adecuado para el mapeo de inundaciones en regiones con escasez de datos, proporcionando capacidad predictiva comparable para mapear áreas de inundación durante eventos de lluvia extrema (Thalakkottukara et al. 2024). Ambas métricas son especialmente valiosas para gobiernos municipales con recursos limitados como primera aproximación para identificar áreas de riesgo relativo de inundaciones, desarrollar planes de emergencia y priorizar estudios más detallados en zonas críticas. Proporcionan un punto de partida sólido y científicamente respaldado para la gestión del riesgo de inundaciones sin requerir inversión significativa en estudios especializados.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TWI y HAND</span>"
    ]
  },
  {
    "objectID": "twi.html#herramientas",
    "href": "twi.html#herramientas",
    "title": "4  TWI y HAND",
    "section": "4.3 Herramientas",
    "text": "4.3 Herramientas\n\n4.3.1 PySHEDS\n“Pysheds es una biblioteca de Python de código abierto diseñada por Matt Bartos para ayudar con el procesamiento de modelos digitales de elevación (DEMs), particularmente para análisis hidrológico. Pysheds realiza muchas de las funciones hidrológicas básicas ofrecidas por software comercial como ArcGIS, incluyendo delineación de cuencas y cálculo de acumulación.” Aquí, utilizamos PySheds para calcular la acumulación de flujo, que se incorpora en nuestro cálculo del TWI.\n\n\n4.3.2 xDEM\nxDEM “fue creado por un grupo de investigadores con experiencia en análisis de datos de elevación para detección de cambios aplicado a glaciología. Hoy en día, su desarrollo es liderado conjuntamente por investigadores en análisis de datos de elevación (incluyendo financiamiento de NASA y SNSF) e ingenieros de CNES (Agencia Espacial Francesa).” Utilizamos xDEM para todo nuestro procesamiento y cálculos de modelos digitales de elevación más allá de la acumulación de flujo.\n\n\n4.3.3 FABDEM 30m\nFathom, líder de la industria en modelado global de inundaciones, creó FABDEM específicamente para el desarrollo de sus modelos. A diferencia de otros modelos que conservan la altura de construcciones y vegetación, este utiliza técnicas de inteligencia artificial para eliminar dichas interferencias y mostrar únicamente la topografía del suelo (Hawker et al. 2022). Su desarrollo involucró datos de referencia de alta precisión provenientes de doce países con características climáticas y urbanas diversas, lo que garantiza su aplicabilidad en distintos contextos geográficos. Los datos están disponibles para descarga en este enlace. Para nuestros propósitos, FABDEM resulta especialmente valioso dado que las investigaciones han demostrado que la calidad del modelo de elevación constituye el factor más influyente en la precisión del modelado de riesgo de inundaciones. Al eliminar las distorsiones causadas por elementos como edificaciones y árboles, este modelo nos permite obtener cálculos de TWI más precisos y representativos de las condiciones reales del terreno, aspecto crucial para la planificación municipal del riesgo de inundaciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TWI y HAND</span>"
    ]
  },
  {
    "objectID": "twi.html#análisis",
    "href": "twi.html#análisis",
    "title": "4  TWI y HAND",
    "section": "4.4 Análisis",
    "text": "4.4 Análisis\n\n4.4.1 Importar datos\nEn esta sección importamos los datos de elevación FABDEM. Hemos descargado previamente los tiles necesarios para cubrir el área del Partido de La Plata y los importamos usando rioxarray para crear un modelo digital de elevación fusionado que servirá como base para nuestros cálculos hidrológicos.\n\n\nMostrar código\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nimport xarray as xr\nimport rioxarray\nfrom rioxarray.merge import merge_arrays\nimport xdem\nimport tempfile\nimport numpy as np\nfrom matplotlib import colors\nimport leafmap.leafmap as leafmap\nfrom pysheds.grid import Grid\nfrom jenkspy import jenks_breaks\n\nCRS_ARGENTINA = \"EPSG:5349\"\nCRS_WGS84 = \"EPSG:4326\"\n\nRUTA_BASE = Path(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo\")\nRUTA_DATOS = RUTA_BASE / \"notebooks/data\"\nRUTA_PARTIDOS = RUTA_DATOS / \"pba_partidos.geojson\"\n\nCMAP = \"BuPu\"\n\npartidos = gpd.read_file(RUTA_PARTIDOS)\npartidos = partidos.to_crs(CRS_ARGENTINA)\nla_plata = partidos[partidos[\"fna\"] == \"Partido de La Plata\"]\n\n# Quitar la isla de La Plata - mantener solo el polígono más grande\ngeometria_principal = la_plata.geometry.iloc[0]\nif geometria_principal.geom_type == \"MultiPolygon\":\n    poligono_mayor = max(geometria_principal.geoms, key=lambda p: p.area)\n    la_plata = la_plata.copy()\n    la_plata.loc[la_plata.index[0], \"geometry\"] = poligono_mayor\n\nbbox_la_plata_4326 = la_plata.to_crs(CRS_WGS84).total_bounds\n\nrutas_tiles = [\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S35W058_FABDEM_V1-2.tif\",\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S36W058_FABDEM_V1-2.tif\",\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S35W059_FABDEM_V1-2.tif\",\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S36W059_FABDEM_V1-2.tif\",\n]\n\ntiles = [rioxarray.open_rasterio(path, chunks=True) for path in rutas_tiles]\ndem_fusionado = merge_arrays(tiles)\n\ndem_recortado = dem_fusionado.rio.clip_box(\n    minx=bbox_la_plata_4326[0],\n    miny=bbox_la_plata_4326[1],\n    maxx=bbox_la_plata_4326[2],\n    maxy=bbox_la_plata_4326[3],\n)\n\ndem_recortado.plot(cmap=CMAP)\nax = plt.gca()\nla_plata_wgs84 = la_plata.to_crs(CRS_WGS84)\nla_plata_wgs84.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)\n\n\n\n\n\n\n\n\n\n\n\n4.4.2 Calcular acumulación de flujo\nCalculamos la acumulación de flujo, que es esencial para el cálculo del índice de humedad topográfica, siguiendo el tutorial de pysheds. No calculamos esto usando xarray porque pysheds no es compatible con xarray, pero luego convertiremos estos datos a xarray para nuestro cálculo del TWI. El proceso incluye acondicionar el DEM eliminando pozos y depresiones, calcular direcciones de flujo, y finalmente determinar la acumulación de flujo.\n\n\nMostrar código\nwith tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False) as tmp_file:\n    ruta_temporal = tmp_file.name\n\n\ndem_recortado.rio.to_raster(ruta_temporal)\ngrilla = Grid.from_raster(ruta_temporal)\n\ndem = grilla.read_raster(ruta_temporal)\n\nvalor_nodata = dem_recortado.attrs.get(\"_FillValue\", -9999.0)\n\n# Acondicionar DEM\ndem_pozos_rellenos = grilla.fill_pits(dem)\ndem_inundado = grilla.fill_depressions(dem_pozos_rellenos)\ndem_inflado = grilla.resolve_flats(dem_inundado)\n\n\ndem_inflado_xarray = xr.DataArray(\n    dem_inflado,\n    coords={\"y\": dem_recortado.y, \"x\": dem_recortado.x},\n    dims=[\"y\", \"x\"],\n    attrs=dem_recortado.attrs,\n).rio.write_crs(\"EPSG:4326\")\n\n\nmapa_direcciones = (64, 128, 1, 2, 4, 8, 16, 32)\n\n\ndirecciones_flujo = grilla.flowdir(\n    dem_inflado, dirmap=mapa_direcciones, nodata_out=np.int32(0)\n)\n\ndirecciones_flujo_xarray = xr.DataArray(\n    direcciones_flujo,\n    coords={\"y\": dem_recortado.y, \"x\": dem_recortado.x},\n    dims=[\"y\", \"x\"],\n    attrs=dem_recortado.attrs,\n).rio.write_crs(\"EPSG:4326\")\n\n\nacumulacion = grilla.accumulation(\n    direcciones_flujo, dirmap=mapa_direcciones, nodata_out=np.int32(0)\n)\n\n\nacumulacion_xarray = xr.DataArray(\n    acumulacion,\n    coords={\"y\": dem_recortado.y, \"x\": dem_recortado.x},\n    dims=[\"y\", \"x\"],\n    attrs=dem_recortado.attrs,\n).rio.write_crs(\"EPSG:4326\")\n\nfig, ax = plt.subplots(figsize=(8, 6))\nfig.patch.set_alpha(0)\nplt.grid(\"on\", zorder=0)\nim = ax.imshow(\n    acumulacion,\n    extent=grilla.extent,\n    zorder=2,\n    cmap=CMAP,\n    norm=colors.LogNorm(1, acumulacion.max()),\n    interpolation=\"bilinear\",\n)\nplt.colorbar(im, ax=ax, label=\"Celdas Aguas Arriba\")\n\nla_plata_wgs84.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)\nplt.title(\"Acumulación de Flujo\", size=14)\nplt.xlabel(\"Longitud\")\nplt.ylabel(\"Latitud\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n4.4.3 Calcular pendiente\nCalculamos la pendiente, otra variable necesaria para el cálculo del índice de humedad topográfica, siguiendo el tutorial de xDEM. La pendiente es un componente fundamental de la fórmula del TWI y debe calcularse con precisión en un sistema de coordenadas métricas para obtener resultados confiables.\n\n\nMostrar código\nwith tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False) as tmp_file:\n    ruta_temporal = tmp_file.name\n    \n    dem_reproyectado = dem_recortado.rio.reproject(\n        CRS_ARGENTINA,\n        resolution=30,\n    )\n    dem_reproyectado.rio.to_raster(ruta_temporal)\n    dem = xdem.DEM(ruta_temporal)\n    \n    atributos = xdem.terrain.get_terrain_attribute(\n        dem.data,\n        resolution=dem.res,\n        attribute=[\n            \"hillshade\",\n            \"slope\", \n            \"aspect\",\n            \"curvature\",\n            \"terrain_ruggedness_index\",\n            \"rugosity\",\n        ],\n    )\n    \n    datos_pendiente = atributos[1]\n    \n    # Fix coordinate generation - y should go from top to bottom\n    coordenadas_y = np.arange(dem.bounds.top, dem.bounds.bottom, -dem.res[1])\n    coordenadas_x = np.arange(dem.bounds.left, dem.bounds.right, dem.res[0])\n    \n    pendiente_xarray = xr.DataArray(\n        datos_pendiente,\n        coords={\"y\": coordenadas_y, \"x\": coordenadas_x},\n        dims=[\"y\", \"x\"],\n        attrs={\"crs\": dem.crs, \"units\": \"degrees\", \"long_name\": \"slope\"},\n    )\n\n    pendiente_xarray.plot(cmap=CMAP)\n    ax = plt.gca()\n    la_plata.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n    )\n\n\n\n\n\n\n\n\n\n\n\n4.4.4 Calcular TWI\nCombinamos la acumulación de flujo y la pendiente para calcular el índice de humedad topográfica usando la fórmula estándar TWI = ln(α / tan(β)), donde α es la acumulación de flujo y β es la pendiente. Ajustamos los valores extremos que surgen de dividir por pendiente cero para evitar valores infinitos en áreas completamente planas.\n\n\nMostrar código\nacumulacion_xarray_reproyectada = acumulacion_xarray.rio.reproject(CRS_ARGENTINA)\n\n# Remuestrear pendiente para coincidir con acumulación\npendiente_remuestreada = pendiente_xarray.rio.reproject(\n    acumulacion_xarray_reproyectada.rio.crs,\n    shape=acumulacion_xarray_reproyectada.shape,\n    transform=acumulacion_xarray_reproyectada.rio.transform(),\n)\n\npendiente_rad = np.radians(pendiente_remuestreada)\ndatos_twi = np.log(acumulacion_xarray_reproyectada / np.tan(pendiente_rad))\n\n# Reemplazar valores infinitos y valores muy altos\ndatos_twi = np.where(np.isinf(datos_twi), 25, datos_twi)\ndatos_twi = np.where(datos_twi &gt; 25, 25, datos_twi)\n\ntwi_xarray = xr.DataArray(\n    datos_twi,\n    coords=acumulacion_xarray_reproyectada.coords,\n    dims=acumulacion_xarray_reproyectada.dims,\n    attrs={\n        \"crs\": acumulacion_xarray_reproyectada.rio.crs,\n        \"units\": \"dimensionless\",\n        \"long_name\": \"Topographic Wetness Index\",\n        \"description\": \"ln(flow_accumulation / tan(slope + 0.0001))\",\n    },\n)\n\nplt.figure()\ntwi_xarray.plot(cmap=CMAP)\nax = plt.gca()\nla_plata.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)\n\n\n\n\n\n\n\n\n\n\n\nMostrar código\nhand = grilla.compute_hand(\n    direcciones_flujo, dem_inflado, acumulacion &gt; 200, nodata_value=np.int32(0)\n)\n\nhand_xarray = xr.DataArray(\n    hand,\n    coords={\"y\": dem_recortado.y, \"x\": dem_recortado.x},\n    dims=[\"y\", \"x\"],\n    attrs={\n        \"crs\": \"EPSG:4326\",\n        \"units\": \"meters\",\n        \"long_name\": \"Height Above Nearest Drainage\",\n        \"description\": \"HAND - Altura Sobre Drenaje Más Cercano\"\n    },\n).rio.write_crs(\"EPSG:4326\")\n\nhand_xarray.plot(cmap=CMAP, figsize=(8, 6))\nax = plt.gca()\nla_plata_wgs84.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)\nplt.title(\"Altura Sobre Drenaje Más Cercano (HAND)\", size=14)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n4.4.5 Análisis de distribuciones\nPara comprender mejor las características de nuestras métricas, analizamos las distribuciones de valores de TWI y HAND mediante histogramas. Esto nos permite identificar los rangos típicos de valores y la forma de la distribución para cada métrica.\n\n\nMostrar código\n# Preparar HAND con transformación de doble raíz cuadrada\nhand_xarray_reproyectada = hand_xarray.rio.reproject(CRS_ARGENTINA)\nhand_double_sqrt_full = np.sqrt(np.sqrt(hand_xarray_reproyectada))\nhand_double_sqrt_mask = hand_double_sqrt_full.rio.clip(la_plata.geometry, la_plata.crs, drop=False, invert=False)\nhand_double_sqrt_mask = xr.where(~hand_double_sqrt_mask.isnull(), 1, 0)\nhand_double_sqrt_masked = xr.where(hand_double_sqrt_mask == 1, hand_double_sqrt_full, np.nan)\nhand_double_sqrt_masked = hand_double_sqrt_masked.rio.write_crs(hand_double_sqrt_full.rio.crs)\nhand_double_sqrt_masked = hand_double_sqrt_masked.rio.write_transform(hand_double_sqrt_full.rio.transform())\n\n# Preparar TWI\ntwi_mask = twi_xarray.rio.clip(la_plata.geometry, la_plata.crs, drop=False, invert=False)\ntwi_mask = xr.where(~twi_mask.isnull(), 1, 0)\ntwi_masked = xr.where(twi_mask == 1, twi_xarray, np.nan)\ntwi_masked = twi_masked.rio.write_crs(twi_xarray.rio.crs)\ntwi_masked = twi_masked.rio.write_transform(twi_xarray.rio.transform())\n\n# Preparar datos válidos para histogramas\ntwi_values = twi_masked.values[~np.isnan(twi_masked.values)]\nhand_original = hand_xarray_reproyectada.values[~np.isnan(hand_xarray_reproyectada.values)]\nhand_double_sqrt = np.sqrt(np.sqrt(hand_original))\n\n# Calcular cortes de cuantiles\ntwi_quantiles = np.percentile(twi_values, [25, 50, 75])\nhand_double_sqrt_quantiles = np.percentile(hand_double_sqrt, [25, 50, 75])\n\n# Obtener colormap para usar los mismos colores que en los mapas\nimport matplotlib.cm as cm\ncmap = cm.get_cmap(CMAP)\ncmap_colors = [cmap(i/3) for i in range(4)]  # 4 colores del colormap\n\n# Función para asignar colores por cuantiles usando CMAP\ndef assign_quantile_colors_cmap(values, quantiles):\n    colors = []\n    for val in values:\n        if val &lt;= quantiles[0]:\n            colors.append(cmap_colors[0])  # Q1\n        elif val &lt;= quantiles[1]:\n            colors.append(cmap_colors[1])  # Q2\n        elif val &lt;= quantiles[2]:\n            colors.append(cmap_colors[2])  # Q3\n        else:\n            colors.append(cmap_colors[3])  # Q4\n    return colors\n\n# Crear figura con subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Histograma TWI con colores por cuantiles\nn_bins = 50\ncounts1, bins1, patches1 = ax1.hist(twi_values, bins=n_bins, alpha=0.8, edgecolor='black')\nbin_centers1 = (bins1[:-1] + bins1[1:]) / 2\ncolors1 = assign_quantile_colors_cmap(bin_centers1, twi_quantiles)\nfor patch, color in zip(patches1, colors1):\n    patch.set_facecolor(color)\n\nax1.set_xlabel('Valores TWI')\nax1.set_ylabel('Frecuencia')\nax1.set_title('Distribución TWI con Cortes de Cuantiles')\nax1.grid(True, alpha=0.3)\n\n# Agregar líneas de cuantiles\nfor i, q in enumerate(twi_quantiles):\n    ax1.axvline(q, color='black', linestyle='--', linewidth=2, alpha=0.7)\n    ax1.text(q, ax1.get_ylim()[1]*0.9, f'Q{i+1}', rotation=90, ha='right')\n\n# Histograma HAND (double sqrt) con colores por cuantiles\ncounts2, bins2, patches2 = ax2.hist(hand_double_sqrt, bins=n_bins, alpha=0.8, edgecolor='black')\nbin_centers2 = (bins2[:-1] + bins2[1:]) / 2\ncolors2 = assign_quantile_colors_cmap(bin_centers2, hand_double_sqrt_quantiles)\nfor patch, color in zip(patches2, colors2):\n    patch.set_facecolor(color)\n\nax2.set_xlabel('Valores HAND (√√metros)')\nax2.set_ylabel('Frecuencia')\nax2.set_title('Distribución HAND (Doble Raíz Cuadrada) con Cortes de Cuantiles')\nax2.grid(True, alpha=0.3)\n\n# Agregar líneas de cuantiles\nfor i, q in enumerate(hand_double_sqrt_quantiles):\n    ax2.axvline(q, color='black', linestyle='--', linewidth=2, alpha=0.7)\n    ax2.text(q, ax2.get_ylim()[1]*0.9, f'Q{i+1}', rotation=90, ha='right')\n\n# Crear leyenda común usando los colores del CMAP\nfrom matplotlib.patches import Patch\nlegend_elements = [\n    Patch(facecolor=cmap_colors[0], label='Q1 (0-25%)'),\n    Patch(facecolor=cmap_colors[1], label='Q2 (25-50%)'),\n    Patch(facecolor=cmap_colors[2], label='Q3 (50-75%)'),\n    Patch(facecolor=cmap_colors[3], label='Q4 (75-100%)')\n]\nfig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.95), ncol=4)\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.85)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TWI y HAND</span>"
    ]
  },
  {
    "objectID": "twi.html#comparativa-de-modelación-flo-2d-y-twi",
    "href": "twi.html#comparativa-de-modelación-flo-2d-y-twi",
    "title": "4  Índice de Humedad Topográfica",
    "section": "4.5 Comparativa de modelación FLO-2D y TWI",
    "text": "4.5 Comparativa de modelación FLO-2D y TWI\nDisponemos de datos oficiales de peligro de inundación desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata (Romanazzi et al. 2019). Estos datos fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que simuló la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. La comparación visual entre nuestros resultados del TWI y estos mapas oficiales de peligrosidad permite evaluar qué tan bien corresponde este índice topográfico simple con el modelado hidráulico más completo.\nPara mejorar la comparabilidad entre ambos enfoques, aplicamos cortes de Jenks con cuatro clases al TWI para aproximar las zonas de peligro alto, medio, bajo y muy bajo/nulo que se encuentran en la capa de peligrosidad del departamento de ingeniería. Esta técnica de clasificación permite una mejor comparación visual entre ambos enfoques metodológicos y facilita la identificación de correspondencias espaciales.\nUn aspecto importante a considerar es que existen diferencias metodológicas fundamentales entre ambos enfoques. El modelado de ingeniería toma en cuenta la infraestructura urbana, especialmente el sistema de calles de la ciudad y elementos del drenaje urbano, mientras que el TWI se basa únicamente en la topografía del terreno.\n\n\nMostrar código\nruta_peligro = RUTA_DATOS / \"peligro_raster_10m.tif\"\npeligro_xarray = rioxarray.open_rasterio(ruta_peligro)\n\nla_plata_centroid = la_plata.to_crs(CRS_WGS84).centroid.iloc[0]\ncenter_lat = la_plata_centroid.y\ncenter_lon = la_plata_centroid.x\n\nhand_xarray_reproyectada = hand_xarray.rio.reproject(CRS_ARGENTINA)\nhand_log = np.log(hand_xarray_reproyectada + 1)\nhand_mask = hand_log.rio.clip(la_plata.geometry, la_plata.crs, drop=False, invert=False)\nhand_mask = xr.where(~hand_mask.isnull(), 1, 0)\nhand_masked = xr.where(hand_mask == 1, hand_log, np.nan)\nhand_masked = hand_masked.rio.write_crs(hand_log.rio.crs)\nhand_masked = hand_masked.rio.write_transform(hand_log.rio.transform())\n\ntwi_mask = twi_xarray.rio.clip(la_plata.geometry, la_plata.crs, drop=False, invert=False)\ntwi_mask = xr.where(~twi_mask.isnull(), 1, 0)\ntwi_masked = xr.where(twi_mask == 1, twi_xarray, np.nan)\ntwi_masked = twi_masked.rio.write_crs(twi_xarray.rio.crs)\ntwi_masked = twi_masked.rio.write_transform(twi_xarray.rio.transform())\n\ntwi_valid = twi_masked.values[~np.isnan(twi_masked.values)]\nsample_size = min(10000, len(twi_valid))\ntwi_sample = np.random.choice(twi_valid, size=sample_size, replace=False)\nbreaks = jenks_breaks(twi_sample, n_classes=4)\ntwi_jenks = xr.where(twi_masked &lt;= breaks[1], 1,\n                     xr.where(twi_masked &lt;= breaks[2], 2,\n                              xr.where(twi_masked &lt;= breaks[3], 3, 4)))\ntwi_jenks = xr.where(~twi_masked.isnull(), twi_jenks, np.nan)\ntwi_jenks = twi_jenks.rio.write_crs(twi_xarray.rio.crs)\ntwi_jenks = twi_jenks.rio.write_transform(twi_xarray.rio.transform())\n\npeligro_2d = peligro_xarray.sel(band=1).astype('float32')\npeligro_clipped = peligro_2d.rio.clip(la_plata.geometry, la_plata.crs)\n\nm = leafmap.Map(center=[center_lat, center_lon], zoom=9)\nm.add_tile_layer(\n    url=\"https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}\",\n    name=\"Google Satellite\",\n    attribution=\"Google\",\n)\n\nm.add_raster(twi_masked, colormap=CMAP, layer_name=\"TWI\", nodata=np.nan)\nm.add_raster(twi_jenks, colormap=CMAP, layer_name=\"TWI Jenks (4 clases)\", nodata=np.nan)\nm.add_raster(hand_masked, colormap=CMAP + \"_r\", layer_name=\"HAND\", nodata=np.nan)\nm.add_raster(peligro_clipped, colormap=CMAP, layer_name=\"Peligrosidad\", nodata=peligro_clipped.rio.nodata)\n\nla_plata_geojson = la_plata.to_crs(CRS_WGS84).__geo_interface__\nm.add_geojson(\n    la_plata_geojson,\n    layer_name=\"Partido de La Plata\",\n    style={\"color\": \"black\", \"weight\": 2, \"fillOpacity\": 0},\n)\n\nm.add_layer_control()\nm",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica</span>"
    ]
  },
  {
    "objectID": "twi.html#conclusión",
    "href": "twi.html#conclusión",
    "title": "4  TWI y HAND",
    "section": "4.6 Conclusión",
    "text": "4.6 Conclusión\nNuestro análisis demuestra que tanto el TWI como HAND corresponden bien al modelado hidrológico desarrollado por la Facultad de Ingeniería Hídrica de la Universidad Nacional de La Plata. A pesar de las diferencias metodológicas entre estos enfoques, la correspondencia espacial general es sólida, proporcionando confianza en el uso de ambas métricas como herramientas de evaluación preliminar para el riesgo de inundaciones. Tanto el TWI como HAND constituyen herramientas valiosas y científicamente respaldadas para evaluaciones preliminares de riesgo de inundación a escala municipal, especialmente en contextos con limitaciones de datos donde no existe modelado hidrológico avanzado disponible. Los resultados son consistentes con estudios internacionales que han validado estas metodologías en ciudades como Katmandú, Nepal (Watson et al. 2024; Li et al. 2023) y en regiones rurales de Estados Unidos (Thalakkottukara et al. 2024), lo que nos proporciona confianza para usar estos datos en evaluaciones iniciales de peligro de inundación.\n\n\n\n\nAtlas. 2025. “Topographic Wetness Index—GIS Use Cases.” https://atlas.co/gis-use-cases/topographic-wetness-index/.\n\n\nBallerine, C. 2017. “Topographic Wetness Index Urban Flooding Awareness Act Action Support.” Technical report; University of Illinois at Urbana-Champaign, Prairie Research Institute.\n\n\nHawker, L., P. Uhe, L. Paulo, J. Sosa, J. Savage, C. Sampson, and J. Neal. 2022. “A 30 m Global Map of Elevation with Forests and Buildings Removed.” Environmental Research Letters 17 (2): 024016. https://doi.org/10.1088/1748-9326/ac4d4f.\n\n\nJohnson, J. M., D. Munasinghe, D. Eyelade, and S. Cohen. 2019. “An Integrated Evaluation of the National Water Model (NWM)–Height Above Nearest Drainage (HAND) Flood Mapping Methodology.” Natural Hazards and Earth System Sciences 19 (11): 2405–20. https://doi.org/10.5194/nhess-19-2405-2019.\n\n\nKelleher, C., and L. McPhillips. 2020. “Exploring the Application of Topographic Indices in Urban Areas as Indicators of Pluvial Flooding Locations.” Hydrological Processes 34 (3): 780–94. https://doi.org/10.1002/hyp.13628.\n\n\nLi, Z., F. Q. Duque, T. Grout, B. Bates, and I. Demir. 2023. “Comparative Analysis of Performance and Mechanisms of Flood Inundation Map Generation Using Height Above Nearest Drainage.” Environmental Modelling & Software 159: 105565. https://doi.org/10.1016/j.envsoft.2022.105565.\n\n\nRomanazzi, Pablo et al. 2019. Plan de Reducción Del Riesgo Por Inundaciones En La Región de La Plata. Edited by Sebastián Guerrini, Pablo Morosi, Eduardo Pablo Spinelli, and Josefina López MacKenzie. 1st ed. La Plata: Universidad Nacional de La Plata. Facultad de Ingeniería; Municipalidad de La Plata. https://sedici.unlp.edu.ar/bitstream/handle/10915/165109/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y.\n\n\nThalakkottukara, N. T., J. Thomas, M. K. Watkins, et al. 2024. “Suitability of the Height Above Nearest Drainage (HAND) Model for Flood Inundation Mapping in Data-Scarce Regions: A Comparative Analysis with Hydrodynamic Models.” Earth Science Informatics 17: 1907–21. https://doi.org/10.1007/s12145-023-01218-x.\n\n\nWatson, C. S., J. Gyawali, M. Creed, and J. R. Elliott. 2024. “City-Scale High-Resolution Flood Models and the Role of Topographic Data: A Case Study of Kathmandu, Nepal.” Geocarto International 39 (1): 2387073. https://doi.org/10.1080/10106049.2024.2387073.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TWI y HAND</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Atlas. 2025. “Topographic Wetness Index—GIS Use Cases.” https://atlas.co/gis-use-cases/topographic-wetness-index/.\n\n\nBallerine, C. 2017. “Topographic Wetness Index Urban Flooding\nAwareness Act Action Support.” Technical report; University of\nIllinois at Urbana-Champaign, Prairie Research Institute.\n\n\nHawker, L., P. Uhe, L. Paulo, J. Sosa, J. Savage, C. Sampson, and J.\nNeal. 2022. “A 30 m Global Map of Elevation with Forests and\nBuildings Removed.” Environmental Research Letters 17\n(2): 024016. https://doi.org/10.1088/1748-9326/ac4d4f.\n\n\nKelleher, C., and L. McPhillips. 2020. “Exploring the Application\nof Topographic Indices in Urban Areas as Indicators of Pluvial Flooding\nLocations.” Hydrological Processes 34 (3): 780–94. https://doi.org/10.1002/hyp.13628.\n\n\nRomanazzi, Pablo et al. 2019. Plan de Reducción Del Riesgo Por\nInundaciones En La Región de La Plata. Edited by Sebastián\nGuerrini, Pablo Morosi, Eduardo Pablo Spinelli, and Josefina López\nMacKenzie. 1st ed. La Plata: Universidad Nacional de La Plata. Facultad\nde Ingeniería; Municipalidad de La Plata. https://sedici.unlp.edu.ar/bitstream/handle/10915/165109/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y.\n\n\nSchiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023.\n“GHS-POP R2023A - GHS Population Grid Multitemporal\n(1975-2030).” European Commission, Joint Research Centre (JRC).\nhttps://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of\nFlood Exposure in Developing Countries Using High-Resolution Population\nData.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite\nImaging Reveals Increased Proportion of Population Exposed to\nFloods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by\nVIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "twi.html#comparativa-de-modelación-flo-2d-con-twi-y-hand",
    "href": "twi.html#comparativa-de-modelación-flo-2d-con-twi-y-hand",
    "title": "4  TWI y HAND",
    "section": "4.5 Comparativa de modelación FLO-2D con TWI y HAND",
    "text": "4.5 Comparativa de modelación FLO-2D con TWI y HAND\nPara validar la efectividad de estas métricas topográficas simples, utilizamos datos oficiales de peligro de inundación desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata (Romanazzi et al. 2019). Estos datos de referencia fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que simuló la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. La disponibilidad de este modelado detallado proporciona una oportunidad única para evaluar qué tan bien corresponden estos índices topográficos simples con el modelado hidráulico más completo como prueba de concepto.\nPara la comparación, presentamos el TWI en su forma continua, permitiendo visualizar la variación completa de valores de humedad topográfica. Para HAND, aplicamos cortes de cuantiles con cuatro clases que dividen el área de estudio en zonas de igual extensión (25% cada una), facilitando la identificación de gradientes de riesgo relativo de inundación. Esta aproximación permite una comparación visual clara entre los diferentes enfoques metodológicos.\nUn aspecto importante a considerar es que existen diferencias metodológicas fundamentales entre estos enfoques. El modelado de ingeniería toma en cuenta la infraestructura urbana, especialmente el sistema de calles de la ciudad y elementos del drenaje urbano, mientras que tanto el TWI como HAND se basan únicamente en la topografía del terreno.\n\nMostrar código\n# Preparar datos para el mapa\nruta_peligro = RUTA_DATOS / \"peligro_raster_10m.tif\"\npeligro_xarray = rioxarray.open_rasterio(ruta_peligro)\n\n# Crear clases de quantiles para TWI usando los breaks calculados\ntwi_quantile_classes = xr.where(twi_masked &lt;= twi_quantiles[0], 1,\n                               xr.where(twi_masked &lt;= twi_quantiles[1], 2,\n                                       xr.where(twi_masked &lt;= twi_quantiles[2], 3, 4)))\ntwi_quantile_classes = xr.where(~twi_masked.isnull(), twi_quantile_classes, np.nan)\ntwi_quantile_classes = twi_quantile_classes.rio.write_crs(twi_masked.rio.crs)\ntwi_quantile_classes = twi_quantile_classes.rio.write_transform(twi_masked.rio.transform())\n\n# Crear clases de quantiles para HAND usando los breaks calculados\nhand_quantile_classes = xr.where(hand_double_sqrt_masked &lt;= hand_double_sqrt_quantiles[0], 1,\n                                xr.where(hand_double_sqrt_masked &lt;= hand_double_sqrt_quantiles[1], 2,\n                                        xr.where(hand_double_sqrt_masked &lt;= hand_double_sqrt_quantiles[2], 3, 4)))\nhand_quantile_classes = xr.where(~hand_double_sqrt_masked.isnull(), hand_quantile_classes, np.nan)\nhand_quantile_classes = hand_quantile_classes.rio.write_crs(hand_double_sqrt_masked.rio.crs)\nhand_quantile_classes = hand_quantile_classes.rio.write_transform(hand_double_sqrt_masked.rio.transform())\n\n# Preparar datos de peligrosidad\npeligro_2d = peligro_xarray.sel(band=1).astype('float32')\npeligro_clipped = peligro_2d.rio.clip(la_plata.geometry, la_plata.crs)\n\n# Definir función para crear mapas consistentes\ndef create_consistent_map(title, boundary_gdf, bounds=None):\n    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n    fig, ax = plt.subplots(figsize=(8, 6))\n    \n    if bounds is not None:\n        ax.set_xlim(bounds[0], bounds[2])\n        ax.set_ylim(bounds[1], bounds[3])\n    \n    if boundary_gdf is not None:\n        boundary_gdf.plot(\n            ax=ax,\n            facecolor=\"none\",\n            edgecolor=\"black\",\n            linewidth=0.5,\n            linestyle=\"--\",\n            zorder=5,\n        )\n    \n    ax.set_title(title, fontsize=14, fontweight=\"bold\", pad=20)\n    ax.set_axis_off()\n    \n    return fig, ax\n\n# Obtener bounds comunes para todos los mapas\ncommon_bounds = la_plata.to_crs(CRS_ARGENTINA).total_bounds\n\n# Mapa 1: TWI\nfig1, ax1 = create_consistent_map(\"Índice de Humedad Topográfica (TWI)\", boundary_gdf=la_plata, bounds=common_bounds)\n\ntwi_masked_3857 = twi_masked.rio.reproject(\"EPSG:3857\")\ntwi_masked_3857.plot(ax=ax1, cmap=CMAP, add_colorbar=True, cbar_kwargs={\"label\": \"Índice de Humedad Topográfica\"})\n\nplt.tight_layout()\nplt.show()\n\n# Mapa 2: HAND\nfig2, ax2 = create_consistent_map(\"Altura Sobre Drenaje Más Cercano (HAND)\", boundary_gdf=la_plata, bounds=common_bounds)\n\nhand_quantile_classes_3857 = hand_quantile_classes.rio.reproject(\"EPSG:3857\")\nhand_quantile_classes_3857.plot(\n    ax=ax2,\n    cmap=CMAP + \"_r\",\n    add_colorbar=True,\n    cbar_kwargs={\n        \"label\": \"HAND (Cuantiles)\",\n        \"ticks\": [1.5, 2.5, 3.5, 4.5],\n        \"format\": lambda x, pos: f\"Q{int(x)}\"\n    }\n)\n\nplt.tight_layout()\nplt.show()\n\n# Mapa 3: Peligrosidad FLO-2D\nfig3, ax3 = create_consistent_map(\"Modelado FLO-2D (Peligrosidad)\", boundary_gdf=la_plata, bounds=common_bounds)\n\npeligro_clipped_3857 = peligro_clipped.rio.reproject(\"EPSG:3857\")\npeligro_clipped_3857.plot(\n    ax=ax3,\n    cmap=CMAP,\n    add_colorbar=True,\n    cbar_kwargs={\"label\": \"Nivel de Peligrosidad\"}\n)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Índice de Humedad Topográfica (TWI)\n\n\n\n\n\n\n\n\n\n\n\n(b) Altura Sobre Drenaje Más Cercano (HAND)\n\n\n\n\n\n\n\n\n\n\n\n(c) Modelado FLO-2D (Peligrosidad)\n\n\n\n\n\n\n\nFigure 4.1: Comparativa de TWI, HAND y modelado FLO-2D",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TWI y HAND</span>"
    ]
  },
  {
    "objectID": "exposicion.html#qué-es-el-mapeo-dasymetrico",
    "href": "exposicion.html#qué-es-el-mapeo-dasymetrico",
    "title": "1  Exposición",
    "section": "1.2 Qué es el mapeo dasymetrico?",
    "text": "1.2 Qué es el mapeo dasymetrico?\nEl mapeo dasimétrico reorganiza datos cartográficos de una unidad de recolección en áreas más precisas, modificando los límites originales usando datos de apoyo relacionados. Por ejemplo, un atributo de población organizado por tracto censal se vuelve más significativo cuando se eliminan áreas donde es razonable inferir que la gente no vive (cuerpos de agua, terrenos vacíos). En nuestro caso, utilizamos datos GHSL y huellas de edificios como información auxiliar para mejorar la precisión de las estimaciones de distribución poblacional.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#fuentes-de-datos",
    "href": "exposicion.html#fuentes-de-datos",
    "title": "1  Exposición",
    "section": "1.3 Fuentes de datos",
    "text": "1.3 Fuentes de datos\n\n1.3.1 Censo Argentino\nLos datos censales provienen del Censo Nacional de Población, Hogares y Viviendas 2022 de Argentina, realizado por el Instituto Nacional de Estadística y Censos (INDEC) (Instituto Nacional de Estadística y Censos (INDEC) 2024). Los datos fueron descargados desde la plataforma Redatam y procesados en R en un repositorio separado, ya que resultó más eficiente trabajar con esa herramienta para el procesamiento inicial. Posteriormente, estos datos fueron unidos con el conjunto de datos de radios censales de Argentina y guardados localmente. Se planea hacer disponible una copia de los datos en formato geoespacial como archivo Parquet almacenado en la nube, pero este trabajo aún está en progreso.\n\n\nMostrar código\ndatos_censales = gpd.read_parquet(\n    \"/home/nissim/Documents/dev/fulbright/ciut-redatam/datos_censales_2022_geo.parquet\"\n)\n\ndatos_censales = datos_censales.to_crs(USE_CRS)\n\ngeometria_esperanza = esperanza.geometry.iloc[0]\ncentroides_dentro = datos_censales.geometry.centroid.within(geometria_esperanza)\ncompletamente_dentro = datos_censales.within(geometria_esperanza)\ndatos_censales_esperanza = datos_censales[\n    completamente_dentro | centroides_dentro\n].copy()\n\nfig, ax = create_consistent_map(\n    \"Población Total por Radio Censal - Censo 2022\", esperanza\n)\n\ndatos_censales_esperanza_3857 = datos_censales_esperanza.to_crs(WEB_MERCATOR_CRS)\n\ndatos_censales_esperanza_3857.plot(\n    column=\"POB_TOT_P\", ax=ax, cmap=PLASMA_CMAP, legend=False, alpha=0.8, zorder=2\n)\n\nplt.title(\"Población Total por Radio Censal - Censo 2022\", fontsize=16, fontweight=\"bold\", pad=20)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n1.3.2 Datos GHSL\nLa Capa Global de Asentamientos Humanos (Global Human Settlement Layer) (Schiavina et al. 2023) es un conjunto de datos de resolución de 100 metros que proporciona estimaciones de población multitemporales (1975-2030) derivadas de datos censales y administrativos, informadas por la distribución y clasificación de áreas construidas. Para este análisis se utilizan los datos GHSL de 2023, que son los más recientes disponibles y los más cercanos temporalmente al Censo Argentino 2022. El GHSL ya tiene un uso científico establecido para mapear la exposición poblacional a peligros de inundación (Tellman et al. 2021). Sin embargo, esta fuente presenta limitaciones importantes: estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución (Smith et al. 2019).\n\n\nMostrar código\nghsl = rioxarray.open_rasterio(\n    \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R13_C13/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R13_C13.tif\",\n    chunks={\"x\": 1024, \"y\": 1024},\n)\n\nghsl = ghsl.rio.reproject(dst_crs=USE_CRS)\n\nghsl_clipped = ghsl.rio.clip(\n    [esperanza.geometry.iloc[0]],\n    from_disk=True,\n)\n\nghsl_masked = ghsl_clipped.where(ghsl_clipped &gt; 0)\n\nfig, ax = create_consistent_map(\n    \"Estimaciones de Población GHSL 2023 - Esperanza, Santa Fe\", esperanza\n)\n\nghsl_masked_3857 = ghsl_masked.rio.reproject(WEB_MERCATOR_CRS)\n\nghsl_masked_3857 = ghsl_masked_3857.where(ghsl_masked_3857 &gt; 0)\n\nghsl_masked_3857.plot(ax=ax, cmap=PLASMA_CMAP, alpha=0.75, add_colorbar=False, add_labels=False, zorder=2)\n\nplt.title(\"Estimaciones de Población GHSL 2023 - Esperanza, Santa Fe\", fontsize=16, fontweight=\"bold\", pad=20)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#resultados",
    "href": "exposicion.html#resultados",
    "title": "1  Exposición",
    "section": "1.4 Resultados",
    "text": "1.4 Resultados\n\n\nMostrar código\ngeometrias = [geom for geom in datos_censales_esperanza.geometry]\n\nestadisticas = rasterstats.zonal_stats(\n    geometrias,\n    ghsl_clipped.values[0],\n    affine=ghsl_clipped.rio.transform(),\n    stats=[\"sum\"],\n    nodata=-200,\n)\n\ntotales_ghsl = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in estadisticas]\n\ndatos_censales_esperanza[\"estimacion_pob_ghsl\"] = totales_ghsl\n\n\nraster_referencia = ghsl_clipped\ntransformacion_referencia = raster_referencia.rio.transform()\ncrs_referencia = raster_referencia.rio.crs\nforma_referencia = raster_referencia.shape[1:]\nraster_ghsl = ghsl_clipped.values[0]\n\n\ngeometrias_ghsl = [\n    (geom, valor)\n    for geom, valor in zip(\n        datos_censales_esperanza.geometry,\n        datos_censales_esperanza[\"estimacion_pob_ghsl\"],\n    )\n]\ngeometrias_pob = [\n    (geom, valor)\n    for geom, valor in zip(\n        datos_censales_esperanza.geometry, datos_censales_esperanza[\"POB_TOT_P\"]\n    )\n]\n\nraster_pob_ghsl = rasterize(\n    geometrias_ghsl,\n    out_shape=forma_referencia,\n    transform=transformacion_referencia,\n    fill=0,\n    dtype=np.float32,\n    all_touched=True,\n)\n\nraster_pob_censo = rasterize(\n    geometrias_pob,\n    out_shape=forma_referencia,\n    transform=transformacion_referencia,\n    fill=0,\n    dtype=np.float32,\n    all_touched=True,\n)\n\n\nmascara = (raster_ghsl &gt; 0) & (raster_ghsl != -200) & (raster_pob_ghsl &gt; 0.1)\nghsl_fraccional = np.full_like(raster_ghsl, 0, dtype=np.float64)\nghsl_fraccional[mascara] = raster_ghsl[mascara] / raster_pob_ghsl[mascara]\n\nmascara2 = (ghsl_fraccional &gt; 0) & (raster_pob_censo &gt; 0)\npob_redistribuida = np.full_like(raster_ghsl, 0, dtype=np.float64)\npob_redistribuida[mascara2] = ghsl_fraccional[mascara2] * raster_pob_censo[mascara2]\n\npob_redistribuida_da = xr.DataArray(\n    pob_redistribuida,\n    coords={\"y\": ghsl_clipped.y, \"x\": ghsl_clipped.x},\n    dims=[\"y\", \"x\"],\n    attrs=ghsl_clipped.attrs.copy(),\n)\n\npob_redistribuida_da = pob_redistribuida_da.rio.write_crs(USE_CRS)\n\npob_redistribuida_enmascarada = pob_redistribuida_da.where(pob_redistribuida_da &gt; 0)\n\ntotal_redistribuido = pob_redistribuida[pob_redistribuida &gt; 0].sum()\ntotal_censo = datos_censales_esperanza[\"POB_TOT_P\"].sum()\n\nfig, ax = create_consistent_map(\n    \"Población Redistribuida a 100m - Esperanza, Santa Fe\", esperanza\n)\n\npob_redistribuida_enmascarada_3857 = pob_redistribuida_enmascarada.rio.reproject(\n    WEB_MERCATOR_CRS\n)\n\npob_redistribuida_enmascarada_3857 = pob_redistribuida_enmascarada_3857.where(\n    pob_redistribuida_enmascarada_3857 &gt; 0\n)\n\npob_redistribuida_enmascarada_3857.plot(\n    ax=ax, cmap=PLASMA_CMAP, alpha=0.75, add_colorbar=False, add_labels=False, zorder=2\n)\n\nplt.title(\"Población Censal Redistribuida a 100m - Esperanza, Santa Fe\", fontsize=16, fontweight=\"bold\", pad=20)\nplt.show()\n\n\n\n\n\n\n\n\n\nEste flujo de trabajo demuestra la capacidad de redistribuir exitosamente datos de población censal a resolución de 100 metros utilizando datos GHSL para mapeo dasimétrico. El proceso logra una conservación de población del 97.6%, redistribuyendo 45,616 personas de un total censal de 46,757 habitantes. Esta metodología permite una representación espacial más precisa de la distribución poblacional, manteniendo la consistencia con los datos censales oficiales.\n\n\n\n\nInstituto Nacional de Estadística y Censos (INDEC). 2024. “Bases de Datos.” https://www.indec.gob.ar/indec/web/Institucional-Indec-BasesDeDatos-6.\n\n\nSchiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023. “GHS-POP R2023A - GHS Population Grid Multitemporal (1975-2030).” European Commission, Joint Research Centre (JRC). https://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of Flood Exposure in Developing Countries Using High-Resolution Population Data.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite Imaging Reveals Increased Proportion of Population Exposed to Floods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#qué-es-el-mapeo-dasimétrico",
    "href": "exposicion.html#qué-es-el-mapeo-dasimétrico",
    "title": "1  Exposición",
    "section": "1.2 Qué es el mapeo dasimétrico?",
    "text": "1.2 Qué es el mapeo dasimétrico?\nEl mapeo dasimétrico reorganiza datos cartográficos de una unidad de recolección en áreas más precisas, modificando los límites originales usando datos de apoyo relacionados. Por ejemplo, un atributo de población organizado por tracto censal se vuelve más significativo cuando se eliminan áreas donde es razonable inferir que la gente no vive (cuerpos de agua, terrenos vacíos). En nuestro caso, utilizamos datos GHSL y huellas de edificios como información auxiliar para mejorar la precisión de las estimaciones de distribución poblacional.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "renabap_final.html",
    "href": "renabap_final.html",
    "title": "4  RENABAP",
    "section": "",
    "text": "4.1 Resumen ejecutivo",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#objetivos",
    "href": "renabap_final.html#objetivos",
    "title": "4  RENABAP",
    "section": "4.2 Objetivos",
    "text": "4.2 Objetivos\nEste proyecto tiene como objetivo principal mejorar el mapeo de la exposición a peligros de inundación en asentamientos informales del Partido de La Plata. El análisis se realiza específicamente con el propósito de preparar un plan para la reubicación gradual de las estructuras, viviendas o familias en mayor riesgo dentro de estos asentamientos informales hacia lugares más seguros.\nEl trabajo busca cuantificar la exposición a peligros de inundación en asentamientos informales como herramienta para la toma de decisiones a nivel municipal, desarrollando metodologías de análisis espacial que permitan identificar las áreas y poblaciones de mayor riesgo. Asimismo, se propone proporcionar información técnica que ayude a mitigar el riesgo de inundación en asentamientos informales y obtener estimaciones más precisas de la población expuesta utilizando datos de huellas de edificios, complementando las limitaciones conocidas de los datos del RENABAP.\nUn objetivo adicional de este análisis es intentar obtener una estimación más precisa utilizando datos abiertos de huellas de edificios que los datos del RENABAP nos proporcionan. Los últimos datos del RENABAP fueron publicados en 2023 y están basados en proyecciones derivadas del censo de 2010, por lo que no se espera que sean especialmente precisos para las condiciones actuales.\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\nfrom io import BytesIO, StringIO\nfrom owslib.wfs import WebFeatureService\nfrom shapely.geometry import box\nimport geopandas as gpd\nimport requests\nimport pandas as pd\nimport os\n\nimport boto3\nimport duckdb\n\n\nimport numpy as np\nimport s2sphere\nfrom botocore.config import Config\nimport itables\nfrom itables import show\nfrom IPython.display import HTML, display\n\n\n# =============================================================================\n# ITABLES SPANISH CONFIGURATION\n# =============================================================================\n\n# Configure Argentine Spanish for itables\ntry:\n    spanish_url = \"https://cdn.datatables.net/plug-ins/2.3.3/i18n/es-AR.json\"\n    response = requests.get(spanish_url)\n    response.raise_for_status()\n    spanish_config = response.json()\n    itables.options.language = spanish_config\nexcept Exception:\n    pass  # Fall back to English if configuration fails\n\n# Configure smaller font size for all itables\ncss = \"\"\"\n.dt-container {\n  font-size: small;\n}\n\"\"\"\ndisplay(HTML(f\"&lt;style&gt;{css}&lt;/style&gt;\"))\n\n\n# Helper function to round numeric columns for display\ndef round_numeric_columns(df, decimals=0):\n    \"\"\"Round all numeric columns in a DataFrame to specified decimal places.\"\"\"\n    df_display = df.copy()\n    numeric_columns = df_display.select_dtypes(include=[np.number]).columns\n    df_display[numeric_columns] = df_display[numeric_columns].round(decimals)\n    return df_display\n\n\n# =============================================================================\n# CONSTANTS AND CONFIGURATION\n# =============================================================================\n\n# Coordinate Reference Systems\nUSE_CRS = \"EPSG:5349\"  # POSGAR 2007 / Argentina 4\nWEB_MERCATOR_CRS = \"EPSG:3857\"  # Web Mercator for visualization\nWGS84_CRS = \"EPSG:4326\"  # WGS84 for API calls\n\n# File paths\nBASE_PATH = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo\"\nDATA_PATH = f\"{BASE_PATH}/notebooks/data\"\nPELIGRO_PATH = f\"{DATA_PATH}/la_plata_pelig_2023_datos_originales.geojson\"\nPARTIDOS_PATH = f\"{DATA_PATH}/pba_partidos.geojson\"\nCUENCAS_PATH = f\"{BASE_PATH}/notebooks/cuencas_buenos_aires.geojson\"\nBUILDINGS_PATH = f\"{BASE_PATH}/notebooks/buildings_filtered.parquet\"\n\n# Data URLs\nRENABAP_URL = (\n    \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\n)\nPARTIDOS_WFS_URL = \"https://geo.arba.gov.ar/geoserver/idera/wfs\"\nCUENCAS_API_URL = \"https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query\"\n\n# Data processing constants\nHAZARD_LEVELS = [\"baja\", \"media\", \"alta\"]\nMETHOD_NAMES = [\"edificios\", \"ghsl\", \"areal\"]\nEXPOSURE_COLUMNS = [\n    \"fam_exp_edificios\",\n    \"fam_exp_ghsl\",\n    \"fam_exp_areal\",\n]\nNON_HAZARD_VALUE = \"none\"\nNODATA_VALUE = -200\n\n# Column mappings and renaming\nCOLUMN_MAPPINGS = {\n    \"buildings_to_edificios\": {\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"},\n    \"method_cleanup_prefix\": \"fam_expuestas_\",\n}\n\n# Basic visualization settings (only for repeated values)\nDEFAULT_FIGSIZE = (12, 10)\nMAP_PADDING = 500\nPLASMA_CMAP = plt.cm.plasma\n\n# Color schemes for visualization\nPELIGROSIDAD_COLORS = {\n    \"alta\": PLASMA_CMAP(0.8),\n    \"media\": PLASMA_CMAP(0.5),\n    \"baja\": PLASMA_CMAP(0.2),\n}\n\nMETHOD_COLORS = {\n    \"fam_exp_areal\": PLASMA_CMAP(0.8),\n    \"fam_exp_ghsl\": PLASMA_CMAP(0.5),\n    \"fam_exp_edificios\": PLASMA_CMAP(0.2),\n}\n\n# Eje mapping for watershed analysis\nEJE_MAPPING = {\n    \"noreste\": [\"Area de Bañados\", \"Cuenca Arroyo Rodriguez-Don Carlos\"],\n    \"noroeste\": [\"Cuenca Arroyo Martín-Carnaval\", \"Cuenca Arroyo Pereyra\"],\n    \"central\": [\"Cuenca Arroyo del Gato\"],\n    \"sudoeste\": [\"Cuenca A° Maldonado\", \"Cuenca Río Samborombón\"],\n    \"sudeste\": [\"Cuenca Arroyo El Pescado\"],\n}\n\n\ndef setup_base_map(\n    figsize=None, bounds=None, boundary_gdf=None, padding_x=None, padding_y=None\n):\n    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n    if figsize is None:\n        figsize = DEFAULT_FIGSIZE\n    if padding_x is None:\n        padding_x = MAP_PADDING\n    if padding_y is None:\n        padding_y = MAP_PADDING\n\n    if bounds is None and boundary_gdf is not None:\n        bounds = boundary_gdf.total_bounds\n    elif bounds is None:\n        bounds = renabap_pba_intersect.total_bounds\n\n    # Convert bounds to Web Mercator for basemap compatibility\n    if bounds is not None:\n        # Create a temporary GeoDataFrame with the bounds to reproject\n        temp_bounds = gpd.GeoDataFrame(\n            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS\n        )\n        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds\n    else:\n        bounds_3857 = bounds\n\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)\n    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)\n    return fig, ax\n\n\ndef add_basemap(ax, zoom=13):\n    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n\n    ctx.add_basemap(\n        ax,\n        source=ctx.providers.CartoDB.PositronNoLabels,\n        zorder=0,\n        zoom=zoom,\n    )\n\n    return ax\n\n\ndef add_north_arrow(ax, x=0.95, y=0.05, arrow_length=0.04):\n    \"\"\"Add a north arrow to the map.\"\"\"\n    # Add north arrow, https://stackoverflow.com/a/58110049/604456\n    ax.annotate(\n        \"N\",\n        xy=(x, y),\n        xytext=(x, y - arrow_length),\n        arrowprops=dict(facecolor=\"black\", width=3, headwidth=10),\n        ha=\"center\",\n        va=\"center\",\n        fontsize=14,\n        xycoords=ax.transAxes,\n    )\n\n\ndef add_la_plata_outline(ax, color=\"black\"):\n    \"\"\"Add the outline of Partido de La Plata to a map as the top layer.\"\"\"\n    la_plata_3857 = la_plata.to_crs(WEB_MERCATOR_CRS)\n    la_plata_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=color,\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=100,  # Ensure it's always on top\n    )\n\n\ndef add_boundary_outline(ax, boundary_gdf, crs=\"EPSG:3857\"):\n    \"\"\"Add the outline of a boundary geodataframe to a map.\"\"\"\n    boundary_3857 = boundary_gdf.to_crs(crs)\n    boundary_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"black\",\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=5,\n    )\n\n\ndef create_consistent_map(title, boundary_gdf=None, bounds=None):\n    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n    fig, ax = setup_base_map(bounds=bounds, boundary_gdf=boundary_gdf)\n\n    add_basemap(ax)\n\n    add_north_arrow(ax)\n\n    if boundary_gdf is not None:\n        add_boundary_outline(ax, boundary_gdf)\n    else:\n        add_la_plata_outline(ax)\n\n    ax.set_title(title, fontsize=16, fontweight=\"bold\", pad=20)\n\n    ax.set_axis_off()\n\n    return fig, ax\n\n\ndef wfs_to_gdf(\n    wfs_url: str, layer_name: str, srs: str = \"EPSG:4326\"\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Descarga una capa WFS y la devuelve como GeoDataFrame.\n\n    Args:\n        wfs_url (str): URL del servicio WFS.\n        layer_name (str): Nombre de la capa (typename).\n        srs (str): Código EPSG del sistema de referencia de coordenadas.\n\n    Returns:\n        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.\n    \"\"\"\n    wfs = WebFeatureService(url=wfs_url, version=\"2.0.0\")\n    response = wfs.getfeature(typename=layer_name, srsname=srs)\n    gdf = gpd.read_file(BytesIO(response.read()))\n    return gdf\n\n\ndef create_exposure_tidy_data(\n    data,\n    id_column,\n    peligrosidad_column,\n    method_suffix,\n    exposure_values,\n    exclude_zero=True,\n):\n    \"\"\"\n    Create tidy exposure dataset in a standardized format.\n\n    Args:\n        data: DataFrame containing the base data\n        id_column: Column name for the identifier (e.g., 'id_renabap', 'Cuenca', 'eje')\n        peligrosidad_column: Column name for hazard level\n        method_suffix: Suffix for the exposure column (e.g., 'areal', 'ghsl', 'edificios')\n        exposure_values: Series or array of exposure values matching data rows\n        exclude_zero: Whether to exclude zero exposure values\n\n    Returns:\n        pd.DataFrame: Tidy format dataframe with id, peligrosidad, and exposure columns\n    \"\"\"\n    tidy_data = []\n    for idx, (_, row) in enumerate(data.iterrows()):\n        exposure_value = (\n            exposure_values.iloc[idx]\n            if hasattr(exposure_values, \"iloc\")\n            else exposure_values[idx]\n        )\n\n        if exclude_zero and exposure_value &lt;= 0:\n            continue\n\n        tidy_data.append(\n            {\n                id_column: row[id_column],\n                \"peligrosidad\": row[peligrosidad_column],\n                f\"fam_expuestas_{method_suffix}\": exposure_value,\n            }\n        )\n\n    return pd.DataFrame(tidy_data)\n\n\ndef create_wide_exposure_dataframe(\n    areal_data, ghsl_data, buildings_data, id_columns, exclude_hazard_value=\"none\"\n):\n    \"\"\"\n    Create wide format exposure dataframe by merging tidy datasets.\n\n    Args:\n        areal_data: Tidy dataframe with areal interpolation results\n        ghsl_data: Tidy dataframe with GHSL dasymetric results\n        buildings_data: Tidy dataframe with buildings dasymetric results\n        id_columns: List of columns to merge on (e.g., ['id_renabap', 'peligrosidad'])\n        exclude_hazard_value: Hazard value to exclude from results\n\n    Returns:\n        pd.DataFrame: Wide format dataframe with all exposure methods\n    \"\"\"\n    # Filter out non-hazard values\n    areal_filtered = areal_data[areal_data[\"peligrosidad\"] != exclude_hazard_value]\n    ghsl_filtered = ghsl_data[ghsl_data[\"peligrosidad\"] != exclude_hazard_value]\n    buildings_filtered = buildings_data[\n        buildings_data[\"peligrosidad\"] != exclude_hazard_value\n    ]\n\n    # Apply column mapping for buildings if needed\n    if \"fam_expuestas_buildings\" in buildings_filtered.columns:\n        buildings_filtered = buildings_filtered.rename(\n            columns={\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"}\n        )\n\n    # Merge all datasets\n    wide_data = areal_filtered.merge(ghsl_filtered, on=id_columns, how=\"outer\").merge(\n        buildings_filtered, on=id_columns, how=\"outer\"\n    )\n\n    # Fill NaN values with 0\n    wide_data = wide_data.fillna(0)\n\n    # Rename columns to shorter format\n    column_mapping = {\n        \"fam_expuestas_areal\": \"fam_exp_areal\",\n        \"fam_expuestas_ghsl\": \"fam_exp_ghsl\",\n        \"fam_expuestas_edificios\": \"fam_exp_edificios\",\n    }\n    wide_data = wide_data.rename(columns=column_mapping)\n\n    return wide_data\n\n\nresponse = requests.get(RENABAP_URL)\nrenabap = gpd.read_file(StringIO(response.text))\nrenabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\nrenabap_pba = renabap_pba.to_crs(USE_CRS)\n\npeligro = gpd.read_file(PELIGRO_PATH)\npeligro = peligro.to_crs(USE_CRS)\n\npeligro_bounds = peligro.total_bounds\npeligro_bbox = box(*peligro_bounds)\n\nif os.path.exists(PARTIDOS_PATH):\n    partidos = gpd.read_file(PARTIDOS_PATH)\nelse:\n    partidos = wfs_to_gdf(\n        wfs_url=PARTIDOS_WFS_URL,\n        layer_name=\"idera:Departamento\",\n        srs=\"EPSG:5347\",\n    )\n\n    partidos.to_file(PARTIDOS_PATH, driver=\"GeoJSON\")\n\npartidos = partidos.to_crs(USE_CRS)\nla_plata = partidos[partidos[\"fna\"] == \"Partido de La Plata\"]\n\n# Obtener la geometría principal\nmain_geom = la_plata.geometry.iloc[0]\n\n# Si es un MultiPolygon, mantener solo el polígono más grande (el partido principal)\n# Esto elimina la pequeña isla que aparece en los datos\nif main_geom.geom_type == \"MultiPolygon\":\n    # Obtener todos los polígonos y mantener el que tenga mayor área\n    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)\n    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning\n    la_plata.loc[la_plata.index[0], \"geometry\"] = largest_polygon\n\nla_plata_bbox = la_plata.geometry.iloc[0]\n\nrenabap_pba_intersect = renabap_pba[\n    renabap_pba.geometry.intersects(la_plata_bbox)\n].copy()\n\n\nif os.path.exists(CUENCAS_PATH):\n    cuencas = gpd.read_file(CUENCAS_PATH)\nelse:\n    params = {\"where\": \"1=1\", \"outFields\": \"*\", \"f\": \"geojson\"}\n\n    cuencas_response = requests.get(CUENCAS_API_URL, params=params)\n    with open(CUENCAS_PATH, \"w\", encoding=\"utf-8\") as f:\n        f.write(cuencas_response.text)\n\n    cuencas = gpd.read_file(StringIO(cuencas_response.text))\n\ncuencas = cuencas.to_crs(USE_CRS)\ncuencas = cuencas.clip(la_plata)\n\n# Map watershed names to axes based on the EJE_MAPPING\ncuencas[\"eje\"] = (\n    cuencas[\"Cuenca\"]\n    .map(\n        {\n            cuenca: eje\n            for eje, cuencas_list in EJE_MAPPING.items()\n            for cuenca in cuencas_list\n        }\n    )\n    .fillna(\"otro\")\n)\n\n# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)\nrenabap_total_area_ha = (\n    renabap_pba_intersect.geometry.area.sum() / 10000\n)  # Convert m² to hectares\nla_plata_area_ha = la_plata.geometry.iloc[0].area / 10000\npercentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100\n\n# Get common bounds for all maps\ncommon_bounds = la_plata.total_bounds\n\n# Intersect settlements with hazard zones\nsettlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n\nsettle_hazard_cuencas = gpd.overlay(\n    settlement_hazard, cuencas, how=\"intersection\", keep_geom_type=True\n)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#contexto",
    "href": "renabap_final.html#contexto",
    "title": "4  RENABAP",
    "section": "4.4 Contexto",
    "text": "4.4 Contexto\n\n\nMostrar código\n# Calcular variables para el contexto\ntotal_barrios = int(len(renabap_pba_intersect))\ntotal_familias = int(renabap_pba_intersect['familias_aproximadas'].sum())\narea_barrios_ha = int(renabap_total_area_ha)\nporcentaje_cobertura = float(round(percentage_coverage, 1))\n\n# Obtener total de edificaciones en La Plata\ntotal_buildings_la_plata = len(buildings_proj)\n\n# Obtener todas las edificaciones que intersectan con los barrios (corregir warning de deprecación)\nbuildings_in_barrios = buildings_proj[\n    buildings_proj.geometry.intersects(renabap_pba_intersect.union_all())\n]\ntotal_buildings_in_barrios = len(buildings_in_barrios)\n\n# Calcular porcentaje de edificaciones en barrios\nbuildings_percentage = float(round((total_buildings_in_barrios / total_buildings_la_plata) * 100, 1))\n\n# Helper function to format numbers with commas\ndef format_number(num):\n    return f\"{num:,}\"\n\n# Recortar peligro por la plata\npeligro_la_plata = peligro.clip(la_plata)\n\n# Calcular área para cada tipo de peligro en hectáreas\npeligro_areas = (\n    peligro_la_plata.groupby(\"PELIGROSID\")[\"geometry\"]\n    .apply(\n        lambda x: x.area.sum() / 10000  # Convertir m² a hectáreas\n    )\n    .reset_index()\n)\npeligro_areas.columns = [\"tipo_peligro\", \"area_ha\"]\n\n# Calcular porcentajes\npeligro_areas[\"porcentaje\"] = (peligro_areas[\"area_ha\"] / la_plata_area_ha) * 100\n\n# Variables para cada nivel de peligro (convertir a float Python nativo)\npeligro_alta_ha = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"alta\"][\"area_ha\"].iloc[0], 1))\npeligro_alta_pct = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"alta\"][\"porcentaje\"].iloc[0], 1))\npeligro_media_ha = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"media\"][\"area_ha\"].iloc[0], 1))\npeligro_media_pct = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"media\"][\"porcentaje\"].iloc[0], 1))\npeligro_baja_ha = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"baja\"][\"area_ha\"].iloc[0], 1))\npeligro_baja_pct = float(round(peligro_areas[peligro_areas[\"tipo_peligro\"] == \"baja\"][\"porcentaje\"].iloc[0], 1))\n\n# Área total cubierta por zonas de peligro (convertir a float Python nativo)\narea_total_peligro_ha = float(round(peligro_areas['area_ha'].sum(), 1))\nporcentaje_total_peligro = float(round(peligro_areas['porcentaje'].sum(), 1))\n\n\nHay un total de 166 barrios populares en el Partido de La Plata, que representan 33,888 familias. Estos barrios ocupan 1,760 hectáreas del Partido de La Plata, o 2.0 por ciento del partido. El análisis de edificaciones revela un total de 604,237 edificaciones en La Plata, de las cuales 71,898 se encuentran en barrios populares (11.9% del total). En cuanto a las zonas de peligro de inundación, el territorio incluye 4,202 hectáreas de peligro alto (4.7% del partido), 19,515 hectáreas de peligro medio (21.8% del partido), y 5,885 hectáreas de peligro bajo (6.6% del partido). El área total cubierta por zonas de peligro es de 29,603 hectáreas, representando 33.0% del partido.\n\nMostrar código\nfig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", boundary_gdf=la_plata, bounds=common_bounds)\n\nrenabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(WEB_MERCATOR_CRS)\n\nrenabap_pba_intersect_3857.plot(\n    ax=ax1, facecolor=\"none\", edgecolor=\"black\", linewidth=0.5, legend=False, zorder=10\n)\n\nplt.tight_layout()\nplt.show()\n\npeligro_clipped = gpd.clip(peligro, la_plata)\n\npeligro_clipped_3857 = peligro_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Reorder the categories so they map correctly to plasma colormap\npeligro_clipped_3857[\"PELIGROSID_ordered\"] = pd.Categorical(\n    peligro_clipped_3857[\"PELIGROSID\"],\n    categories=[\"baja\", \"media\", \"alta\"],\n    ordered=True,\n)\n\n\nfig2, ax2 = create_consistent_map(\"Zonas de Peligro en La Plata\", boundary_gdf=la_plata, bounds=common_bounds)\n\n\npeligro_clipped_3857.plot(\n    ax=ax2,\n    column=\"PELIGROSID_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    zorder=5,\n)\n\nplt.tight_layout()\nplt.show()\n\n\nfig3, ax3 = create_consistent_map(\"Huellas de edificios\", boundary_gdf=la_plata, bounds=common_bounds)\n\nbuildings_3857 = buildings_proj.to_crs(WEB_MERCATOR_CRS)\n\nbuildings_3857.plot(ax=ax3, facecolor=\"grey\", edgecolor=\"none\", alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Asentamientos RENABAP en La Plata\n\n\n\n\n\n\n\n\n\n\n\n(b) Zonas de Peligro en La Plata\n\n\n\n\n\n\n\n\n\n\n\n(c) Huellas de edificios\n\n\n\n\n\n\n\nFigure 4.1: Fuentes de datos para análisis de exposición",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#fuentes-de-datos",
    "href": "renabap_final.html#fuentes-de-datos",
    "title": "4  RENABAP",
    "section": "4.3 Fuentes de datos",
    "text": "4.3 Fuentes de datos\n\n4.3.1 RENABAP\nEl Registro Nacional de Barrios Populares (RENABAP) es producido por la Subsecretaría de Integración Socio Urbana y proporciona información sobre asentamientos informales en Argentina, incluyendo estimaciones de población y delimitaciones geográficas de estos barrios. Más información sobre el RENABAP está disponible en el Observatorio de Barrios Populares. Los datos fueron obtenidos a través del Mapa de Barrios Populares y están disponibles para descarga como GeoJSON.\n\n\n4.3.2 Peligro de inundación\nLos datos de peligro de inundación utilizados en este análisis fueron desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata (Romanazzi et al. 2019). Estos datos fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que permitió simular la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. El modelo calcula las principales variables hidráulicas (altura del agua, velocidad y caudal) a lo largo del tiempo, y a partir de estos resultados se generaron los mapas de peligrosidad que combinan el efecto de la profundidad con la velocidad de la corriente, ofreciendo un indicador más completo que los mapas tradicionales de máximas profundidades.\n\n\n4.3.3 Google-Microsoft-OSM Open Buildings\nLos datos de Google-Microsoft-OSM Open Buildings - combined by VIDA (VIDA 2023) representan una forma más precisa de evaluar dónde se ubican los asentamientos humanos. Este conjunto de datos combina Google’s V3 Open Buildings, Microsoft’s GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo más de 2.7 mil millones de huellas de edificios. Estos datos han sido exitosamente aplicados a evaluaciones de riesgo de inundación por empresas globales de riesgo financiero como ICE, demostrando su utilidad para mapear la exposición climática a nivel de huella de edificio individual. Sin embargo, en ausencia de información sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el número total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de dónde se ubican las personas, sin tener una comprensión precisa de quién vive realmente allí y cuántas personas.\n\n\nMostrar código\ndef fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n\n    # Get S2 cell and bounds\n    center = geodataframe.to_crs(WEB_MERCATOR_CRS).union_all().centroid\n    center_wgs84 = (\n        gpd.GeoDataFrame(geometry=[center], crs=WEB_MERCATOR_CRS)\n        .to_crs(WGS84_CRS)\n        .geometry.iloc[0]\n    )\n    cell = s2sphere.CellId.from_lat_lng(\n        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n    ).parent(10)\n    bounds = geodataframe.to_crs(WGS84_CRS).total_bounds\n\n    # Find matching S2 partition\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=\"https://data.source.coop\",\n        aws_access_key_id=\"\",\n        aws_secret_access_key=\"\",\n        config=Config(s3={\"addressing_style\": \"path\"}),\n    )\n\n    partitions = {\n        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n        for obj in s3.list_objects_v2(\n            Bucket=\"vida\",\n            Prefix=\"google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n        ).get(\"Contents\", [])\n    }\n\n    parent_id = next(\n        str(cell.parent(level).id())\n        for level in range(10, 0, -1)\n        if str(cell.parent(level).id()) in partitions\n    )\n\n    # Setup DuckDB and query\n    con = duckdb.connect()\n    for cmd in [\n        \"INSTALL spatial\",\n        \"LOAD spatial\",\n        \"INSTALL httpfs\",\n        \"LOAD httpfs\",\n        \"SET s3_region='us-east-1'\",\n        \"SET s3_endpoint='data.source.coop'\",\n        \"SET s3_use_ssl=true\",\n        \"SET s3_url_style='path'\",\n    ]:\n        con.execute(cmd)\n\n    # Export and read back\n    query = f\"\"\"\n    COPY (SELECT * FROM 's3://vida/google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n          WHERE bbox.xmax &gt;= {bounds[0]} AND bbox.xmin &lt;= {bounds[2]} AND\n                bbox.ymax &gt;= {bounds[1]} AND bbox.ymin &lt;= {bounds[3]}\n    ) TO '{temp_file}' (FORMAT PARQUET);\n    \"\"\"\n\n    con.execute(query)\n    df = pd.read_parquet(temp_file)\n    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n\n    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=WGS84_CRS)\n\n\nif os.path.exists(BUILDINGS_PATH):\n    buildings = gpd.read_parquet(BUILDINGS_PATH)\nelse:\n    buildings = fetch_buildings(renabap_pba_intersect)\n\n\nbuildings_proj = buildings.to_crs(USE_CRS)\n\nbuildings_proj = buildings_proj.clip(la_plata)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#metodología",
    "href": "renabap_final.html#metodología",
    "title": "4  RENABAP",
    "section": "4.5 Metodología",
    "text": "4.5 Metodología\nEn versiones anteriores de este análisis, el trabajo se realizó mediante una interpolación areal simple del porcentaje de superposición de cada área de peligro de inundación con los asentamientos informales. Este enfoque presenta dos problemas fundamentales que este estudio busca abordar.\nEl primer problema es que la interpolación areal es inherentemente imprecisa, ya que asume lo que se conoce como el problema de la unidad areal modificable y presupone que la población se distribuye uniformemente en el espacio. Sin embargo, estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución (Smith et al. 2019). La población, de hecho, no se distribuye uniformemente en el espacio; frecuentemente los edificios se agrupan ya sea alejándose de las zonas de peligro de inundación o concentrándose en zonas de alto peligro de inundación. Por tanto, es fundamental comprender con estimaciones más precisas dónde vive realmente la gente.\nEl segundo problema radica en que los propios datos del RENABAP, según nuestro análisis aquí presentado, parecen contar dramáticamente de forma incorrecta, frecuentemente por un factor de dos o más, el número de familias que aparentemente viven en un asentamiento informal basándose en el número de edificaciones. Esto probablemente se debe a errores de proyección acumulados a lo largo del tiempo y a la dificultad de mantener actualizados los datos de asentamientos informales.\nEsta es una de las grandes ventajas de las huellas de edificios globales derivadas de satélite que han surgido en los últimos años de Google-Microsoft-OSM, entre otros. Uno de los objetivos principales de este análisis es demostrar que estos datos de huellas de edificios pueden utilizarse para estimar la exposición de manera más precisa, tanto en términos de precisión metodológica como en términos de mejora sobre conjuntos de datos nacionales existentes como el RENABAP.\nPor tanto, en este estudio utilizamos el número de edificios que intersectan con las diferentes zonas de peligro de inundación como indicador de exposición, asumiendo que un edificio equivale aproximadamente a una familia, supuesto que el propio RENABAP asume en sus datos.\n\n\nMostrar código\n## Análisis de exposición: edificios por barrio y cuenca por zona de peligro\n# Versión concisa con spatial joins (sin warnings)\n\nimport geopandas as gpd\n\n# Definir orden de prioridad de peligro y simplificar\nhazard_priority = {\"alta\": 3, \"media\": 2, \"baja\": 1}\npeligro_simple = peligro_la_plata.dissolve(by=\"PELIGROSID\").reset_index()\n\n# === ANÁLISIS POR BARRIO ===\n# Spatial joins\nbuildings_with_barrios = gpd.sjoin(\n    buildings_proj,\n    renabap_pba_intersect[\n        [\"id_renabap\", \"nombre_barrio\", \"familias_aproximadas\", \"geometry\"]\n    ],\n    how=\"inner\",\n    predicate=\"within\",\n)\nbuildings_with_barrios = buildings_with_barrios.drop(columns=[\"index_right\"]).copy()\n\nbuildings_with_peligro_barrio = gpd.sjoin(\n    buildings_with_barrios,\n    peligro_simple[[\"PELIGROSID\", \"geometry\"]],\n    how=\"left\",\n    predicate=\"within\",\n)\n\n# Resolver duplicados y contar\nbuildings_barrio_final = buildings_with_peligro_barrio.dropna(\n    subset=[\"PELIGROSID\"]\n).copy()\nbuildings_barrio_final.loc[:, \"prioridad\"] = buildings_barrio_final[\"PELIGROSID\"].map(\n    hazard_priority\n)\nbuildings_barrio_unique = buildings_barrio_final.sort_values(\n    \"prioridad\", ascending=False\n).drop_duplicates(subset=buildings_barrio_final.geometry.name, keep=\"first\")\n\n# Calcular exposición por barrio\nedificios_por_barrio_peligro = (\n    buildings_barrio_unique.groupby([\"id_renabap\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"edificios_expuestos\")\n)\n\ntotal_edificios_barrio = (\n    buildings_with_barrios.groupby(\"id_renabap\")\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nexposure_barrio = edificios_por_barrio_peligro.merge(\n    total_edificios_barrio, on=\"id_renabap\"\n)\nexposure_barrio[\"proporcion\"] = (\n    exposure_barrio[\"edificios_expuestos\"] / exposure_barrio[\"total_edificios\"]\n)\n\nfamilias_barrio = renabap_pba_intersect[\n    [\"id_renabap\", \"nombre_barrio\", \"familias_aproximadas\"]\n].drop_duplicates()\nfinal_exposure_barrio = exposure_barrio.merge(familias_barrio, on=\"id_renabap\")\nfinal_exposure_barrio[\"fam_expuestas\"] = (\n    final_exposure_barrio[\"proporcion\"] * final_exposure_barrio[\"familias_aproximadas\"]\n)\n\nresultado_exposicion_barrio = final_exposure_barrio[\n    [\n        \"id_renabap\",\n        \"nombre_barrio\",\n        \"PELIGROSID\",\n        \"fam_expuestas\",\n        \"edificios_expuestos\",\n    ]\n].rename(columns={\"PELIGROSID\": \"peligrosidad\"})\n\n# === ANÁLISIS POR CUENCA ===\n# Usar edificios ya en barrios para análisis de cuenca\nbuildings_in_settlements = buildings_with_barrios.copy()\n\n# Spatial joins para cuenca\nbuildings_with_cuenca = gpd.sjoin(\n    buildings_in_settlements,\n    cuencas[[\"Cuenca\", \"eje\", \"geometry\"]],\n    how=\"left\",\n    predicate=\"within\",\n)\nbuildings_with_cuenca = buildings_with_cuenca.drop(columns=[\"index_right\"]).copy()\n\nbuildings_with_peligro_cuenca = gpd.sjoin(\n    buildings_in_settlements,\n    peligro_simple[[\"PELIGROSID\", \"geometry\"]],\n    how=\"left\",\n    predicate=\"within\",\n)\n\n# Combinar y filtrar\nbuildings_cuenca_final = buildings_in_settlements.copy()\nbuildings_cuenca_final.loc[:, \"Cuenca\"] = buildings_with_cuenca[\"Cuenca\"]\nbuildings_cuenca_final.loc[:, \"eje\"] = buildings_with_cuenca[\"eje\"]\nbuildings_cuenca_final.loc[:, \"PELIGROSID\"] = buildings_with_peligro_cuenca[\n    \"PELIGROSID\"\n]\nbuildings_cuenca_final = buildings_cuenca_final.dropna(\n    subset=[\"Cuenca\", \"PELIGROSID\"]\n).copy()\n\n# Resolver duplicados y calcular exposición por cuenca\nbuildings_cuenca_final.loc[:, \"prioridad\"] = buildings_cuenca_final[\"PELIGROSID\"].map(\n    hazard_priority\n)\nbuildings_cuenca_unique = buildings_cuenca_final.sort_values(\n    \"prioridad\", ascending=False\n).drop_duplicates(subset=buildings_cuenca_final.geometry.name, keep=\"first\")\n\nedificios_por_cuenca_peligro = (\n    buildings_cuenca_unique.groupby([\"Cuenca\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"edificios_expuestos\")\n)\n\ntotal_edificios_cuenca = (\n    buildings_with_cuenca.dropna(subset=[\"Cuenca\"])\n    .groupby(\"Cuenca\")\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nexposure_cuenca = edificios_por_cuenca_peligro.merge(\n    total_edificios_cuenca, on=\"Cuenca\"\n)\nexposure_cuenca[\"proporcion\"] = (\n    exposure_cuenca[\"edificios_expuestos\"] / exposure_cuenca[\"total_edificios\"]\n)\n\nfamilias_cuenca = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"Cuenca\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\n\nfinal_exposure_cuenca = exposure_cuenca.merge(familias_cuenca, on=\"Cuenca\")\nfinal_exposure_cuenca[\"fam_expuestas\"] = (\n    final_exposure_cuenca[\"proporcion\"] * final_exposure_cuenca[\"familias_aproximadas\"]\n)\n\nresultado_exposicion_cuenca = final_exposure_cuenca[\n    [\"Cuenca\", \"PELIGROSID\", \"fam_expuestas\", \"edificios_expuestos\"]\n].rename(columns={\"PELIGROSID\": \"peligrosidad\"})\n\n# === ANÁLISIS POR EJE ===\n# Usar los edificios ya procesados con cuenca y peligro\nbuildings_eje_final = buildings_cuenca_final.dropna(subset=[\"eje\"]).copy()\n\n# Resolver duplicados por prioridad de peligro\nbuildings_eje_final.loc[:, \"prioridad\"] = buildings_eje_final[\"PELIGROSID\"].map(\n    hazard_priority\n)\nbuildings_eje_unique = buildings_eje_final.sort_values(\n    \"prioridad\", ascending=False\n).drop_duplicates(subset=buildings_eje_final.geometry.name, keep=\"first\")\n\n# Calcular exposición por eje y peligrosidad\nedificios_por_eje_peligro = (\n    buildings_eje_unique.groupby([\"eje\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"edificios_expuestos\")\n)\n\ntotal_edificios_eje = (\n    buildings_with_cuenca.dropna(subset=[\"eje\"])\n    .groupby(\"eje\")\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nexposure_eje = edificios_por_eje_peligro.merge(total_edificios_eje, on=\"eje\")\nexposure_eje[\"proporcion\"] = (\n    exposure_eje[\"edificios_expuestos\"] / exposure_eje[\"total_edificios\"]\n)\n\nfamilias_por_eje = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"eje\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\n\nfinal_exposure_eje = exposure_eje.merge(familias_por_eje, on=\"eje\")\nfinal_exposure_eje[\"fam_expuestas\"] = (\n    final_exposure_eje[\"proporcion\"] * final_exposure_eje[\"familias_aproximadas\"]\n)\n\nresultado_exposicion_eje = final_exposure_eje[\n    [\"eje\", \"PELIGROSID\", \"fam_expuestas\", \"edificios_expuestos\"]\n].rename(columns={\"PELIGROSID\": \"peligrosidad\"})\n\n\n\n4.5.1 Análisis de las limitaciones de los datos del RENABAP\nObservamos que los datos más recientes del RENABAP de 2023 frecuentemente y significativamente subestiman el número total de familias por asentamiento informal. Los datos de 2023 fueron basados en proyecciones derivadas del censo de 2010. Aquí comparamos estos datos con el número de huellas de edificios por asentamiento informal. Podemos asumir razonablemente que hay mínimamente una correspondencia uno a uno entre unidades de vivienda y familias, que es lo que los propios datos del RENABAP asumen. Encontramos que usando este método, los datos del RENABAP frecuentemente están desactualizados por una cantidad significativa. En promedio, subestiman el número de estructuras habitacionales por 41%, lo que equivale a aproximadamente 1.7 veces más familias por asentamiento de lo que aparecen en los datos del RENABAP.\n\n\nMostrar código\nimport matplotlib.pyplot as plt\n\n# Calcular familias estimadas basadas en edificios (1.1 familias por edificio)\nratio_fam_edif = (\n    buildings_with_barrios.groupby([\"id_renabap\", \"familias_aproximadas\"])\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nratio_fam_edif[\"familias_estimadas_edificios\"] = ratio_fam_edif[\"total_edificios\"] * 1.1\n# Calcular el error porcentual: (RENABAP - Edificios) / Edificios * 100\nratio_fam_edif[\"error_porcentual\"] = (\n    (\n        ratio_fam_edif[\"familias_aproximadas\"]\n        - ratio_fam_edif[\"familias_estimadas_edificios\"]\n    )\n    / ratio_fam_edif[\"familias_estimadas_edificios\"]\n) * 100\n\n# Crear histograma\nplt.figure(figsize=(12, 6))\nplt.hist(\n    ratio_fam_edif[\"error_porcentual\"],\n    bins=30,\n    edgecolor=\"none\",\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Error de Estimación de RENABAP vs Estimación por Edificios\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Error Porcentual (%)\", fontsize=12)\nplt.ylabel(\"Frecuencia (Número de Barrios)\", fontsize=12)\n\n# Agregar líneas de referencia\nmean_error = ratio_fam_edif[\"error_porcentual\"].mean()\nmedian_error = ratio_fam_edif[\"error_porcentual\"].median()\n\nplt.axvline(\n    mean_error,\n    color=\"black\",\n    linestyle=\"--\",\n    linewidth=2,\n    label=f\"Error promedio: {mean_error:.1f}%\",\n)\nplt.axvline(\n    median_error,\n    color=\"black\",\n    linestyle=\"dotted\",\n    linewidth=2,\n    label=f\"Error mediano: {median_error:.1f}%\",\n)\n\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4.2: Distribución del error porcentual en las estimaciones del RENABAP comparado con estimaciones basadas en edificios\n\n\n\n\n\nTambién podemos examinar imágenes satelitales de un asentamiento informal de muestra con las huellas de edificios superpuestas para tener una idea de la veracidad de los datos. Aquí está un barrio llamado Los Pinos, en el cual mapeamos la extensión del RENABAP del barrio y las huellas de los edificios dentro de él. Las estimaciones del RENABAP dicen que este asentamiento informal tiene solo 72 familias. Nuestros datos cuentan 519 edificios. Si usamos la estimación del RENABAP de aproximadamente 1.1 familias por edificio, que es lo que calculan en sus datos originales, estamos hablando de un total de 570 familias, que es casi ocho veces más de lo que los datos del RENABAP contabilizan.\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport contextily as cx\n\n# Filtrar para obtener solo el barrio con id_renabap 5688\nbarrio_5688 = renabap_pba_intersect[renabap_pba_intersect[\"id_renabap\"] == 5688].copy()\n\nif len(barrio_5688) == 0:\n    print(\"No se encontró el barrio con id_renabap 5688\")\nelse:\n    # Obtener edificios en este barrio\n    buildings_5688 = buildings_with_barrios[\n        buildings_with_barrios[\"id_renabap\"] == 5688\n    ].copy()\n\n    # Convertir a Web Mercator\n    barrio_5688_3857 = barrio_5688.to_crs(WEB_MERCATOR_CRS)\n    buildings_5688_3857 = buildings_5688.to_crs(WEB_MERCATOR_CRS)\n\n    # Crear el mapa\n    fig, ax = plt.subplots(figsize=(12, 10))\n\n    # Configurar límites basados en el barrio\n    bounds = barrio_5688_3857.total_bounds\n    margin = 50  # metros\n    ax.set_xlim(bounds[0] - margin, bounds[2] + margin)\n    ax.set_ylim(bounds[1] - margin, bounds[3] + margin)\n\n    # Agregar basemap de contextily\n    cx.add_basemap(ax, crs=\"EPSG:3857\", source=cx.providers.Esri.WorldImagery)\n\n    # Plot de edificios con contorno naranja (sin fill)\n    buildings_5688_3857.plot(\n        ax=ax, facecolor=\"none\", edgecolor=PLASMA_CMAP(1), linewidth=1\n    )\n\n    # Plot del límite del barrio con estilo consistente\n    barrio_5688_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"white\",  # White for satellite imagery visibility\n        linewidth=3,\n        linestyle=\"--\",\n        zorder=10,\n    )\n\n    # Limpiar el mapa\n    barrio_nombre = barrio_5688[\"nombre_barrio\"].iloc[0]\n    ax.set_title(\n        f\"Barrio {barrio_nombre} - Límites y Edificaciones\",\n        fontsize=14,\n        fontweight=\"bold\",\n        pad=20,\n    )\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"\")\n    ax.set_ylabel(\"\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n\n    # Agregar leyenda simple\n    legend_elements = [\n        plt.Line2D([0], [0], color=\"white\", linewidth=3, label=\"Límite del barrio\"),\n        plt.Line2D([0], [0], color=PLASMA_CMAP(1), linewidth=1, label=\"Edificaciones\"),\n    ]\n    ax.legend(handles=legend_elements, loc=\"upper right\")\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\nFigure 4.3: Ejemplo de discrepancia en los datos del RENABAP: el barrio Los Pinos con límites oficiales y edificaciones detectadas",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#metodología-y-procesamiento",
    "href": "renabap_final.html#metodología-y-procesamiento",
    "title": "4  RENABAP",
    "section": "4.6 Metodología y procesamiento",
    "text": "4.6 Metodología y procesamiento\n\n4.6.1 Exposición por barrio\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport contextily as cx\n\n# Colores para peligrosidad\nPELIGROSIDAD_COLORS = {\n    \"alta\": PLASMA_CMAP(0.8),\n    \"media\": PLASMA_CMAP(0.5),\n    \"baja\": PLASMA_CMAP(0.2),\n}\n\n\n# Preparar datos - solo alta y media\nexposure_data = resultado_exposicion_barrio[\n    resultado_exposicion_barrio[\"peligrosidad\"].isin([\"alta\", \"media\"])\n].copy()\n\n# Merge con geometrías para obtener centroides\nexposure_gdf = exposure_data.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"geometry\"]], on=\"id_renabap\"\n)\nexposure_gdf = gpd.GeoDataFrame(exposure_gdf, geometry=\"geometry\", crs=USE_CRS)\n\n# Convertir a Web Mercator para el plotting\nexposure_gdf_3857 = exposure_gdf.to_crs(\"EPSG:3857\")\nla_plata_3857 = la_plata.to_crs(\"EPSG:3857\")\n\n# Crear el mapa\nfig, ax = plt.subplots(figsize=(12, 10))\n\n# Configurar límites\nbounds = la_plata_3857.total_bounds\nmargin = 2000  # metros\nax.set_xlim(bounds[0] - margin, bounds[2] + margin)\nax.set_ylim(bounds[1] - margin, bounds[3] + margin)\n\n# Agregar basemap de contextily\ncx.add_basemap(\n    ax, crs=\"EPSG:3857\", source=cx.providers.CartoDB.PositronNoLabels, alpha=0.7\n)\n\n# Plot de puntos con jitter\nnp.random.seed(42)\nplotting_order = [\"media\", \"alta\"]\n\nfor peligrosidad in plotting_order:\n    level_data = exposure_gdf_3857[exposure_gdf_3857[\"peligrosidad\"] == peligrosidad]\n    for _, row in level_data.iterrows():\n        centroid = row[\"geometry\"].centroid\n        jitter_x = np.random.uniform(-200, 200)\n        jitter_y = np.random.uniform(-200, 200)\n        x_pos = centroid.x + jitter_x\n        y_pos = centroid.y + jitter_y\n        color = PELIGROSIDAD_COLORS[row[\"peligrosidad\"]]\n        size = max(10, row[\"edificios_expuestos\"] * 0.5 + 15)\n        ax.scatter(\n            x_pos,\n            y_pos,\n            s=size,\n            color=color,\n            alpha=0.9,\n            edgecolors=\"white\",\n            linewidth=1.0,\n        )\n\n# Leyenda de peligrosidad\nlegend_elements_peligro = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=PELIGROSIDAD_COLORS[\"alta\"],\n        markersize=8,\n        label=\"Alta\",\n    ),\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=PELIGROSIDAD_COLORS[\"media\"],\n        markersize=8,\n        label=\"Media\",\n    ),\n]\n\n# Leyenda de tamaño\nbuilding_values = [100, 500, 1000]\nlegend_elements_size = []\nfor val in building_values:\n    size = max(10, val * 0.5 + 15)\n    legend_elements_size.append(\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"o\",\n            color=\"w\",\n            markerfacecolor=\"gray\",\n            markersize=np.sqrt(size / 10),\n            label=f\"{val} edificios\",\n        )\n    )\n\n# Crear leyendas lado a lado en bottom right\nlegend1 = ax.legend(\n    handles=legend_elements_peligro,\n    title=\"Nivel de peligrosidad\",\n    loc=\"lower right\",\n    bbox_to_anchor=(0.85, 0),\n)\nax.add_artist(legend1)\n\nlegend2 = ax.legend(\n    handles=legend_elements_size,\n    title=\"Edificios expuestos\",\n    loc=\"lower right\",\n    bbox_to_anchor=(1.0, 0),\n)\n\n# Agregar el contorno de La Plata como capa superior\nadd_la_plata_outline(ax)\n\n# Agregar flecha norte para consistencia\nadd_north_arrow(ax)\n\n# Limpiar el mapa - quitar bordes, ticks, etc.\nax.set_title(\n    \"Exposición de Barrios Populares por Nivel de Peligrosidad\",\n    fontsize=14,\n    fontweight=\"bold\",\n    pad=20,\n)\nax.set_axis_off()\n\nplt.tight_layout()\nplt.show()\n\nimport matplotlib.pyplot as plt\n\n# Filtrar solo exposición alta y agregar por nombre de barrio (excluyendo \"Sin Nombre\")\nedificios_alta_por_nombre = (\n    resultado_exposicion_barrio[\n        (resultado_exposicion_barrio[\"peligrosidad\"] == \"alta\")\n        & (resultado_exposicion_barrio[\"nombre_barrio\"] != \"Sin Nombre\")\n    ]\n    .groupby(\"nombre_barrio\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n    .head(25)\n)\n\n# Crear el gráfico de barras\nplt.figure(figsize=(12, 8))\nbars = plt.bar(\n    range(len(edificios_alta_por_nombre)),\n    edificios_alta_por_nombre[\"edificios_expuestos\"],\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n    edgecolor=\"none\",\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Top 25 Barrios por Edificaciones Expuestas a Peligro Alto\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Barrios\", fontsize=12)\nplt.ylabel(\"Edificaciones Expuestas (Peligro Alto)\", fontsize=12)\nplt.xticks(\n    range(len(edificios_alta_por_nombre)),\n    edificios_alta_por_nombre[\"nombre_barrio\"],\n    rotation=45,\n    ha=\"right\",\n)\n\n# Agregar valores en las barras\nfor i, bar in enumerate(bars):\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 5,\n        f\"{int(height)}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=9,\n    )\n\nplt.tight_layout()\nplt.show()\n\nshow(resultado_exposicion_barrio)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n4.6.2 Exposición por cuenca\n\n\nMostrar código\nimport matplotlib.pyplot as plt\n\n# Filtrar solo exposición alta y agregar por cuenca\nedificios_alta_por_cuenca = (\n    resultado_exposicion_cuenca[resultado_exposicion_cuenca[\"peligrosidad\"] == \"alta\"]\n    .groupby(\"Cuenca\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n)\n\n# Crear el gráfico de barras\nplt.figure(figsize=(12, 6))\nbars = plt.bar(\n    range(len(edificios_alta_por_cuenca)),\n    edificios_alta_por_cuenca[\"edificios_expuestos\"],\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n    edgecolor=\"none\",\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Top Cuencas por Edificaciones Expuestas a Peligro Alto\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Cuencas\", fontsize=12)\nplt.ylabel(\"Edificaciones Expuestas (Peligro Alto)\", fontsize=12)\nplt.xticks(\n    range(len(edificios_alta_por_cuenca)),\n    edificios_alta_por_cuenca[\"Cuenca\"],\n    rotation=45,\n    ha=\"right\",\n)\n\n# Agregar valores en las barras\nfor i, bar in enumerate(bars):\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 10,\n        f\"{int(height)}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=10,\n    )\n\nplt.tight_layout()\nplt.show()\n\n\nshow(resultado_exposicion_cuenca)\n\n\n\n\n\n\n\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n4.6.3 Exposición por eje\n\n\nMostrar código\nimport matplotlib.pyplot as plt\n\n# Filtrar solo exposición alta y agregar por eje\nedificios_alta_por_eje = (\n    resultado_exposicion_eje[resultado_exposicion_eje[\"peligrosidad\"] == \"alta\"]\n    .groupby(\"eje\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n)\n\n# Crear el gráfico de barras\nplt.figure(figsize=(10, 6))\nbars = plt.bar(\n    range(len(edificios_alta_por_eje)),\n    edificios_alta_por_eje[\"edificios_expuestos\"],\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n    edgecolor=\"none\",\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Ejes por Edificaciones Expuestas a Peligro Alto\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Ejes\", fontsize=12)\nplt.ylabel(\"Edificaciones Expuestas (Peligro Alto)\", fontsize=12)\nplt.xticks(\n    range(len(edificios_alta_por_eje)),\n    edificios_alta_por_eje[\"eje\"],\n    rotation=45,\n    ha=\"right\",\n)\n\n# Agregar valores en las barras\nfor i, bar in enumerate(bars):\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 10,\n        f\"{int(height)}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=10,\n    )\n\nplt.tight_layout()\nplt.show()\n\nshow(resultado_exposicion_eje)\n\n\n\n\n\n\n\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#conclusiones",
    "href": "renabap_final.html#conclusiones",
    "title": "4  RENABAP",
    "section": "4.8 Conclusiones",
    "text": "4.8 Conclusiones\nLos datos de huellas de edificios nos permiten realizar evaluaciones significativamente más precisas de la exposición poblacional en asentamientos informales en todo el partido. Este análisis identifica aproximadamente 23,000 edificaciones adicionales que creemos están presentes, equivalentes a potencialmente alrededor de 100,000 personas adicionales que no han sido mapeadas en los datos del RENABAP. Por tanto, representan un recurso realmente importante para la planificación de gestión de riesgo.\nEncontramos que Villa Montoro contiene el mayor número de edificaciones y, por tanto, población expuesta a peligro alto con 555 edificaciones, seguido por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. La Cuenca Arroyo del Gato presenta el mayor número de población expuesta con 2,662 edificaciones, seguida por la Cuenca A° Maldonado con 1,000. Lo mismo es cierto para los ejes, donde el central tiene 2,662 y el sudoeste tiene 1,000, correspondiendo exactamente a estas cifras.\n\n\n\n\nRomanazzi, Pablo et al. 2019. Plan de Reducción Del Riesgo Por Inundaciones En La Región de La Plata. Edited by Sebastián Guerrini, Pablo Morosi, Eduardo Pablo Spinelli, and Josefina López MacKenzie. 1st ed. La Plata: Universidad Nacional de La Plata. Facultad de Ingeniería; Municipalidad de La Plata. https://sedici.unlp.edu.ar/bitstream/handle/10915/165109/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of Flood Exposure in Developing Countries Using High-Resolution Population Data.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by VIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#procesamiento-y-resultados",
    "href": "renabap_final.html#procesamiento-y-resultados",
    "title": "4  RENABAP",
    "section": "4.6 Procesamiento y resultados",
    "text": "4.6 Procesamiento y resultados\nLa exposición en asentamientos informales se concentra principalmente en los alrededores del casco urbano de La Plata. El análisis revela una distribución característica donde un número pequeño de barrios presenta exposición muy alta, seguido por un grupo de exposición media, y luego una disminución gradual. Villa Montoro lidera con 555 edificaciones expuestas a peligro alto, seguida por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. Otros barrios con exposición significativa incluyen Aeropuerto (258), 48 y 144 (225), San Luis (206), y El Uido (132).\nA nivel de cuencas hidrográficas, la Cuenca Arroyo del Gato concentra la mayor exposición con 2,662 edificaciones expuestas a peligro alto, principalmente debido a la presencia de Villa Montoro y otros asentamientos importantes. Le sigue la Cuenca A° Maldonado con 1,000 edificaciones y la Cuenca Arroyo Martín-Carnaval con 368. Esta concentración en la Cuenca Arroyo del Gato refleja tanto la densidad de asentamientos informales como su ubicación en zonas de alto riesgo hidrológico.\n\n4.6.1 Exposición por barrio\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport contextily as cx\n\n# Colores para peligrosidad\nPELIGROSIDAD_COLORS = {\n    \"alta\": PLASMA_CMAP(0.8),\n    \"media\": PLASMA_CMAP(0.5),\n    \"baja\": PLASMA_CMAP(0.2),\n}\n\n\n# Preparar datos - solo alta y media\nexposure_data = resultado_exposicion_barrio[\n    resultado_exposicion_barrio[\"peligrosidad\"].isin([\"alta\", \"media\"])\n].copy()\n\n# Merge con geometrías para obtener centroides\nexposure_gdf = exposure_data.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"geometry\"]], on=\"id_renabap\"\n)\nexposure_gdf = gpd.GeoDataFrame(exposure_gdf, geometry=\"geometry\", crs=USE_CRS)\n\n# Convertir a Web Mercator para el plotting\nexposure_gdf_3857 = exposure_gdf.to_crs(\"EPSG:3857\")\nla_plata_3857 = la_plata.to_crs(\"EPSG:3857\")\n\n# Crear el mapa\nfig, ax = plt.subplots(figsize=(12, 10))\n\n# Configurar límites\nbounds = la_plata_3857.total_bounds\nmargin = 2000  # metros\nax.set_xlim(bounds[0] - margin, bounds[2] + margin)\nax.set_ylim(bounds[1] - margin, bounds[3] + margin)\n\n# Agregar basemap de contextily\ncx.add_basemap(\n    ax, crs=\"EPSG:3857\", source=cx.providers.CartoDB.PositronNoLabels, alpha=0.7\n)\n\n# Plot de puntos con jitter\nnp.random.seed(42)\nplotting_order = [\"media\", \"alta\"]\n\nfor peligrosidad in plotting_order:\n    level_data = exposure_gdf_3857[exposure_gdf_3857[\"peligrosidad\"] == peligrosidad]\n    for _, row in level_data.iterrows():\n        centroid = row[\"geometry\"].centroid\n        jitter_x = np.random.uniform(-200, 200)\n        jitter_y = np.random.uniform(-200, 200)\n        x_pos = centroid.x + jitter_x\n        y_pos = centroid.y + jitter_y\n        color = PELIGROSIDAD_COLORS[row[\"peligrosidad\"]]\n        size = max(10, row[\"edificios_expuestos\"] * 0.5 + 15)\n        ax.scatter(\n            x_pos,\n            y_pos,\n            s=size,\n            color=color,\n            alpha=0.9,\n            edgecolors=\"white\",\n            linewidth=1.0,\n        )\n\n# Leyenda de peligrosidad\nlegend_elements_peligro = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=PELIGROSIDAD_COLORS[\"alta\"],\n        markersize=8,\n        label=\"Alta\",\n    ),\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=PELIGROSIDAD_COLORS[\"media\"],\n        markersize=8,\n        label=\"Media\",\n    ),\n]\n\n# Leyenda de tamaño\nbuilding_values = [100, 500, 1000]\nlegend_elements_size = []\nfor val in building_values:\n    size = max(10, val * 0.5 + 15)\n    legend_elements_size.append(\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"o\",\n            color=\"w\",\n            markerfacecolor=\"gray\",\n            markersize=np.sqrt(size / 10),\n            label=f\"{val} edificios\",\n        )\n    )\n\n# Crear leyendas lado a lado en bottom right\nlegend1 = ax.legend(\n    handles=legend_elements_peligro,\n    title=\"Nivel de peligrosidad\",\n    loc=\"lower right\",\n    bbox_to_anchor=(0.85, 0),\n)\nax.add_artist(legend1)\n\nlegend2 = ax.legend(\n    handles=legend_elements_size,\n    title=\"Edificios expuestos\",\n    loc=\"lower right\",\n    bbox_to_anchor=(1.0, 0),\n)\n\n# Agregar el contorno de La Plata como capa superior\nadd_la_plata_outline(ax)\n\n# Agregar flecha norte para consistencia\nadd_north_arrow(ax)\n\n# Limpiar el mapa - quitar bordes, ticks, etc.\nax.set_title(\n    \"Exposición de Barrios Populares por Nivel de Peligrosidad\",\n    fontsize=14,\n    fontweight=\"bold\",\n    pad=20,\n)\nax.set_axis_off()\n\nplt.tight_layout()\nplt.show()\n\n# | label: fig-top-barrios-peligro-alto\n# | fig-cap: \"Los 25 barrios con mayor número de edificaciones expuestas a peligro alto de inundación\"\n\nimport matplotlib.pyplot as plt\n\n# Filtrar solo exposición alta y agregar por nombre de barrio (excluyendo \"Sin Nombre\")\nedificios_alta_por_nombre = (\n    resultado_exposicion_barrio[\n        (resultado_exposicion_barrio[\"peligrosidad\"] == \"alta\")\n        & (resultado_exposicion_barrio[\"nombre_barrio\"] != \"Sin Nombre\")\n    ]\n    .groupby(\"nombre_barrio\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n    .head(25)\n)\n\n# Crear el gráfico de barras\nplt.figure(figsize=(12, 8))\nbars = plt.bar(\n    range(len(edificios_alta_por_nombre)),\n    edificios_alta_por_nombre[\"edificios_expuestos\"],\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n    edgecolor=\"none\",\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Top 25 Barrios por Edificaciones Expuestas a Peligro Alto\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Barrios\", fontsize=12)\nplt.ylabel(\"Edificaciones Expuestas (Peligro Alto)\", fontsize=12)\nplt.xticks(\n    range(len(edificios_alta_por_nombre)),\n    edificios_alta_por_nombre[\"nombre_barrio\"],\n    rotation=45,\n    ha=\"right\",\n)\n\n# Agregar valores en las barras\nfor i, bar in enumerate(bars):\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 5,\n        f\"{int(height)}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=9,\n    )\n\nplt.tight_layout()\nplt.show()\n\nshow(resultado_exposicion_barrio)\n\n\n\n\n\n\n\n\n\n\n\n(a) Mapa de exposición de barrios populares por nivel de peligrosidad de inundación\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n(c)\n\n\n\n\n\nFigure 4.4\n\n\n\n\n\n\n4.6.2 Exposición por cuenca\n\n\nMostrar código\nimport matplotlib.pyplot as plt\n\n# Filtrar solo exposición alta y agregar por cuenca\nedificios_alta_por_cuenca = (\n    resultado_exposicion_cuenca[resultado_exposicion_cuenca[\"peligrosidad\"] == \"alta\"]\n    .groupby(\"Cuenca\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n)\n\n# Crear el gráfico de barras\nplt.figure(figsize=(12, 6))\nbars = plt.bar(\n    range(len(edificios_alta_por_cuenca)),\n    edificios_alta_por_cuenca[\"edificios_expuestos\"],\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n    edgecolor=\"none\",\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Top Cuencas por Edificaciones Expuestas a Peligro Alto\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Cuencas\", fontsize=12)\nplt.ylabel(\"Edificaciones Expuestas (Peligro Alto)\", fontsize=12)\nplt.xticks(\n    range(len(edificios_alta_por_cuenca)),\n    edificios_alta_por_cuenca[\"Cuenca\"],\n    rotation=45,\n    ha=\"right\",\n)\n\n# Agregar valores en las barras\nfor i, bar in enumerate(bars):\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 10,\n        f\"{int(height)}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=10,\n    )\n\nplt.tight_layout()\nplt.show()\n\n\nshow(resultado_exposicion_cuenca)\n\n\n\n\n\n\n\n\n\n\n\n(a) Cuencas hidrográficas ordenadas por número de edificaciones expuestas a peligro alto de inundación\n\n\n\n\n\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n(b)\n\n\n\n\n\nFigure 4.5\n\n\n\n\n\n\n4.6.3 Exposición por eje\n\n\nMostrar código\nimport matplotlib.pyplot as plt\n\n# Filtrar solo exposición alta y agregar por eje\nedificios_alta_por_eje = (\n    resultado_exposicion_eje[resultado_exposicion_eje[\"peligrosidad\"] == \"alta\"]\n    .groupby(\"eje\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n)\n\n# Crear el gráfico de barras\nplt.figure(figsize=(10, 6))\nbars = plt.bar(\n    range(len(edificios_alta_por_eje)),\n    edificios_alta_por_eje[\"edificios_expuestos\"],\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n    edgecolor=\"none\",\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Ejes por Edificaciones Expuestas a Peligro Alto\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Ejes\", fontsize=12)\nplt.ylabel(\"Edificaciones Expuestas (Peligro Alto)\", fontsize=12)\nplt.xticks(\n    range(len(edificios_alta_por_eje)),\n    edificios_alta_por_eje[\"eje\"],\n    rotation=45,\n    ha=\"right\",\n)\n\n# Agregar valores en las barras\nfor i, bar in enumerate(bars):\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 10,\n        f\"{int(height)}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=10,\n    )\n\nplt.tight_layout()\nplt.show()\n\nshow(resultado_exposicion_eje)\n\n\n\n\n\n\n\n\n\n\n\n(a) Ejes territoriales ordenados por número de edificaciones expuestas a peligro alto de inundación\n\n\n\n\n\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n(b)\n\n\n\n\n\nFigure 4.6",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap_final.html#comparativa-de-periodos-de-retorno",
    "href": "renabap_final.html#comparativa-de-periodos-de-retorno",
    "title": "4  RENABAP",
    "section": "4.7 Comparativa de periodos de retorno",
    "text": "4.7 Comparativa de periodos de retorno\n\nMostrar código\n# Preparar datos de cuenca Maldonado para clipping\ncuenca_maldonado = cuencas[cuencas[\"Cuenca\"] == \"Cuenca A° Maldonado\"].copy()\n\n# === MAPA PMP ===\n# Clipear peligro PMP a cuenca Maldonado\npeligro_pmp_maldonado = gpd.clip(peligro_la_plata, cuenca_maldonado)\npeligro_pmp_maldonado_3857 = peligro_pmp_maldonado.to_crs(WEB_MERCATOR_CRS)\n\n# Ordenar categorías para mapeo correcto\npeligro_pmp_maldonado_3857[\"PELIGROSID_ordered\"] = pd.Categorical(\n    peligro_pmp_maldonado_3857[\"PELIGROSID\"],\n    categories=[\"baja\", \"media\", \"alta\"],\n    ordered=True,\n)\n\nfig1, ax1 = create_consistent_map(\"PMP (Precipitación Máxima Probable)\", boundary_gdf=cuenca_maldonado)\npeligro_pmp_maldonado_3857.plot(\n    ax=ax1,\n    column=\"PELIGROSID_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    zorder=5,\n)\nplt.tight_layout()\nplt.show()\n\n# === MAPA R100 ===\npelig_100_maldonado = gpd.read_file(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp\")\npelig_100_maldonado = pelig_100_maldonado.to_crs(USE_CRS)\n\n# Clipear a cuenca Maldonado\npelig_100_maldonado_clipped = gpd.clip(pelig_100_maldonado, cuenca_maldonado)\npelig_100_maldonado_clipped_3857 = pelig_100_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Ordenar categorías\npelig_100_maldonado_clipped_3857[\"peli_ordered\"] = pd.Categorical(\n    pelig_100_maldonado_clipped_3857[\"peli\"],\n    categories=[\"Bajo\", \"Medio\", \"Alto\"],\n    ordered=True,\n)\n\nfig2, ax2 = create_consistent_map(\"R100 (Período de retorno 100 años)\", boundary_gdf=cuenca_maldonado)\npelig_100_maldonado_clipped_3857.plot(\n    ax=ax2,\n    column=\"peli_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    zorder=5,\n)\nplt.tight_layout()\nplt.show()\n\n# === MAPA R25 ===\npelig_25_maldonado = gpd.read_file(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp\")\npelig_25_maldonado = pelig_25_maldonado.to_crs(USE_CRS)\n\n# Clipear a cuenca Maldonado\npelig_25_maldonado_clipped = gpd.clip(pelig_25_maldonado, cuenca_maldonado)\npelig_25_maldonado_clipped_3857 = pelig_25_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Ordenar categorías\npelig_25_maldonado_clipped_3857[\"peli_ordered\"] = pd.Categorical(\n    pelig_25_maldonado_clipped_3857[\"peli\"],\n    categories=[\"Bajo\", \"Medio\", \"Alto\"],\n    ordered=True,\n)\n\nfig3, ax3 = create_consistent_map(\"R25 (Período de retorno 25 años)\", boundary_gdf=cuenca_maldonado)\npelig_25_maldonado_clipped_3857.plot(\n    ax=ax3,\n    column=\"peli_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    zorder=5,\n)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) PMP (Precipitación Máxima Probable)\n\n\n\n\n\n\n\n\n\n\n\n(b) R100 (Período de retorno 100 años)\n\n\n\n\n\n\n\n\n\n\n\n(c) R25 (Período de retorno 25 años)\n\n\n\n\n\n\n\nFigure 4.7: Escenarios de peligrosidad en Cuenca Maldonado\n\n\n\n\n\nMostrar código\n# Comparación de escenarios de precipitación para Cuenca Maldonado\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Helper function para procesar datos de peligro\ndef process_hazard_data(file_path, buildings):\n    pelig_data = gpd.read_file(file_path).to_crs(USE_CRS)\n    pelig_filtered = pelig_data[pelig_data[\"peli\"].isin([\"Alto\", \"Medio\"])].copy()\n    pelig_simple = pelig_filtered.dissolve(by=\"peli\").reset_index()\n    \n    buildings_with_peligro = gpd.sjoin(buildings, pelig_simple[[\"peli\", \"geometry\"]], how=\"left\", predicate=\"within\")\n    buildings_exposed = buildings_with_peligro.dropna(subset=[\"peli\"]).copy()\n    \n    hazard_priority = {\"Alto\": 3, \"Medio\": 2}\n    buildings_exposed.loc[:, \"prioridad\"] = buildings_exposed[\"peli\"].map(hazard_priority)\n    buildings_unique = buildings_exposed.sort_values(\"prioridad\", ascending=False).drop_duplicates(subset=buildings_exposed.geometry.name, keep=\"first\")\n    \n    exposicion = buildings_unique.groupby(\"peli\").size().reset_index(name=\"edificios_expuestos\")\n    result = {}\n    for _, row in exposicion.iterrows():\n        peligro_name = \"alta\" if row['peli'] == \"Alto\" else \"media\"\n        result[peligro_name] = row['edificios_expuestos']\n    return result\n\nbuildings_maldonado = buildings_with_barrios.copy()\n\n# === DATOS DE LOS TRES ESCENARIOS ===\n# PMP\nmaldonado_pmp = resultado_exposicion_cuenca[resultado_exposicion_cuenca[\"Cuenca\"] == \"Cuenca A° Maldonado\"].copy()\npmp_data = {row['peligrosidad']: int(row['edificios_expuestos']) for _, row in maldonado_pmp.iterrows()} if len(maldonado_pmp) &gt; 0 else {}\n\n# R25 y R100\nr25_data = process_hazard_data(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp\", buildings_maldonado)\nr100_data = process_hazard_data(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp\", buildings_maldonado)\n\n# === VISUALIZACIÓN COMPARATIVA ===\nescenarios = ['PMP', 'R100', 'R25']\nalta_values = [pmp_data.get('alta', 0), r100_data.get('alta', 0), r25_data.get('alta', 0)]\nmedia_values = [pmp_data.get('media', 0), r100_data.get('media', 0), r25_data.get('media', 0)]\n\nx = np.arange(len(escenarios))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(10, 6))\nbars1 = ax.bar(x - width/2, alta_values, width, label='Peligro Alto', color=PELIGROSIDAD_COLORS[\"alta\"], alpha=0.8)\nbars2 = ax.bar(x + width/2, media_values, width, label='Peligro Medio', color=PELIGROSIDAD_COLORS[\"media\"], alpha=0.8)\n\nax.set_xlabel('Escenario de Precipitación', fontsize=12)\nax.set_ylabel('Edificios Expuestos', fontsize=12)\nax.set_title('Exposición en Cuenca Maldonado por Escenario de Precipitación', fontsize=14, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(escenarios)\nax.legend()\n\ndef add_value_labels(bars):\n    for bar in bars:\n        height = bar.get_height()\n        if height &gt; 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nadd_value_labels(bars1)\nadd_value_labels(bars2)\n\nax.grid(True, axis='y', alpha=0.3)\nax.set_axisbelow(True)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#metodología",
    "href": "renabap.html#metodología",
    "title": "3  RENABAP",
    "section": "3.5 Metodología",
    "text": "3.5 Metodología\nEn versiones anteriores de este análisis, el trabajo se realizó mediante una interpolación areal simple del porcentaje de superposición de cada área de peligro de inundación con los asentamientos informales. Este enfoque presenta dos problemas fundamentales que este estudio busca abordar.\nEl primer problema es que la interpolación areal es inherentemente imprecisa, ya que asume lo que se conoce como el problema de la unidad areal modificable y presupone que la población se distribuye uniformemente en el espacio. Sin embargo, estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución (Smith et al. 2019). La población, de hecho, no se distribuye uniformemente en el espacio; frecuentemente los edificios se agrupan ya sea alejándose de las zonas de peligro de inundación o concentrándose en zonas de alto peligro de inundación. Por tanto, es fundamental comprender con estimaciones más precisas dónde vive realmente la gente.\nEl segundo problema radica en que los propios datos del RENABAP, según nuestro análisis aquí presentado, parecen contar dramáticamente de forma incorrecta, frecuentemente por un factor de dos o más, el número de familias que aparentemente viven en un asentamiento informal basándose en el número de edificaciones. Esto probablemente se debe a errores de proyección acumulados a lo largo del tiempo y a la dificultad de mantener actualizados los datos de asentamientos informales.\nEsta es una de las grandes ventajas de las huellas de edificios globales derivadas de satélite que han surgido en los últimos años de Google-Microsoft-OSM, entre otros. Uno de los objetivos principales de este análisis es demostrar que estos datos de huellas de edificios pueden utilizarse para estimar la exposición de manera más precisa, tanto en términos de precisión metodológica como en términos de mejora sobre conjuntos de datos nacionales existentes como el RENABAP.\nPor tanto, en este estudio utilizamos el número de edificios que intersectan con las diferentes zonas de peligro de inundación como medida de exposición. Hemos encontrado que los datos del RENABAP presentan limitaciones significativas, como se demuestra en nuestro análisis. Los datos del RENABAP para los asentamientos informales de La Plata estiman aproximadamente 1.1 familias por edificio. Para quienes estén interesados en entender el número de familias que probablemente estén expuestas, pueden multiplicar el número de edificios por 1.1 y obtener una estimación razonable.\nSin embargo, dado que no conocemos exactamente cuántas familias viven en cada edificio y que los edificios pueden variar en tamaño, no realizamos esta conversión. En su lugar, medimos la exposición puramente en términos del número comparativo de edificios, lo cual es suficiente para demostrar que los datos del RENABAP están considerablemente desactualizados, pero también para proporcionarnos estimaciones razonablemente buenas de exposición.\nAdemás, basándonos en conversaciones con planificadores tanto del ámbito académico como del gobierno municipal, nos sentimos razonablemente seguros al asumir que la mayoría o la totalidad de los edificios dentro de los límites de un asentamiento informal son probablemente edificios residenciales de uno a dos pisos como máximo. Por tanto, existe una correspondencia muy estrecha entre el número de edificios observados y el número de familias que viven en un asentamiento informal. Esto no será el caso en todos los asentamientos informales y ciertamente no es el caso en asentamientos formales densos. En este contexto particular, nos sentimos cómodos haciendo esta suposición por las razones expuestas.\n\n\nMostrar código\n## Análisis de exposición: edificios por barrio y cuenca por zona de peligro\n# Versión concisa con spatial joins (sin warnings)\n\nimport geopandas as gpd\n\n# Definir orden de prioridad de peligro y simplificar\nhazard_priority = {\"alta\": 3, \"media\": 2, \"baja\": 1}\npeligro_simple = peligro_la_plata.dissolve(by=\"PELIGROSID\").reset_index()\n\n# === ANÁLISIS POR BARRIO ===\n# Spatial joins\nbuildings_with_barrios = gpd.sjoin(\n    buildings_proj,\n    renabap_pba_intersect[\n        [\"id_renabap\", \"nombre_barrio\", \"familias_aproximadas\", \"geometry\"]\n    ],\n    how=\"inner\",\n    predicate=\"within\",\n)\nbuildings_with_barrios = buildings_with_barrios.drop(columns=[\"index_right\"]).copy()\n\nbuildings_with_peligro_barrio = gpd.sjoin(\n    buildings_with_barrios,\n    peligro_simple[[\"PELIGROSID\", \"geometry\"]],\n    how=\"left\",\n    predicate=\"within\",\n)\n\n# Resolver duplicados y contar\nbuildings_barrio_final = buildings_with_peligro_barrio.dropna(\n    subset=[\"PELIGROSID\"]\n).copy()\nbuildings_barrio_final.loc[:, \"prioridad\"] = buildings_barrio_final[\"PELIGROSID\"].map(\n    hazard_priority\n)\nbuildings_barrio_unique = buildings_barrio_final.sort_values(\n    \"prioridad\", ascending=False\n).drop_duplicates(subset=buildings_barrio_final.geometry.name, keep=\"first\")\n\n# Calcular exposición por barrio\nedificios_por_barrio_peligro = (\n    buildings_barrio_unique.groupby([\"id_renabap\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"edificios_expuestos\")\n)\n\ntotal_edificios_barrio = (\n    buildings_with_barrios.groupby(\"id_renabap\")\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nexposure_barrio = edificios_por_barrio_peligro.merge(\n    total_edificios_barrio, on=\"id_renabap\"\n)\nexposure_barrio[\"proporcion\"] = (\n    exposure_barrio[\"edificios_expuestos\"] / exposure_barrio[\"total_edificios\"]\n)\n\nfamilias_barrio = renabap_pba_intersect[\n    [\"id_renabap\", \"nombre_barrio\", \"familias_aproximadas\"]\n].drop_duplicates()\nfinal_exposure_barrio = exposure_barrio.merge(familias_barrio, on=\"id_renabap\")\nfinal_exposure_barrio[\"fam_expuestas\"] = (\n    final_exposure_barrio[\"proporcion\"] * final_exposure_barrio[\"familias_aproximadas\"]\n)\n\nresultado_exposicion_barrio = final_exposure_barrio[\n    [\n        \"id_renabap\",\n        \"nombre_barrio\",\n        \"PELIGROSID\",\n        \"edificios_expuestos\",\n    ]\n].rename(columns={\"PELIGROSID\": \"peligrosidad\"})\n\n# === ANÁLISIS POR CUENCA ===\n# Usar edificios ya en barrios para análisis de cuenca\nbuildings_in_settlements = buildings_with_barrios.copy()\n\n# Spatial joins para cuenca\nbuildings_with_cuenca = gpd.sjoin(\n    buildings_in_settlements,\n    cuencas[[\"Cuenca\", \"eje\", \"geometry\"]],\n    how=\"left\",\n    predicate=\"within\",\n)\nbuildings_with_cuenca = buildings_with_cuenca.drop(columns=[\"index_right\"]).copy()\n\nbuildings_with_peligro_cuenca = gpd.sjoin(\n    buildings_in_settlements,\n    peligro_simple[[\"PELIGROSID\", \"geometry\"]],\n    how=\"left\",\n    predicate=\"within\",\n)\n\n# Combinar y filtrar\nbuildings_cuenca_final = buildings_in_settlements.copy()\nbuildings_cuenca_final.loc[:, \"Cuenca\"] = buildings_with_cuenca[\"Cuenca\"]\nbuildings_cuenca_final.loc[:, \"eje\"] = buildings_with_cuenca[\"eje\"]\nbuildings_cuenca_final.loc[:, \"PELIGROSID\"] = buildings_with_peligro_cuenca[\n    \"PELIGROSID\"\n]\nbuildings_cuenca_final = buildings_cuenca_final.dropna(\n    subset=[\"Cuenca\", \"PELIGROSID\"]\n).copy()\n\n# Resolver duplicados y calcular exposición por cuenca\nbuildings_cuenca_final.loc[:, \"prioridad\"] = buildings_cuenca_final[\"PELIGROSID\"].map(\n    hazard_priority\n)\nbuildings_cuenca_unique = buildings_cuenca_final.sort_values(\n    \"prioridad\", ascending=False\n).drop_duplicates(subset=buildings_cuenca_final.geometry.name, keep=\"first\")\n\nedificios_por_cuenca_peligro = (\n    buildings_cuenca_unique.groupby([\"Cuenca\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"edificios_expuestos\")\n)\n\ntotal_edificios_cuenca = (\n    buildings_with_cuenca.dropna(subset=[\"Cuenca\"])\n    .groupby(\"Cuenca\")\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nexposure_cuenca = edificios_por_cuenca_peligro.merge(\n    total_edificios_cuenca, on=\"Cuenca\"\n)\nexposure_cuenca[\"proporcion\"] = (\n    exposure_cuenca[\"edificios_expuestos\"] / exposure_cuenca[\"total_edificios\"]\n)\n\nfamilias_cuenca = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"Cuenca\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\n\nfinal_exposure_cuenca = exposure_cuenca.merge(familias_cuenca, on=\"Cuenca\")\nfinal_exposure_cuenca[\"fam_expuestas\"] = (\n    final_exposure_cuenca[\"proporcion\"] * final_exposure_cuenca[\"familias_aproximadas\"]\n)\n\nresultado_exposicion_cuenca = final_exposure_cuenca[\n    [\"Cuenca\", \"PELIGROSID\", \"edificios_expuestos\"]\n].rename(columns={\"PELIGROSID\": \"peligrosidad\"})\n\n# === ANÁLISIS POR EJE ===\n# Usar los edificios ya procesados con cuenca y peligro\nbuildings_eje_final = buildings_cuenca_final.dropna(subset=[\"eje\"]).copy()\n\n# Resolver duplicados por prioridad de peligro\nbuildings_eje_final.loc[:, \"prioridad\"] = buildings_eje_final[\"PELIGROSID\"].map(\n    hazard_priority\n)\nbuildings_eje_unique = buildings_eje_final.sort_values(\n    \"prioridad\", ascending=False\n).drop_duplicates(subset=buildings_eje_final.geometry.name, keep=\"first\")\n\n# Calcular exposición por eje y peligrosidad\nedificios_por_eje_peligro = (\n    buildings_eje_unique.groupby([\"eje\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"edificios_expuestos\")\n)\n\ntotal_edificios_eje = (\n    buildings_with_cuenca.dropna(subset=[\"eje\"])\n    .groupby(\"eje\")\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nexposure_eje = edificios_por_eje_peligro.merge(total_edificios_eje, on=\"eje\")\nexposure_eje[\"proporcion\"] = (\n    exposure_eje[\"edificios_expuestos\"] / exposure_eje[\"total_edificios\"]\n)\n\nfamilias_por_eje = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"eje\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\n\nfinal_exposure_eje = exposure_eje.merge(familias_por_eje, on=\"eje\")\nfinal_exposure_eje[\"fam_expuestas\"] = (\n    final_exposure_eje[\"proporcion\"] * final_exposure_eje[\"familias_aproximadas\"]\n)\n\nresultado_exposicion_eje = final_exposure_eje[\n    [\"eje\", \"PELIGROSID\", \"edificios_expuestos\"]\n].rename(columns={\"PELIGROSID\": \"peligrosidad\"})\n\n\n\n3.5.1 Limitaciones de los datos del RENABAP\nLos datos del RENABAP presentan limitaciones importantes que justifican el uso de huellas de edificios como alternativa más precisa. Los datos más recientes del RENABAP de 2023 subestiman significativamente el número total de familias por asentamiento informal. Estos datos se basan en proyecciones derivadas del censo de 2010, lo que ha resultado en estimaciones considerablemente desactualizadas.\nNuestro análisis comparativo entre los datos del RENABAP y el conteo de huellas de edificios revela que el RENABAP subestima el número de estructuras habitacionales en un promedio del 41%. A nivel agregado, esto se traduce en aproximadamente 41,000 viviendas faltantes que no están contabilizadas en las estadísticas oficiales del RENABAP. Considerando un rango razonable de 3 a 5 personas por vivienda, esta subestimación representa entre 120,000 y 205,000 personas que podrían estar no contabilizadas en los asentamientos informales. Esta discrepancia masiva demuestra claramente las limitaciones críticas del RENABAP para la evaluación precisa de la exposición a riesgos de inundación y la planificación de políticas públicas.\n\n\nMostrar código\nimport matplotlib.pyplot as plt\n\n# Calcular familias estimadas basadas en edificios (1.1 familias por edificio)\nratio_fam_edif = (\n    buildings_with_barrios.groupby([\"id_renabap\", \"familias_aproximadas\"])\n    .size()\n    .reset_index(name=\"total_edificios\")\n)\n\nratio_fam_edif[\"familias_estimadas_edificios\"] = ratio_fam_edif[\"total_edificios\"] * 1.1\n# Calcular el error porcentual: (RENABAP - Edificios) / Edificios * 100\nratio_fam_edif[\"error_porcentual\"] = (\n    (\n        ratio_fam_edif[\"familias_aproximadas\"]\n        - ratio_fam_edif[\"familias_estimadas_edificios\"]\n    )\n    / ratio_fam_edif[\"familias_estimadas_edificios\"]\n) * 100\n\n# Crear histograma\nplt.figure(figsize=(12, 6))\nplt.hist(\n    ratio_fam_edif[\"error_porcentual\"],\n    bins=30,\n    edgecolor=\"none\",\n    color=PELIGROSIDAD_COLORS[\"alta\"],\n)\n\n# Personalizar el gráfico\nplt.title(\n    \"Error de Estimación de RENABAP vs Estimación por Edificios\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nplt.xlabel(\"Error Porcentual (%)\", fontsize=12)\nplt.ylabel(\"Frecuencia (Número de Barrios)\", fontsize=12)\n\n# Agregar líneas de referencia\nmean_error = ratio_fam_edif[\"error_porcentual\"].mean()\nmedian_error = ratio_fam_edif[\"error_porcentual\"].median()\n\nplt.axvline(\n    mean_error,\n    color=\"black\",\n    linestyle=\"--\",\n    linewidth=2,\n    label=f\"Error promedio: {mean_error:.1f}%\",\n)\nplt.axvline(\n    median_error,\n    color=\"black\",\n    linestyle=\"dotted\",\n    linewidth=2,\n    label=f\"Error mediano: {median_error:.1f}%\",\n)\n\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.2: Distribución del error porcentual en las estimaciones del RENABAP comparado con estimaciones basadas en edificios\n\n\n\n\n\nTambién podemos examinar imágenes satelitales de un asentamiento informal de muestra con las huellas de edificios superpuestas para tener una idea de la veracidad de los datos. Aquí está un barrio llamado Los Pinos, en el cual mapeamos la extensión del RENABAP del barrio y las huellas de los edificios dentro de él. Las estimaciones del RENABAP dicen que este asentamiento informal tiene solo 72 familias. Nuestros datos cuentan 519 edificios. Si usamos la estimación del RENABAP de aproximadamente 1.1 familias por edificio, que es lo que calculan en sus datos originales, estamos hablando de un total de 570 familias, que es casi ocho veces más de lo que los datos del RENABAP contabilizan.\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport contextily as cx\nfrom matplotlib_map_utils.core.scale_bar import ScaleBar, scale_bar\nfrom matplotlib_map_utils.core.north_arrow import north_arrow\n\n# Filtrar para obtener solo el barrio con id_renabap 5688\nbarrio_5688 = renabap_pba_intersect[renabap_pba_intersect[\"id_renabap\"] == 5688].copy()\nif len(barrio_5688) == 0:\n    print(\"No se encontró el barrio con id_renabap 5688\")\nelse:\n    # Obtener edificios en este barrio\n    buildings_5688 = buildings_with_barrios[\n        buildings_with_barrios[\"id_renabap\"] == 5688\n    ].copy()\n    # Convertir a Web Mercator\n    barrio_5688_3857 = barrio_5688.to_crs(WEB_MERCATOR_CRS)\n    buildings_5688_3857 = buildings_5688.to_crs(WEB_MERCATOR_CRS)\n    # Crear el mapa\n    fig, ax = plt.subplots(figsize=(12, 10))\n    # Configurar límites basados en el barrio\n    bounds = barrio_5688_3857.total_bounds\n    margin = 50  # metros\n    ax.set_xlim(bounds[0] - margin, bounds[2] + margin)\n    ax.set_ylim(bounds[1] - margin, bounds[3] + margin)\n    # Agregar basemap de contextily\n    cx.add_basemap(ax, crs=\"EPSG:3857\", source=cx.providers.Esri.WorldImagery)\n    # Plot de edificios con contorno naranja (sin fill)\n    buildings_5688_3857.plot(\n        ax=ax, facecolor=\"none\", edgecolor=PLASMA_CMAP(1), linewidth=1\n    )\n    # Plot del límite del barrio con estilo consistente\n    barrio_5688_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"white\",  # White for satellite imagery visibility\n        linewidth=3,\n        linestyle=\"--\",\n        zorder=10,\n    )\n    \n    ScaleBar.set_size(\"md\")\n    \n    scale_bar(ax=ax, \n    location=\"upper left\", \n    style=\"ticks\", \n    bar={\"projection\":\"axis\",\n    \"minor_type\":\"none\",\n    \"tickcolors\": \"white\",\n    \"basecolors\": \"white\"}, \n    labels={\"style\":\"first_last\",\n    \"textcolors\":[\"white\"],\n    \"stroke_width\":0},\n    units={\"label\":\"m\",\n    \"textcolor\":\"white\",\n    \"stroke_width\":0}\n    )\n    \n    north_arrow(\n        ax,\n        location=\"upper right\",\n        scale=0.3,  # Small size\n        rotation={\"degrees\": 0},\n        base={\"facecolor\": \"none\", \"edgecolor\": \"white\", \"linewidth\": 1},\n        fancy=True,\n        shadow=True,\n        label=False  # Hide the \"N\" text\n    )\n    \n    # Limpiar el mapa\n    barrio_nombre = barrio_5688[\"nombre_barrio\"].iloc[0]\n    ax.set_title(\n        f\"Barrio {barrio_nombre} - Límites y Edificaciones\",\n        fontsize=14,\n        fontweight=\"bold\",\n        pad=20,\n    )\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"\")\n    ax.set_ylabel(\"\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    # Agregar leyenda simple\n    legend_elements = [\n        plt.Line2D([0], [0], color=\"white\", linewidth=3, label=\"Límite del barrio\"),\n        plt.Line2D([0], [0], color=PLASMA_CMAP(1), linewidth=1, label=\"Edificaciones\"),\n    ]\n    ax.legend(handles=legend_elements, loc=\"lower right\", bbox_to_anchor=(1.0, 0.02))\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\nFigure 3.3: Ejemplo de discrepancia en los datos del RENABAP: el barrio Los Pinos con límites oficiales y edificaciones detectadas",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#procesamiento-y-resultados",
    "href": "renabap.html#procesamiento-y-resultados",
    "title": "3  RENABAP",
    "section": "3.6 Procesamiento y resultados",
    "text": "3.6 Procesamiento y resultados\nLa exposición en asentamientos informales se concentra principalmente en los alrededores del casco urbano de La Plata. El análisis revela una distribución característica donde un número pequeño de barrios presenta exposición muy alta, seguido por un grupo de exposición media, y luego una disminución gradual. Villa Montoro lidera con 555 edificaciones expuestas a peligro alto, seguida por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. Otros barrios con exposición significativa incluyen Aeropuerto (258), 48 y 144 (225), San Luis (206), y El Uido (132).\nA nivel de cuencas hidrográficas, la Cuenca Arroyo del Gato concentra la mayor exposición con 2,662 edificaciones expuestas a peligro alto, principalmente debido a la presencia de Villa Montoro y otros asentamientos importantes. Le sigue la Cuenca A° Maldonado con 1,000 edificaciones y la Cuenca Arroyo Martín-Carnaval con 368. Esta concentración en la Cuenca Arroyo del Gato refleja tanto la densidad de asentamientos informales como su ubicación en zonas de alto riesgo hidrológico.\n\n3.6.1 Exposición por barrio\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport contextily as cx\n\n# Colores para peligrosidad\nPELIGROSIDAD_COLORS = {\n    \"alta\": PLASMA_CMAP(0.8),\n    \"media\": PLASMA_CMAP(0.5),\n    \"baja\": PLASMA_CMAP(0.2),\n}\n\n\n# Preparar datos - solo alta y media\nexposure_data = resultado_exposicion_barrio[\n    resultado_exposicion_barrio[\"peligrosidad\"].isin([\"alta\", \"media\"])\n].copy()\n\n# Merge con geometrías para obtener centroides\nexposure_gdf = exposure_data.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"geometry\"]], on=\"id_renabap\"\n)\nexposure_gdf = gpd.GeoDataFrame(exposure_gdf, geometry=\"geometry\", crs=USE_CRS)\n\n# Convertir a Web Mercator para el plotting\nexposure_gdf_3857 = exposure_gdf.to_crs(\"EPSG:3857\")\nla_plata_3857 = la_plata.to_crs(\"EPSG:3857\")\n\n# Crear el mapa\nfig, ax = plt.subplots(figsize=(12, 10))\n\n# Configurar límites\nbounds = la_plata_3857.total_bounds\nmargin = 2000  # metros\nax.set_xlim(bounds[0] - margin, bounds[2] + margin)\nax.set_ylim(bounds[1] - margin, bounds[3] + margin)\n\n# Agregar basemap de contextily\ncx.add_basemap(\n    ax, crs=\"EPSG:3857\", source=cx.providers.CartoDB.PositronNoLabels, alpha=0.7\n)\n\n# Plot de puntos con jitter\nnp.random.seed(42)\nplotting_order = [\"media\", \"alta\"]\n\nfor peligrosidad in plotting_order:\n    level_data = exposure_gdf_3857[exposure_gdf_3857[\"peligrosidad\"] == peligrosidad]\n    for _, row in level_data.iterrows():\n        centroid = row[\"geometry\"].centroid\n        jitter_x = np.random.uniform(-200, 200)\n        jitter_y = np.random.uniform(-200, 200)\n        x_pos = centroid.x + jitter_x\n        y_pos = centroid.y + jitter_y\n        color = PELIGROSIDAD_COLORS[row[\"peligrosidad\"]]\n        size = max(10, row[\"edificios_expuestos\"] * 0.5 + 15)\n        ax.scatter(\n            x_pos,\n            y_pos,\n            s=size,\n            color=color,\n            alpha=0.9,\n            edgecolors=\"white\",\n            linewidth=1.0,\n        )\n\n# Leyenda de peligrosidad\nlegend_elements_peligro = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=PELIGROSIDAD_COLORS[\"alta\"],\n        markersize=8,\n        label=\"Alta\",\n    ),\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=PELIGROSIDAD_COLORS[\"media\"],\n        markersize=8,\n        label=\"Media\",\n    ),\n]\n\n# Leyenda de tamaño\nbuilding_values = [100, 500, 1000]\nlegend_elements_size = []\nfor val in building_values:\n    size = max(10, val * 0.5 + 15)\n    legend_elements_size.append(\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"o\",\n            color=\"w\",\n            markerfacecolor=\"gray\",\n            markersize=np.sqrt(size / 10),\n            label=f\"{val} edificios\",\n        )\n    )\n\n# Crear leyendas lado a lado en bottom right\nlegend1 = ax.legend(\n    handles=legend_elements_peligro,\n    title=\"Nivel de peligrosidad\",\n    loc=\"lower right\",\n    bbox_to_anchor=(0.85, 0),\n)\nax.add_artist(legend1)\n\nlegend2 = ax.legend(\n    handles=legend_elements_size,\n    title=\"Edificios expuestos\",\n    loc=\"lower right\",\n    bbox_to_anchor=(1.0, 0),\n)\n\n# Agregar el contorno de La Plata como capa superior\nadd_la_plata_outline(ax)\n\n# Agregar escala y flecha norte para consistencia\nadd_scale_bar_and_north_arrow(ax)\n\n# Limpiar el mapa - quitar bordes, ticks, etc.\nax.set_title(\n    \"Exposición de Barrios Populares por Nivel de Peligrosidad\",\n    fontsize=14,\n    fontweight=\"bold\",\n    pad=20,\n)\nax.set_axis_off()\n\nplt.tight_layout()\nplt.show()\n\n# | label: fig-top-barrios-exposicion\n# | fig-cap: \"Los 10 barrios con mayor número de edificaciones expuestas a peligros de inundación\"\n\n# Filtrar exposición alta y media por nombre de barrio (excluyendo \"Sin Nombre\")\nbarrios_alta_data = (\n    resultado_exposicion_barrio[\n        (resultado_exposicion_barrio[\"peligrosidad\"] == \"alta\")\n        & (resultado_exposicion_barrio[\"nombre_barrio\"] != \"Sin Nombre\")\n    ]\n    .groupby(\"nombre_barrio\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n    .head(10)\n)\n\nbarrios_media_data = (\n    resultado_exposicion_barrio[\n        (resultado_exposicion_barrio[\"peligrosidad\"] == \"media\")\n        & (resultado_exposicion_barrio[\"nombre_barrio\"] != \"Sin Nombre\")\n    ]\n    .groupby(\"nombre_barrio\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n)\n\n# Merge para tener ambos niveles\nbarrios_combined = barrios_alta_data.merge(barrios_media_data, on=\"nombre_barrio\", how=\"left\", suffixes=(\"_alta\", \"_media\"))\nbarrios_combined[\"edificios_expuestos_media\"] = barrios_combined[\"edificios_expuestos_media\"].fillna(0)\n\n# Crear el gráfico de barras\nfig, ax = plt.subplots(figsize=(12, 8))\nx = np.arange(len(barrios_combined))\nwidth = 0.35\n\nbars1 = ax.bar(x - width/2, barrios_combined[\"edificios_expuestos_alta\"], width,\n               label=\"Peligro Alto\", color=PELIGROSIDAD_COLORS[\"alta\"])\nbars2 = ax.bar(x + width/2, barrios_combined[\"edificios_expuestos_media\"], width,\n               label=\"Peligro Medio\", color=PELIGROSIDAD_COLORS[\"media\"])\n\nax.set_xlabel(\"Barrios\", fontsize=12)\nax.set_ylabel(\"Edificios Expuestos\", fontsize=12)\nax.set_title(\"Top 10 Barrios por Edificios Expuestos\", fontsize=14, fontweight=\"bold\")\nax.set_xticks(x)\nax.set_xticklabels(barrios_combined[\"nombre_barrio\"], rotation=45, ha=\"right\")\nax.legend(loc=\"upper right\")\n\n# Agregar valores en las barras\nfor bar in bars1:\n    height = bar.get_height()\n    if height &gt; 0:\n        ax.text(bar.get_x() + bar.get_width()/2., height + 5, f'{int(height)}',\n                ha='center', va='bottom', fontsize=10)\n\nfor bar in bars2:\n    height = bar.get_height()\n    if height &gt; 0:\n        ax.text(bar.get_x() + bar.get_width()/2., height + 5, f'{int(height)}',\n                ha='center', va='bottom', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nshow(resultado_exposicion_barrio)\n\n\n\n\n\n\n\n\n\n\n\n(a) Mapa de exposición de barrios populares por nivel de peligrosidad de inundación\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n(c)\n\n\n\n\n\nFigure 3.4\n\n\n\n\n\n\n3.6.2 Exposición por cuenca y eje\n\nMostrar código\n# === GRÁFICO DE CUENCAS ===\n# Filtrar exposición alta y media por cuenca\ncuenca_alta_data = (\n    resultado_exposicion_cuenca[resultado_exposicion_cuenca[\"peligrosidad\"] == \"alta\"]\n    .groupby(\"Cuenca\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n)\n\ncuenca_media_data = (\n    resultado_exposicion_cuenca[resultado_exposicion_cuenca[\"peligrosidad\"] == \"media\"]\n    .groupby(\"Cuenca\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n)\n\n# Merge para tener ambos niveles\ncuenca_combined = cuenca_alta_data.merge(cuenca_media_data, on=\"Cuenca\", how=\"left\", suffixes=(\"_alta\", \"_media\"))\ncuenca_combined[\"edificios_expuestos_media\"] = cuenca_combined[\"edificios_expuestos_media\"].fillna(0)\n\n# Crear gráfico de cuencas\nfig1, ax1 = plt.subplots(figsize=(10, 8))\nx = np.arange(len(cuenca_combined))\nwidth = 0.35\n\nbars1 = ax1.bar(x - width/2, cuenca_combined[\"edificios_expuestos_alta\"], width, \n                label=\"Peligro Alto\", color=PELIGROSIDAD_COLORS[\"alta\"])\nbars2 = ax1.bar(x + width/2, cuenca_combined[\"edificios_expuestos_media\"], width,\n                label=\"Peligro Medio\", color=PELIGROSIDAD_COLORS[\"media\"])\n\nax1.set_xlabel(\"Cuencas\", fontsize=12)\nax1.set_ylabel(\"Edificios Expuestos\", fontsize=12)\nax1.set_title(\"Cuencas por Edificaciones Expuestas\", fontsize=14, fontweight=\"bold\")\nax1.set_xticks(x)\nax1.set_xticklabels(cuenca_combined[\"Cuenca\"], rotation=45, ha=\"right\")\nax1.legend(loc=\"upper right\")\n\n# Agregar valores en las barras\nfor bar in bars1:\n    height = bar.get_height()\n    if height &gt; 0:\n        ax1.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}',\n                ha='center', va='bottom', fontsize=10)\n\nfor bar in bars2:\n    height = bar.get_height()\n    if height &gt; 0:\n        ax1.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}',\n                ha='center', va='bottom', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\n# === GRÁFICO DE EJES ===\n# Filtrar exposición alta y media por eje\neje_alta_data = (\n    resultado_exposicion_eje[resultado_exposicion_eje[\"peligrosidad\"] == \"alta\"]\n    .groupby(\"eje\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n    .sort_values(\"edificios_expuestos\", ascending=False)\n)\n\neje_media_data = (\n    resultado_exposicion_eje[resultado_exposicion_eje[\"peligrosidad\"] == \"media\"]\n    .groupby(\"eje\")[\"edificios_expuestos\"]\n    .sum()\n    .reset_index()\n)\n\n# Merge para tener ambos niveles\neje_combined = eje_alta_data.merge(eje_media_data, on=\"eje\", how=\"left\", suffixes=(\"_alta\", \"_media\"))\neje_combined[\"edificios_expuestos_media\"] = eje_combined[\"edificios_expuestos_media\"].fillna(0)\n\n# Crear gráfico de ejes\nfig2, ax2 = plt.subplots(figsize=(10, 8))\nx = np.arange(len(eje_combined))\nwidth = 0.35\n\nbars1 = ax2.bar(x - width/2, eje_combined[\"edificios_expuestos_alta\"], width,\n                label=\"Peligro Alto\", color=PELIGROSIDAD_COLORS[\"alta\"])\nbars2 = ax2.bar(x + width/2, eje_combined[\"edificios_expuestos_media\"], width,\n                label=\"Peligro Medio\", color=PELIGROSIDAD_COLORS[\"media\"])\n\nax2.set_xlabel(\"Ejes\", fontsize=12)\nax2.set_ylabel(\"Edificios Expuestos\", fontsize=12)\nax2.set_title(\"Ejes por Edificaciones Expuestas\", fontsize=14, fontweight=\"bold\")\nax2.set_xticks(x)\nax2.set_xticklabels(eje_combined[\"eje\"], rotation=45, ha=\"right\")\nax2.legend(loc=\"upper right\")\n\n# Agregar valores en las barras\nfor bar in bars1:\n    height = bar.get_height()\n    if height &gt; 0:\n        ax2.text(bar.get_x() + bar.get_width()/2., height + 10, f'{int(height)}',\n                ha='center', va='bottom', fontsize=10)\n\nfor bar in bars2:\n    height = bar.get_height()\n    if height &gt; 0:\n        ax2.text(bar.get_x() + bar.get_width()/2., height + 10, f'{int(height)}',\n                ha='center', va='bottom', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cuencas por edificaciones expuestas\n\n\n\n\n\n\n\n\n\n\n\n(b) Ejes por edificaciones expuestas\n\n\n\n\n\n\n\nFigure 3.5: Exposición por cuencas hidrográficas y ejes territoriales",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#comparativa-de-periodos-de-retorno",
    "href": "renabap.html#comparativa-de-periodos-de-retorno",
    "title": "3  RENABAP",
    "section": "3.7 Comparativa de periodos de retorno",
    "text": "3.7 Comparativa de periodos de retorno\n\nMostrar código\n# Preparar datos de cuenca Maldonado para clipping\ncuenca_maldonado = cuencas[cuencas[\"Cuenca\"] == \"Cuenca A° Maldonado\"].copy()\n\n# === MAPA PMP ===\n# Clipear peligro PMP a cuenca Maldonado\npeligro_pmp_maldonado = gpd.clip(peligro_la_plata, cuenca_maldonado)\npeligro_pmp_maldonado_3857 = peligro_pmp_maldonado.to_crs(WEB_MERCATOR_CRS)\n\n# Ordenar categorías para mapeo correcto\npeligro_pmp_maldonado_3857[\"PELIGROSID_ordered\"] = pd.Categorical(\n    peligro_pmp_maldonado_3857[\"PELIGROSID\"],\n    categories=[\"baja\", \"media\", \"alta\"],\n    ordered=True,\n)\n\nfig1, ax1 = create_consistent_map(\"PMP (Precipitación Máxima Probable)\", boundary_gdf=cuenca_maldonado)\npeligro_pmp_maldonado_3857.plot(\n    ax=ax1,\n    column=\"PELIGROSID_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    legend_kwds={\"loc\": \"lower right\"},\n    zorder=5,\n)\nplt.tight_layout()\nplt.show()\n\n# === MAPA R100 ===\npelig_100_maldonado = gpd.read_file(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp\")\npelig_100_maldonado = pelig_100_maldonado.to_crs(USE_CRS)\n\n# Clipear a cuenca Maldonado\npelig_100_maldonado_clipped = gpd.clip(pelig_100_maldonado, cuenca_maldonado)\npelig_100_maldonado_clipped_3857 = pelig_100_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Ordenar categorías\npelig_100_maldonado_clipped_3857[\"peli_ordered\"] = pd.Categorical(\n    pelig_100_maldonado_clipped_3857[\"peli\"],\n    categories=[\"Bajo\", \"Medio\", \"Alto\"],\n    ordered=True,\n)\n\nfig2, ax2 = create_consistent_map(\"R100 (Período de retorno 100 años)\", boundary_gdf=cuenca_maldonado)\npelig_100_maldonado_clipped_3857.plot(\n    ax=ax2,\n    column=\"peli_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    legend_kwds={\"loc\": \"lower right\"},\n    zorder=5,\n)\nplt.tight_layout()\nplt.show()\n\n# === MAPA R25 ===\npelig_25_maldonado = gpd.read_file(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp\")\npelig_25_maldonado = pelig_25_maldonado.to_crs(USE_CRS)\n\n# Clipear a cuenca Maldonado\npelig_25_maldonado_clipped = gpd.clip(pelig_25_maldonado, cuenca_maldonado)\npelig_25_maldonado_clipped_3857 = pelig_25_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Ordenar categorías\npelig_25_maldonado_clipped_3857[\"peli_ordered\"] = pd.Categorical(\n    pelig_25_maldonado_clipped_3857[\"peli\"],\n    categories=[\"Bajo\", \"Medio\", \"Alto\"],\n    ordered=True,\n)\n\nfig3, ax3 = create_consistent_map(\"R25 (Período de retorno 25 años)\", boundary_gdf=cuenca_maldonado)\npelig_25_maldonado_clipped_3857.plot(\n    ax=ax3,\n    column=\"peli_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    legend_kwds={\"loc\": \"lower right\"},\n    zorder=5,\n)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) PMP (Precipitación Máxima Probable)\n\n\n\n\n\n\n\n\n\n\n\n(b) R100 (Período de retorno 100 años)\n\n\n\n\n\n\n\n\n\n\n\n(c) R25 (Período de retorno 25 años)\n\n\n\n\n\n\n\nFigure 3.6: Escenarios de peligrosidad en Cuenca Maldonado\n\n\n\n\n\nMostrar código\n# Comparación de escenarios de precipitación para Cuenca Maldonado\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Helper function para procesar datos de peligro\ndef process_hazard_data(file_path, buildings):\n    pelig_data = gpd.read_file(file_path).to_crs(USE_CRS)\n    pelig_filtered = pelig_data[pelig_data[\"peli\"].isin([\"Alto\", \"Medio\"])].copy()\n    pelig_simple = pelig_filtered.dissolve(by=\"peli\").reset_index()\n    \n    buildings_with_peligro = gpd.sjoin(buildings, pelig_simple[[\"peli\", \"geometry\"]], how=\"left\", predicate=\"within\")\n    buildings_exposed = buildings_with_peligro.dropna(subset=[\"peli\"]).copy()\n    \n    hazard_priority = {\"Alto\": 3, \"Medio\": 2}\n    buildings_exposed.loc[:, \"prioridad\"] = buildings_exposed[\"peli\"].map(hazard_priority)\n    buildings_unique = buildings_exposed.sort_values(\"prioridad\", ascending=False).drop_duplicates(subset=buildings_exposed.geometry.name, keep=\"first\")\n    \n    exposicion = buildings_unique.groupby(\"peli\").size().reset_index(name=\"edificios_expuestos\")\n    result = {}\n    for _, row in exposicion.iterrows():\n        peligro_name = \"alta\" if row['peli'] == \"Alto\" else \"media\"\n        result[peligro_name] = row['edificios_expuestos']\n    return result\n\nbuildings_maldonado = buildings_with_barrios.copy()\n\n# === DATOS DE LOS TRES ESCENARIOS ===\n# PMP\nmaldonado_pmp = resultado_exposicion_cuenca[resultado_exposicion_cuenca[\"Cuenca\"] == \"Cuenca A° Maldonado\"].copy()\npmp_data = {row['peligrosidad']: int(row['edificios_expuestos']) for _, row in maldonado_pmp.iterrows()} if len(maldonado_pmp) &gt; 0 else {}\n\n# R25 y R100\nr25_data = process_hazard_data(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp\", buildings_maldonado)\nr100_data = process_hazard_data(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp\", buildings_maldonado)\n\n# === VISUALIZACIÓN COMPARATIVA ===\nescenarios = ['PMP', 'R100', 'R25']\nalta_values = [pmp_data.get('alta', 0), r100_data.get('alta', 0), r25_data.get('alta', 0)]\nmedia_values = [pmp_data.get('media', 0), r100_data.get('media', 0), r25_data.get('media', 0)]\n\nx = np.arange(len(escenarios))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(10, 6))\nbars1 = ax.bar(x - width/2, alta_values, width, label=\"Peligro Alto\", color=PELIGROSIDAD_COLORS[\"alta\"])\nbars2 = ax.bar(x + width/2, media_values, width, label=\"Peligro Medio\", color=PELIGROSIDAD_COLORS[\"media\"])\n\nax.set_xlabel(\"Escenario de Precipitación\", fontsize=12)\nax.set_ylabel(\"Edificios Expuestos\", fontsize=12)\nax.set_title(\"Exposición en Cuenca Maldonado por Escenario de Precipitación\", fontsize=14, fontweight=\"bold\")\nax.set_xticks(x)\nax.set_xticklabels(escenarios)\nax.legend(loc=\"upper right\")\n\ndef add_value_labels(bars):\n    for bar in bars:\n        height = bar.get_height()\n        if height &gt; 0:\n            ax.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}', ha='center', va='bottom', fontsize=10)\n\nadd_value_labels(bars1)\nadd_value_labels(bars2)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  }
]