[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CIUT Riesgo",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "exposicion.html",
    "href": "exposicion.html",
    "title": "1  Exposición",
    "section": "",
    "text": "1.1 Introducción a la Exposición\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#análisis-de-exposición",
    "href": "exposicion.html#análisis-de-exposición",
    "title": "1  Exposición",
    "section": "1.2 Análisis de Exposición",
    "text": "1.2 Análisis de Exposición\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#evaluación-de-riesgos",
    "href": "exposicion.html#evaluación-de-riesgos",
    "title": "1  Exposición",
    "section": "1.3 Evaluación de Riesgos",
    "text": "1.3 Evaluación de Riesgos\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "suavizacion.html",
    "href": "suavizacion.html",
    "title": "2  Suavización",
    "section": "",
    "text": "2.1 Conceptos de Suavización\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#métodos-de-suavización",
    "href": "suavizacion.html#métodos-de-suavización",
    "title": "2  Suavización",
    "section": "2.2 Métodos de Suavización",
    "text": "2.2 Métodos de Suavización\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#aplicaciones-prácticas",
    "href": "suavizacion.html#aplicaciones-prácticas",
    "title": "2  Suavización",
    "section": "2.3 Aplicaciones Prácticas",
    "text": "2.3 Aplicaciones Prácticas\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "renabap.html",
    "href": "renabap.html",
    "title": "3  RENABAP",
    "section": "",
    "text": "3.1 Resumen ejecutivo\nLos datos procesados, incluyendo las estimaciones de exposición por barrio popular para los tres métodos de estimación, desglosados por nivel de peligro, están disponibles para descarga en formato CSV. Haga clic aquí para descargar los datos por barrio. Los datos agregados por cuenca también están disponibles, incluyendo una columna “eje” que permite resumir los datos al nivel de eje de cuenca. Haga clic aquí para descargar los datos por cuenca.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#objetivos",
    "href": "renabap.html#objetivos",
    "title": "3  RENABAP",
    "section": "3.2 Objetivos",
    "text": "3.2 Objetivos\nEl objetivo principal de este análisis es calcular con mayor precisión la exposición poblacional en la región del Partido de La Plata, comparando el enfoque actual de interpolación por área de datos del RENABAP con enfoques de mapeo dasimétrico de mayor resolución utilizando datos de la Capa Global de Asentamientos Humanos (GHSL) y el conjunto de datos de edificios abiertos de Google-Microsoft OpenStreetMap.\nPara lograr este objetivo, necesitamos:\n\nExplicar y comparar metodologías: Desarrollar una comprensión clara de las diferencias entre interpolación por área y mapeo dasimétrico\nEvaluar fuentes de datos: Analizar las ventajas y limitaciones de cada conjunto de datos utilizado\nCrear estimaciones robustas: Generar un rango de posibles exposiciones poblacionales para informar la toma de decisiones\nPriorizar recursos: Identificar áreas donde se requiera recopilación de datos más precisa",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#contexto",
    "href": "renabap.html#contexto",
    "title": "3  RENABAP",
    "section": "3.3 Contexto",
    "text": "3.3 Contexto\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\nfrom io import BytesIO, StringIO\nfrom owslib.wfs import WebFeatureService\nfrom shapely.geometry import box\nimport geopandas as gpd\nimport requests\nimport pandas as pd\nimport os\n\nimport boto3\nimport duckdb\n\n\nimport numpy as np\nimport s2sphere\nfrom botocore.config import Config\nfrom rasterstats import zonal_stats\nimport rasterstats\nfrom rasterio.features import rasterize\nimport numpy.ma as ma\nfrom itables import show\nimport matplotlib.cm as cm\n\nimport seaborn as sns\nimport rioxarray\n\n# =============================================================================\n# CONSTANTS AND CONFIGURATION\n# =============================================================================\n\n# Coordinate Reference Systems\nUSE_CRS = \"EPSG:5349\"  # POSGAR 2007 / Argentina 4\nWEB_MERCATOR_CRS = \"EPSG:3857\"  # Web Mercator for visualization\nWGS84_CRS = \"EPSG:4326\"  # WGS84 for API calls\n\n# File paths\nBASE_PATH = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo\"\nDATA_PATH = f\"{BASE_PATH}/notebooks/data\"\nPELIGRO_PATH = f\"{DATA_PATH}/la_plata_pelig_2023_datos_originales.geojson\"\nPARTIDOS_PATH = f\"{DATA_PATH}/pba_partidos.geojson\"\nCUENCAS_PATH = f\"{BASE_PATH}/notebooks/cuencas_buenos_aires.geojson\"\nBUILDINGS_PATH = f\"{BASE_PATH}/notebooks/buildings_filtered.parquet\"\nGHSL_PATH = \"/home/nissim/Downloads/spatial/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13.tif\"\n\n# Data URLs\nRENABAP_URL = \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\nPARTIDOS_WFS_URL = \"https://geo.arba.gov.ar/geoserver/idera/wfs\"\nCUENCAS_API_URL = \"https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query\"\n\n# Data processing constants\nHAZARD_LEVELS = [\"baja\", \"media\", \"alta\"]\nMETHOD_NAMES = [\"edificios\", \"ghsl\", \"areal\"]\nEXPOSURE_COLUMNS = [\"fam_expuestas_edificios\", \"fam_expuestas_ghsl\", \"fam_expuestas_areal\"]\nNON_HAZARD_VALUE = \"none\"\nNODATA_VALUE = -200\n\n# Column mappings and renaming  \nCOLUMN_MAPPINGS = {\n    \"buildings_to_edificios\": {\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"},\n    \"method_cleanup_prefix\": \"fam_expuestas_\"\n}\n\n# Basic visualization settings (only for repeated values)\nDEFAULT_FIGSIZE = (12, 10)\nMAP_PADDING = 500\nPLASMA_CMAP = plt.cm.plasma\n\n# Color schemes for visualization\nPELIGROSIDAD_COLORS = {\n    \"alta\": PLASMA_CMAP(0.8),\n    \"media\": PLASMA_CMAP(0.5),\n    \"baja\": PLASMA_CMAP(0.2),\n}\n\nMETHOD_COLORS = {\n    \"areal\": PLASMA_CMAP(0.8),\n    \"ghsl\": PLASMA_CMAP(0.5),\n    \"edificios\": PLASMA_CMAP(0.2),\n}\n\n# Eje mapping for watershed analysis\nEJE_MAPPING = {\n    \"noreste\": [\"Area de Bañados\", \"Cuenca Arroyo Rodriguez-Don Carlos\"],\n    \"noroeste\": [\"Cuenca Arroyo Martín-Carnaval\", \"Cuenca Arroyo Pereyra\"],\n    \"central\": [\"Cuenca Arroyo del Gato\"],\n    \"sudoeste\": [\"Cuenca A° Maldonado\", \"Cuenca Río Samborombón\"],\n    \"sudeste\": [\"Cuenca Arroyo El Pescado\"],\n}\n\n\n\ndef setup_base_map(figsize=None, bounds=None, padding_x=None, padding_y=None):\n    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n    if figsize is None:\n        figsize = DEFAULT_FIGSIZE\n    if padding_x is None:\n        padding_x = MAP_PADDING\n    if padding_y is None:\n        padding_y = MAP_PADDING\n    \n    if bounds is None:\n        bounds = renabap_pba_intersect.total_bounds\n\n    # Convert bounds to Web Mercator for basemap compatibility\n    if bounds is not None:\n        # Create a temporary GeoDataFrame with the bounds to reproject\n        temp_bounds = gpd.GeoDataFrame(\n            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS\n        )\n        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds\n    else:\n        bounds_3857 = bounds\n\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)\n    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)\n    return fig, ax\n\n\ndef add_basemap(ax, zoom=13):\n    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n\n    ctx.add_basemap(\n        ax,\n        source=ctx.providers.CartoDB.PositronNoLabels,\n        zorder=0,\n        zoom=zoom,\n    )\n\n    return ax\n\n\ndef add_north_arrow(ax, x=0.95, y=0.05, arrow_length=0.04):\n    \"\"\"Add a north arrow to the map.\"\"\"\n    # Add north arrow, https://stackoverflow.com/a/58110049/604456\n    ax.annotate(\n        \"N\",\n        xy=(x, y),\n        xytext=(x, y - arrow_length),\n        arrowprops=dict(facecolor=\"black\", width=3, headwidth=10),\n        ha=\"center\",\n        va=\"center\",\n        fontsize=14,\n        xycoords=ax.transAxes,\n    )\n\n\ndef add_la_plata_outline(ax):\n    \"\"\"Add the outline of Partido de La Plata to a map.\"\"\"\n    la_plata_3857 = la_plata.to_crs(WEB_MERCATOR_CRS)\n    la_plata_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"black\",\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=5,\n    )\n\n\ndef create_consistent_map(title, bounds=None):\n    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n    fig, ax = setup_base_map(bounds=bounds)\n\n\n    add_basemap(ax)\n\n\n    add_north_arrow(ax)\n\n    add_la_plata_outline(ax)\n\n    ax.set_title(title, fontsize=16, fontweight=\"bold\", pad=20)\n\n    ax.set_axis_off()\n\n    return fig, ax\n\n\ndef wfs_to_gdf(\n    wfs_url: str, layer_name: str, srs: str = \"EPSG:4326\"\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Descarga una capa WFS y la devuelve como GeoDataFrame.\n\n    Args:\n        wfs_url (str): URL del servicio WFS.\n        layer_name (str): Nombre de la capa (typename).\n        srs (str): Código EPSG del sistema de referencia de coordenadas.\n\n    Returns:\n        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.\n    \"\"\"\n    wfs = WebFeatureService(url=wfs_url, version=\"2.0.0\")\n    response = wfs.getfeature(typename=layer_name, srsname=srs)\n    gdf = gpd.read_file(BytesIO(response.read()))\n    return gdf\n\n\ndef create_exposure_tidy_data(data, id_column, peligrosidad_column, method_suffix, \n                            exposure_values, exclude_zero=True):\n    \"\"\"\n    Create tidy exposure dataset in a standardized format.\n    \n    Args:\n        data: DataFrame containing the base data\n        id_column: Column name for the identifier (e.g., 'id_renabap', 'Cuenca', 'eje')\n        peligrosidad_column: Column name for hazard level\n        method_suffix: Suffix for the exposure column (e.g., 'areal', 'ghsl', 'edificios')\n        exposure_values: Series or array of exposure values matching data rows\n        exclude_zero: Whether to exclude zero exposure values\n    \n    Returns:\n        pd.DataFrame: Tidy format dataframe with id, peligrosidad, and exposure columns\n    \"\"\"\n    tidy_data = []\n    for idx, (_, row) in enumerate(data.iterrows()):\n        exposure_value = exposure_values.iloc[idx] if hasattr(exposure_values, 'iloc') else exposure_values[idx]\n        \n        if exclude_zero and exposure_value &lt;= 0:\n            continue\n            \n        tidy_data.append({\n            id_column: row[id_column],\n            \"peligrosidad\": row[peligrosidad_column],\n            f\"fam_expuestas_{method_suffix}\": exposure_value,\n        })\n    \n    return pd.DataFrame(tidy_data)\n\n\ndef create_wide_exposure_dataframe(areal_data, ghsl_data, buildings_data, \n                                 id_columns, exclude_hazard_value=\"none\"):\n    \"\"\"\n    Create wide format exposure dataframe by merging tidy datasets.\n    \n    Args:\n        areal_data: Tidy dataframe with areal interpolation results\n        ghsl_data: Tidy dataframe with GHSL dasymetric results  \n        buildings_data: Tidy dataframe with buildings dasymetric results\n        id_columns: List of columns to merge on (e.g., ['id_renabap', 'peligrosidad'])\n        exclude_hazard_value: Hazard value to exclude from results\n    \n    Returns:\n        pd.DataFrame: Wide format dataframe with all exposure methods\n    \"\"\"\n    # Filter out non-hazard values\n    areal_filtered = areal_data[areal_data[\"peligrosidad\"] != exclude_hazard_value]\n    ghsl_filtered = ghsl_data[ghsl_data[\"peligrosidad\"] != exclude_hazard_value]\n    buildings_filtered = buildings_data[buildings_data[\"peligrosidad\"] != exclude_hazard_value]\n    \n    # Apply column mapping for buildings if needed\n    if \"fam_expuestas_buildings\" in buildings_filtered.columns:\n        buildings_filtered = buildings_filtered.rename(\n            columns={\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"}\n        )\n    \n    # Merge all datasets\n    wide_data = (\n        areal_filtered\n        .merge(ghsl_filtered, on=id_columns, how=\"outer\")\n        .merge(buildings_filtered, on=id_columns, how=\"outer\")\n    )\n    \n    # Fill NaN values with 0\n    wide_data = wide_data.fillna(0)\n    \n    return wide_data\n\n\nresponse = requests.get(RENABAP_URL)\nrenabap = gpd.read_file(StringIO(response.text))\nrenabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\nrenabap_pba = renabap_pba.to_crs(USE_CRS)\n\npeligro = gpd.read_file(PELIGRO_PATH)\npeligro = peligro.to_crs(USE_CRS)\n\npeligro_bounds = peligro.total_bounds\npeligro_bbox = box(*peligro_bounds)\n\nif os.path.exists(PARTIDOS_PATH):\n    partidos = gpd.read_file(PARTIDOS_PATH)\nelse:\n    partidos = wfs_to_gdf(\n        wfs_url=PARTIDOS_WFS_URL,\n        layer_name=\"idera:Departamento\",\n        srs=\"EPSG:5347\",\n    )\n\n    partidos.to_file(PARTIDOS_PATH, driver=\"GeoJSON\")\n\npartidos = partidos.to_crs(USE_CRS)\nla_plata = partidos[partidos[\"fna\"] == \"Partido de La Plata\"]\n\n# Obtener la geometría principal\nmain_geom = la_plata.geometry.iloc[0]\n\n# Si es un MultiPolygon, mantener solo el polígono más grande (el partido principal)\n# Esto elimina la pequeña isla que aparece en los datos\nif main_geom.geom_type == \"MultiPolygon\":\n    # Obtener todos los polígonos y mantener el que tenga mayor área\n    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)\n    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning\n    la_plata.loc[la_plata.index[0], \"geometry\"] = largest_polygon\n\nla_plata_bbox = la_plata.geometry.iloc[0]\n\nrenabap_pba_intersect = renabap_pba[\n    renabap_pba.geometry.intersects(la_plata_bbox)\n].copy()\n\n\nif os.path.exists(CUENCAS_PATH):\n    cuencas = gpd.read_file(CUENCAS_PATH)\nelse:\n    params = {\"where\": \"1=1\", \"outFields\": \"*\", \"f\": \"geojson\"}\n\n    cuencas_response = requests.get(CUENCAS_API_URL, params=params)\n    with open(CUENCAS_PATH, \"w\", encoding=\"utf-8\") as f:\n        f.write(cuencas_response.text)\n\n    cuencas = gpd.read_file(StringIO(cuencas_response.text))\n\ncuencas = cuencas.to_crs(USE_CRS)\ncuencas = cuencas.clip(la_plata)\n\n# Map watershed names to axes based on the EJE_MAPPING\ncuencas[\"eje\"] = (\n    cuencas[\"Cuenca\"]\n    .map(\n        {\n            cuenca: eje\n            for eje, cuencas_list in EJE_MAPPING.items()\n            for cuenca in cuencas_list\n        }\n    )\n    .fillna(\"otro\")\n)\n\n# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)\nrenabap_total_area_ha = (\n    renabap_pba_intersect.geometry.area.sum() / 10000\n)  # Convert m² to hectares\nla_plata_area_ha = la_plata.geometry.iloc[0].area / 10000\npercentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100\n\n# Get common bounds for all maps\ncommon_bounds = la_plata.total_bounds\n\n# Intersect settlements with hazard zones\nsettlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n\nsettle_hazard_cuencas = gpd.overlay(\n    settlement_hazard, cuencas, how=\"intersection\", keep_geom_type=True\n)\n\n\nHay un total de 166 barrios populares en el Partido de La Plata, que representan np.int64(33888) familias. Estos barrios ocupan np.float64(1760.927308165013) hectáreas del Partido de La Plata, o np.float64(1.9638325015304627) por ciento del partido.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#fuentes-de-datos",
    "href": "renabap.html#fuentes-de-datos",
    "title": "3  RENABAP",
    "section": "3.4 Fuentes de datos",
    "text": "3.4 Fuentes de datos\n\n3.4.1 RENABAP\nEl Registro Nacional de Barrios Populares (RENABAP) es producido por la Subsecretaría de Integración Socio Urbana y proporciona información sobre asentamientos informales en Argentina, incluyendo estimaciones de población y delimitaciones geográficas de estos barrios. Más información sobre el RENABAP está disponible en el Observatorio de Barrios Populares. Los datos fueron obtenidos a través del Mapa de Barrios Populares y están disponibles para descarga como GeoJSON.\n\n\n3.4.2 GHSL\nLa Capa Global de Asentamientos Humanos (Global Human Settlement Layer) (Schiavina et al. 2023) es un conjunto de datos de resolución de 100 metros que proporciona estimaciones de población multitemporales (1975-2030) derivadas de datos censales y administrativos, informadas por la distribución y clasificación de áreas construidas. El GHSL ya tiene un uso científico establecido para mapear la exposición poblacional a peligros de inundación (Tellman et al. 2021). Sin embargo, esta fuente presenta limitaciones importantes: estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución (Smith et al. 2019).\n\n\nMostrar código\n# Load GHSL data with dask chunking for memory efficiency\nghsl = rioxarray.open_rasterio(\n    GHSL_PATH,\n    chunks={\"x\": 1024, \"y\": 1024},  # Adjust chunk size based on your memory constraints\n)\n\nghsl = ghsl.rio.reproject(dst_crs=USE_CRS)\n\n\nghsl_clipped = ghsl.rio.clip(\n    [la_plata.geometry.iloc[0]],\n    from_disk=True,  # Process from disk to avoid loading entire dataset into memory\n)\n\n\n\n\n3.4.3 Google-Microsoft-OSM Open Buildings\nLos datos de Google-Microsoft-OSM Open Buildings - combined by VIDA (VIDA 2023) representan una forma más precisa de evaluar dónde se ubican los asentamientos humanos. Este conjunto de datos combina Google’s V3 Open Buildings, Microsoft’s GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo más de 2.7 mil millones de huellas de edificios. Estos datos han sido exitosamente aplicados a evaluaciones de riesgo de inundación por empresas globales de riesgo financiero como ICE, demostrando su utilidad para mapear la exposición climática a nivel de huella de edificio individual. Sin embargo, en ausencia de información sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el número total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de dónde se ubican las personas, sin tener una comprensión precisa de quién vive realmente allí y cuántas personas.\n\n\nMostrar código\ndef fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n\n    # Get S2 cell and bounds\n    center = geodataframe.to_crs(WEB_MERCATOR_CRS).union_all().centroid\n    center_wgs84 = (\n        gpd.GeoDataFrame(geometry=[center], crs=WEB_MERCATOR_CRS)\n        .to_crs(WGS84_CRS)\n        .geometry.iloc[0]\n    )\n    cell = s2sphere.CellId.from_lat_lng(\n        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n    ).parent(10)\n    bounds = geodataframe.to_crs(WGS84_CRS).total_bounds\n\n    # Find matching S2 partition\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=\"https://data.source.coop\",\n        aws_access_key_id=\"\",\n        aws_secret_access_key=\"\",\n        config=Config(s3={\"addressing_style\": \"path\"}),\n    )\n\n    partitions = {\n        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n        for obj in s3.list_objects_v2(\n            Bucket=\"vida\",\n            Prefix=\"google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n        ).get(\"Contents\", [])\n    }\n\n    parent_id = next(\n        str(cell.parent(level).id())\n        for level in range(10, 0, -1)\n        if str(cell.parent(level).id()) in partitions\n    )\n\n    # Setup DuckDB and query\n    con = duckdb.connect()\n    for cmd in [\n        \"INSTALL spatial\",\n        \"LOAD spatial\",\n        \"INSTALL httpfs\",\n        \"LOAD httpfs\",\n        \"SET s3_region='us-east-1'\",\n        \"SET s3_endpoint='data.source.coop'\",\n        \"SET s3_use_ssl=true\",\n        \"SET s3_url_style='path'\",\n    ]:\n        con.execute(cmd)\n\n    # Export and read back\n    query = f\"\"\"\n    COPY (SELECT * FROM 's3://vida/google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n          WHERE bbox.xmax &gt;= {bounds[0]} AND bbox.xmin &lt;= {bounds[2]} AND\n                bbox.ymax &gt;= {bounds[1]} AND bbox.ymin &lt;= {bounds[3]}\n    ) TO '{temp_file}' (FORMAT PARQUET);\n    \"\"\"\n\n    con.execute(query)\n    df = pd.read_parquet(temp_file)\n    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n\n    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=WGS84_CRS)\n\n\n\nif os.path.exists(BUILDINGS_PATH):\n    buildings = gpd.read_parquet(BUILDINGS_PATH)\nelse:\n    buildings = fetch_buildings(renabap_pba_intersect)\n\n\nbuildings_proj = buildings.to_crs(USE_CRS)\n\nbuildings_proj = buildings_proj.clip(la_plata)\n\n\n\nMostrar código\nfig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", common_bounds)\n\nrenabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(WEB_MERCATOR_CRS)\n\nrenabap_pba_intersect_3857.plot(\n    ax=ax1, facecolor=\"none\", edgecolor=\"black\", linewidth=0.5, legend=False, zorder=10\n)\n\nplt.tight_layout()\nplt.show()\n\npeligro_clipped = gpd.clip(peligro, la_plata)\n\npeligro_clipped_3857 = peligro_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Reorder the categories so they map correctly to plasma colormap\npeligro_clipped_3857[\"PELIGROSID_ordered\"] = pd.Categorical(\n    peligro_clipped_3857[\"PELIGROSID\"],\n    categories=[\"baja\", \"media\", \"alta\"],\n    ordered=True,\n)\n\n\nfig2, ax2 = create_consistent_map(\"Zonas de Peligro en La Plata\", common_bounds)\n\n\npeligro_clipped_3857.plot(\n    ax=ax2,\n    column=\"PELIGROSID_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    zorder=5,\n)\n\nplt.tight_layout()\nplt.show()\n\nfig3, ax3 = create_consistent_map(\"Datos de población GHSL\", common_bounds)\n\nghsl_masked = ma.masked_where(ghsl_clipped.values[0] == 0, ghsl_clipped.values[0])\n\nghsl_valid = (ghsl_clipped.values[0] != NODATA_VALUE) & (ghsl_clipped.values[0] != 0)\nghsl_valid_data = ghsl_clipped.values[0][ghsl_valid]\n\nplasma_cmap = PLASMA_CMAP\n\nghsl_clipped_3857 = ghsl_clipped.rio.reproject(WEB_MERCATOR_CRS)\n\n# Mask out zeros AND nodata values\nghsl_masked_3857 = ma.masked_where(\n    (ghsl_clipped_3857.values[0] == 0) | (ghsl_clipped_3857.values[0] == NODATA_VALUE),\n    ghsl_clipped_3857.values[0],\n)\n\nim = ax3.imshow(\n    ghsl_masked_3857,\n    extent=[\n        ghsl_clipped_3857.x.min(),\n        ghsl_clipped_3857.x.max(),\n        ghsl_clipped_3857.y.min(),\n        ghsl_clipped_3857.y.max(),\n    ],\n    cmap=plasma_cmap,\n    alpha=0.75,\n)\n\nplt.tight_layout()\nplt.show()\n\nfig4, ax4 = create_consistent_map(\"Huellas de edificios\", common_bounds)\n\nbuildings_3857 = buildings_proj.to_crs(WEB_MERCATOR_CRS)\n\nbuildings_3857.plot(ax=ax4, facecolor=\"grey\", edgecolor=\"none\", alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Asentamientos RENABAP en La Plata\n\n\n\n\n\n\n\n\n\n\n\n(b) Zonas de Peligro en La Plata\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Datos de población GHSL\n\n\n\n\n\n\n\n\n\n\n\n(d) Huellas de edificios\n\n\n\n\n\n\n\nFigure 3.1: Fuentes de datos para análisis de exposición",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#metodología-y-procesamiento",
    "href": "renabap.html#metodología-y-procesamiento",
    "title": "3  RENABAP",
    "section": "3.5 Metodología y procesamiento",
    "text": "3.5 Metodología y procesamiento\n\n3.5.1 Interpolación por area\nLa interpolación areal es un método simple en el que las variables de los datos fuente se ponderan según la superposición entre polígonos fuente y objetivo, luego se reagregan para ajustarse a las geometrías de los polígonos objetivo. En nuestro análisis, esto significa distribuir proporcionalmente la población de cada barrio popular según el área de intersección con diferentes niveles de peligro de inundación. El analasis original de la exposición poblacional a peligros de inundación en la región del Partido de La Plata se realizó utilizando este método.\n\n\nMostrar código\nif renabap_pba_intersect.crs != peligro.crs:\n    peligro = peligro.to_crs(renabap_pba_intersect.crs)\n\nhazard_levels = peligro[\"PELIGROSID\"].unique()\n\nrenabap_with_porciones = renabap_pba_intersect.copy()\nfor level in hazard_levels:\n    renabap_with_porciones[f\"porcion_{level}\"] = 0.0\n\nrenabap_with_porciones[\"total_area\"] = renabap_with_porciones.geometry.area\n\nfor idx, barrio in renabap_with_porciones.iterrows():\n    barrio_geom = barrio.geometry\n    barrio_total_area = barrio_geom.area\n\n    if barrio_total_area == 0:\n        continue\n\n    for level in hazard_levels:\n        hazard_subset = peligro[peligro[\"PELIGROSID\"] == level]\n\n        if hazard_subset.empty:\n            continue\n\n        intersection_area = 0\n        for _, hazard_row in hazard_subset.iterrows():\n            try:\n                intersection = barrio_geom.intersection(hazard_row.geometry)\n                if not intersection.is_empty:\n                    intersection_area += intersection.area\n            except Exception as e:\n                print(\n                    f\"Error calculating intersection for {barrio.get('nombre_barrio', idx)}: {e}\"\n                )\n                continue\n\n        proportion = (\n            intersection_area / barrio_total_area if barrio_total_area &gt; 0 else 0\n        )\n        renabap_with_porciones.at[idx, f\"porcion_{level}\"] = proportion\n\n# Create barrio tidy format using consolidated function\nbarrio_areal_rows = []\nfor idx, row in renabap_with_porciones.iterrows():\n    for level in hazard_levels:\n        familias_expuestas = row[f\"porcion_{level}\"] * row[\"familias_aproximadas\"]\n        if familias_expuestas &gt; 0:\n            barrio_areal_rows.append({\n                \"id_renabap\": row[\"id_renabap\"],\n                \"PELIGROSID\": level,\n                \"fam_expuestas\": familias_expuestas,\n            })\n\nbarrio_areal_temp = pd.DataFrame(barrio_areal_rows)\nbarrio_areal_tidy = create_exposure_tidy_data(\n    data=barrio_areal_temp,\n    id_column=\"id_renabap\", \n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"areal\",\n    exposure_values=barrio_areal_temp[\"fam_expuestas\"],\n    exclude_zero=True\n)\n\n# 2. CUENCA AREAL EXPOSURE - aggregate from barrio level, avoiding double counting\n# Get the cuenca for each settlement - but handle settlements that cross cuenca boundaries\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\n\n# Check if any settlements appear in multiple cuencas\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\n\nif len(multi_cuenca_settlements) &gt; 0:\n    # For settlements in multiple cuencas, assign to the cuenca with largest intersection\n    # For now, just take the first occurrence\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\ncuenca_areal_tidy = barrio_areal_tidy[\n    barrio_areal_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE\n].merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\ncuenca_areal_tidy = (\n    cuenca_areal_tidy.groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n# 3. EJE AREAL EXPOSURE - same fix\ncuenca_eje_mapping = settle_hazard_cuencas[[\"Cuenca\", \"eje\"]].drop_duplicates()\n\neje_areal_tidy = cuenca_areal_tidy.merge(cuenca_eje_mapping, on=\"Cuenca\")\neje_areal_tidy = (\n    eje_areal_tidy.groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n\n\n\n3.5.2 Cuenta de edificios\n\n\n3.5.3 Mapeo dasymetrico\nEl mapeo dasimétrico reorganiza datos cartográficos de una unidad de recolección en áreas más precisas, modificando los límites originales usando datos de apoyo relacionados. Por ejemplo, un atributo de población organizado por tracto censal se vuelve más significativo cuando se eliminan áreas donde es razonable inferir que la gente no vive (cuerpos de agua, terrenos vacíos). En nuestro caso, utilizamos datos GHSL y huellas de edificios como información auxiliar para mejorar la precisión de las estimaciones de distribución poblacional.\n\n3.5.3.1 Mapeo dasymetrico con datos de edificios\n\n\nMostrar código\n# Get ALL buildings per settlement (not just hazard-intersected ones)\nbuildings_settlement = gpd.overlay(\n    buildings_proj, renabap_pba_intersect, how=\"intersection\"\n)\ntotal_buildings_per_settlement = (\n    buildings_settlement.groupby(\"id_renabap\")\n    .size()\n    .reset_index(name=\"total_buildings\")\n)\n\n# Get buildings intersected with hazard zones\nbuildings_hazard = gpd.overlay(\n    buildings_proj, settle_hazard_cuencas, how=\"intersection\"\n)\n\n# 1. Buildings per barrio-hazard (including non-hazard areas)\nbuildings_barrio_hazard = (\n    buildings_hazard.groupby([\"id_renabap\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\n\n# Calculate ratios using TOTAL buildings per settlement (not just hazard buildings)\nbarrio_ratios = buildings_barrio_hazard.merge(\n    total_buildings_per_settlement, on=\"id_renabap\"\n)\nbarrio_ratios[\"ratio\"] = (\n    barrio_ratios[\"buildings_count\"] / barrio_ratios[\"total_buildings\"]\n)\nbarrio_pop = renabap_pba_intersect[\n    [\"id_renabap\", \"familias_aproximadas\"]\n].drop_duplicates()\nbarrio_exposure = barrio_ratios.merge(barrio_pop, on=\"id_renabap\")\nbarrio_exposure[\"fam_expuestas\"] = (\n    barrio_exposure[\"ratio\"] * barrio_exposure[\"familias_aproximadas\"]\n)\n\n# Add non-hazard population for each settlement\nsettlements_with_hazards = barrio_exposure[\"id_renabap\"].unique()\nall_settlements = total_buildings_per_settlement[\"id_renabap\"].unique()\n\nfor settlement in all_settlements:\n    if settlement in settlements_with_hazards:\n        # Calculate non-hazard population\n        hazard_pop = barrio_exposure[barrio_exposure[\"id_renabap\"] == settlement][\n            \"fam_expuestas\"\n        ].sum()\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        non_hazard_pop = total_pop - hazard_pop\n\n        if non_hazard_pop &gt; 0:\n            barrio_exposure = pd.concat(\n                [\n                    barrio_exposure,\n                    pd.DataFrame(\n                        [\n                            {\n                                \"id_renabap\": settlement,\n                                \"PELIGROSID\": \"none\",\n                                \"buildings_count\": 0,\n                                \"total_buildings\": total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0],\n                                \"ratio\": (\n                                    total_buildings_per_settlement[\n                                        total_buildings_per_settlement[\"id_renabap\"]\n                                        == settlement\n                                    ][\"total_buildings\"].iloc[0]\n                                    - buildings_hazard[\n                                        buildings_hazard[\"id_renabap\"] == settlement\n                                    ].shape[0]\n                                )\n                                / total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                if total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                &gt; 0\n                                else 0,\n                                \"familias_aproximadas\": total_pop,\n                                \"fam_expuestas\": non_hazard_pop,\n                            }\n                        ]\n                    ),\n                ],\n                ignore_index=True,\n            )\n    else:\n        # Settlement with no hazard intersection - all population is non-hazard\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        barrio_exposure = pd.concat(\n            [\n                barrio_exposure,\n                pd.DataFrame(\n                    [\n                        {\n                            \"id_renabap\": settlement,\n                            \"PELIGROSID\": \"none\",\n                            \"buildings_count\": 0,\n                            \"total_buildings\": total_buildings_per_settlement[\n                                total_buildings_per_settlement[\"id_renabap\"]\n                                == settlement\n                            ][\"total_buildings\"].iloc[0],\n                            \"ratio\": 1.0,\n                            \"familias_aproximadas\": total_pop,\n                            \"fam_expuestas\": total_pop,\n                        }\n                    ]\n                ),\n            ],\n            ignore_index=True,\n        )\n\n# Create buildings tidy dataframe for barrio level using consolidated function\nbuildings_barrio_tidy = create_exposure_tidy_data(\n    data=barrio_exposure,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\", \n    method_suffix=\"buildings\",\n    exposure_values=barrio_exposure[\"fam_expuestas\"],\n    exclude_zero=False  # Keep all values including zeros for completeness\n)\n\n# 2. Cuenca exposure - using total buildings across all settlements in cuenca\nbuildings_cuenca_hazard = (\n    buildings_hazard.groupby([\"Cuenca\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_cuenca_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"Cuenca\"]].drop_duplicates(),\n        on=\"id_renabap\",\n    )\n    .groupby(\"Cuenca\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\ncuenca_ratios = buildings_cuenca_hazard.merge(buildings_cuenca_total, on=\"Cuenca\")\ncuenca_ratios[\"ratio\"] = (\n    cuenca_ratios[\"buildings_count\"] / cuenca_ratios[\"total_buildings_all\"]\n)\n\ncuenca_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"Cuenca\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\ncuenca_exposure = cuenca_ratios.merge(cuenca_pop, on=\"Cuenca\")\ncuenca_exposure[\"fam_expuestas\"] = (\n    cuenca_exposure[\"ratio\"] * cuenca_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for cuenca level using consolidated function\nbuildings_cuenca_tidy = create_exposure_tidy_data(\n    data=cuenca_exposure,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\", \n    exposure_values=cuenca_exposure[\"fam_expuestas\"],\n    exclude_zero=False\n)\n\n# 3. Eje exposure - using total buildings across all settlements in eje\nbuildings_eje_hazard = (\n    buildings_hazard.groupby([\"eje\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_eje_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates(), on=\"id_renabap\"\n    )\n    .groupby(\"eje\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\neje_ratios = buildings_eje_hazard.merge(buildings_eje_total, on=\"eje\")\neje_ratios[\"ratio\"] = eje_ratios[\"buildings_count\"] / eje_ratios[\"total_buildings_all\"]\n\neje_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"eje\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\neje_exposure = eje_ratios.merge(eje_pop, on=\"eje\")\neje_exposure[\"fam_expuestas\"] = (\n    eje_exposure[\"ratio\"] * eje_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for eje level using consolidated function\nbuildings_eje_tidy = create_exposure_tidy_data(\n    data=eje_exposure,\n    id_column=\"eje\", \n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\",\n    exposure_values=eje_exposure[\"fam_expuestas\"], \n    exclude_zero=False\n)\n\n\n\n\n3.5.3.2 Mapeo dasymetrico con datos GHSL\n\n\nMostrar código\n# Step 1: Calculate the total GHSL population per barrio popular using zonal statistics\n\n# Convert to the format expected by rasterstats\ngeometries = [geom for geom in renabap_pba_intersect.geometry]\n\n# Use rasterstats for vectorized zonal statistics\nstats = rasterstats.zonal_stats(\n    geometries,\n    ghsl_clipped.values[0],  # rasterstats expects 2D array\n    affine=ghsl_clipped.rio.transform(),\n    stats=[\"sum\"],\n    nodata=ghsl_clipped.rio.nodata,\n)\n\n# Extract the sum values\nghsl_totals = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n\n# Add the GHSL population estimates as a new column\nrenabap_pba_intersect[\"ghsl_pop_est\"] = ghsl_totals\n\n\n# Get the reference raster properties from GHSL data\nreference_raster = ghsl_clipped\nreference_transform = reference_raster.rio.transform()\nreference_crs = reference_raster.rio.crs\nreference_shape = reference_raster.shape[1:]  # Get 2D shape (height, width)\n\n\n# Prepare geometries and values for rasterization\ngeometries_ghsl = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"ghsl_pop_est\"]\n    )\n]\ngeometries_familias = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"familias_aproximadas\"]\n    )\n]\n\n# Create GHSL population raster\nghsl_pop_raster = rasterize(\n    geometries_ghsl,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Create familias aproximadas raster\nfamilias_raster = rasterize(\n    geometries_familias,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n\n# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n# Use masking to avoid division on invalid cells\nmask = (ghsl_clipped.values[0] != NODATA_VALUE) & (ghsl_pop_raster &gt; 0.1)\nghsl_fractional = np.full_like(ghsl_clipped.values[0], NODATA_VALUE, dtype=np.float64)\nghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n\n# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\nmask2 = (ghsl_fractional != NODATA_VALUE) & (familias_raster &gt; 0)\nfamilias_downscaled = np.full_like(ghsl_clipped.values[0], NODATA_VALUE, dtype=np.float64)\nfamilias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n\n# Verify the results - exclude NODATA_VALUE from range calculations\nghsl_valid = ghsl_clipped.values[0] != NODATA_VALUE\nfractional_valid = ghsl_fractional != NODATA_VALUE\ndownscaled_valid = familias_downscaled != NODATA_VALUE\n\n# GHSL downscaling for all three levels using the same approach\n\n# 1. BARRIO-HAZARD EXPOSURE using consolidated approach\nghsl_barrio_exposure = []\nfor idx, row in settlement_hazard.iterrows():\n    stats = zonal_stats(\n        [row.geometry],\n        familias_downscaled,\n        affine=reference_transform,\n        stats=[\"sum\"],\n        nodata=NODATA_VALUE,\n    )[0]\n\n    ghsl_barrio_exposure.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"PELIGROSID\": row[\"PELIGROSID\"],\n            \"fam_expuestas\": stats[\"sum\"] if stats[\"sum\"] is not None else 0,\n        }\n    )\n\nghsl_barrio_temp = pd.DataFrame(ghsl_barrio_exposure)\nghsl_barrio_tidy = create_exposure_tidy_data(\n    data=ghsl_barrio_temp,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_barrio_temp[\"fam_expuestas\"],\n    exclude_zero=False\n)\n\n# 2. CUENCA-HAZARD EXPOSURE using consolidated approach\nghsl_cuenca_exposure = []\nfor cuenca in settle_hazard_cuencas[\"Cuenca\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this cuenca-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"Cuenca\"] == cuenca)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=NODATA_VALUE,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_cuenca_exposure.append(\n                {\n                    \"Cuenca\": cuenca,\n                    \"PELIGROSID\": peligro,\n                    \"fam_expuestas\": total_pop,\n                }\n            )\n\nghsl_cuenca_temp = pd.DataFrame(ghsl_cuenca_exposure)\nghsl_cuenca_tidy = create_exposure_tidy_data(\n    data=ghsl_cuenca_temp,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"PELIGROSID\", \n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_cuenca_temp[\"fam_expuestas\"],\n    exclude_zero=False\n)\n\n# 3. EJE-HAZARD EXPOSURE using consolidated approach\nghsl_eje_exposure = []\nfor eje in settle_hazard_cuencas[\"eje\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this eje-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"eje\"] == eje)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=NODATA_VALUE,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_eje_exposure.append(\n                {\n                    \"eje\": eje,\n                    \"PELIGROSID\": peligro,\n                    \"fam_expuestas\": total_pop,\n                }\n            )\n\nghsl_eje_temp = pd.DataFrame(ghsl_eje_exposure)\nghsl_eje_tidy = create_exposure_tidy_data(\n    data=ghsl_eje_temp,\n    id_column=\"eje\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\", \n    exposure_values=ghsl_eje_temp[\"fam_expuestas\"],\n    exclude_zero=False\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#resultados",
    "href": "renabap.html#resultados",
    "title": "3  RENABAP",
    "section": "3.6 Resultados",
    "text": "3.6 Resultados\n\n\nMostrar código\n# 1. BARRIO-LEVEL WIDE DATAFRAME using consolidated function\nrenabap_info = renabap_pba_intersect[[\"id_renabap\", \"nombre_barrio\"]].drop_duplicates()\n\nbarrio_wide = create_wide_exposure_dataframe(\n    areal_data=barrio_areal_tidy,\n    ghsl_data=ghsl_barrio_tidy, \n    buildings_data=buildings_barrio_tidy,\n    id_columns=[\"id_renabap\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE\n)\n\n# Add barrio names and reorder columns\nbarrio_wide = barrio_wide.merge(renabap_info, on=\"id_renabap\", how=\"left\")\nbarrio_wide = barrio_wide[\n    [\n        \"id_renabap\",\n        \"nombre_barrio\", \n        \"peligrosidad\",\n    ] + EXPOSURE_COLUMNS\n]\n\n# 2. CUENCA-LEVEL WIDE DATAFRAME using consolidated function\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\nif len(multi_cuenca_settlements) &gt; 0:\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\n# Aggregate buildings data from barrio to cuenca level\ncuenca_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE]\n    .merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\n\n# Convert to tidy format for the consolidated function\ncuenca_buildings_tidy_for_merge = create_exposure_tidy_data(\n    data=cuenca_buildings_wide,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"peligrosidad\",\n    method_suffix=\"buildings\", \n    exposure_values=cuenca_buildings_wide[\"fam_expuestas_buildings\"],\n    exclude_zero=False\n)\n\ncuenca_wide = create_wide_exposure_dataframe(\n    areal_data=cuenca_areal_tidy,\n    ghsl_data=ghsl_cuenca_tidy,\n    buildings_data=cuenca_buildings_tidy_for_merge,\n    id_columns=[\"Cuenca\", \"peligrosidad\"], \n    exclude_hazard_value=NON_HAZARD_VALUE\n)\n\ncuenca_wide[\"cuenca\"] = cuenca_wide[\"Cuenca\"].str.lower()\ncuenca_wide = cuenca_wide[\n    [\n        \"cuenca\",\n        \"peligrosidad\",\n    ] + EXPOSURE_COLUMNS\n]\n\n# 3. EJE-LEVEL WIDE DATAFRAME using consolidated function\nsettlement_eje_mapping = settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates()\neje_settlement_counts = settlement_eje_mapping[\"id_renabap\"].value_counts()\nmulti_eje_settlements = eje_settlement_counts[eje_settlement_counts &gt; 1].index\nif len(multi_eje_settlements) &gt; 0:\n    settlement_eje_mapping = settlement_eje_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\n# Aggregate buildings data from barrio to eje level\neje_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE]\n    .merge(settlement_eje_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\n\n# Convert to tidy format for the consolidated function\neje_buildings_tidy_for_merge = create_exposure_tidy_data(\n    data=eje_buildings_wide,\n    id_column=\"eje\",\n    peligrosidad_column=\"peligrosidad\",\n    method_suffix=\"buildings\",\n    exposure_values=eje_buildings_wide[\"fam_expuestas_buildings\"], \n    exclude_zero=False\n)\n\neje_wide = create_wide_exposure_dataframe(\n    areal_data=eje_areal_tidy,\n    ghsl_data=ghsl_eje_tidy,\n    buildings_data=eje_buildings_tidy_for_merge,\n    id_columns=[\"eje\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE\n)\n\neje_wide = eje_wide[\n    [\n        \"eje\", \n        \"peligrosidad\",\n    ] + EXPOSURE_COLUMNS\n]\n\n\n\n3.6.1 Comparación de métodos\n\nMostrar código\nbarrio_tidy = pd.melt(\n    barrio_wide,\n    id_vars=[\"id_renabap\", \"nombre_barrio\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\nbarrio_tidy[\"metodo\"] = barrio_tidy[\"metodo\"].str.replace(COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\")\n\nbarrio_tidy = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"geometry\"]], on=\"id_renabap\", how=\"left\"\n)\n\nbarrio_tidy[\"area\"] = barrio_tidy.geometry.apply(lambda geom: geom.area)\n\n\n\n\n\n\n# Group by id_renabap and peligro, then find which method has the highest fam_expuestas\nhighest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmax()\n\n# Get the method names for the highest estimates\nmethod_counts = barrio_tidy.loc[highest_methods, \"metodo\"].value_counts()\n\nplt.figure(figsize=(12, 7))\nsns.barplot(x=method_counts.index, y=method_counts.values, palette='viridis')\nplt.title('Métodos que Más Frecuentemente Devuelven la Mayor Estimación de Familias Expuestas', \n          fontsize=14, fontweight='bold', pad=20)\nplt.xlabel('Método', fontsize=12, fontweight='bold')\nplt.ylabel('Frecuencia', fontsize=12, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Group by id_renabap and peligro, then find which method has the lowest fam_expuestas\nlowest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmin()\n\n# Get the method names for the lowest estimates\nlowest_method_counts = barrio_tidy.loc[lowest_methods, \"metodo\"].value_counts()\n\n# Crear gráfico de barras para métodos con menor estimación\nplt.figure(figsize=(12, 7))\nsns.barplot(x=lowest_method_counts.index, y=lowest_method_counts.values, palette='viridis')\nplt.title('Métodos que Más Frecuentemente Devuelven la Menor Estimación de Familias Expuestas', \n          fontsize=14, fontweight='bold', pad=20)\nplt.xlabel('Método', fontsize=12, fontweight='bold')\nplt.ylabel('Frecuencia', fontsize=12, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# First, left join familias_aproximadas from renabap_pba_intersect\nfinal_tidy_with_pop = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"familias_aproximadas\"]],\n    on=\"id_renabap\",\n    how=\"left\",\n)\n\n# Calculate the range (highest - lowest) per id_renabap and peligro\nrange_by_barrio = final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].agg([\"max\", \"min\"])\nrange_by_barrio[\"range\"] = range_by_barrio[\"max\"] - range_by_barrio[\"min\"]\n\n# Merge back to get the total population for each barrio\nrange_by_barrio = range_by_barrio.reset_index().merge(\n    final_tidy_with_pop[[\"id_renabap\", \"familias_aproximadas\"]].drop_duplicates(),\n    on=\"id_renabap\",\n)\n\n# Calculate absolute percent difference as fraction of total barrio population\nrange_by_barrio[\"abs_pct_diff\"] = (\n    range_by_barrio[\"range\"] / range_by_barrio[\"familias_aproximadas\"]\n) * 100\n\n# Calculate average absolute percent difference per peligro level\navg_pct_diff_by_peligro = range_by_barrio.groupby(\"peligrosidad\")[\"abs_pct_diff\"].mean()\n\n# Calculate absolute percent difference by method\nmethod_errors = final_tidy_with_pop.copy()\n\n\n# Calculate absolute error as percent of total population for each method\nmethod_errors[\"abs_error_pct\"] = abs(\n    method_errors[\"fam_expuestas\"] - method_errors.groupby([\"id_renabap\", \"peligrosidad\"])[\"fam_expuestas\"].transform(\"mean\")\n) / method_errors[\"familias_aproximadas\"] * 100\n\n# Calculate coefficient of variation for each barrio-peligro combination\nbarrio_reliability = final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"]).agg({\n    \"fam_expuestas\": [\"mean\", \"std\"],\n    \"familias_aproximadas\": \"first\"\n}).reset_index()\n\nbarrio_reliability.columns = [\"id_renabap\", \"peligrosidad\", \"mean_estimate\", \"std_estimate\", \"familias_aproximadas\"]\nbarrio_reliability[\"coefficient_variation\"] = barrio_reliability[\"std_estimate\"] / barrio_reliability[\"mean_estimate\"]\n\n# Create box plot\nplt.figure(figsize=(12, 3))\nsns.boxplot(data=barrio_reliability, y=\"peligrosidad\", x=\"coefficient_variation\", \n           hue=\"peligrosidad\", palette=\"viridis\", legend=False, width=0.4)\nplt.title(\"Variabilidad de Estimaciones entre Métodos\", fontsize=16, fontweight='bold', pad=20)\nplt.ylabel(\"Peligrosidad\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Coeficiente de Variación (0 = estimaciones idénticas, 1 = muy variables)\", fontsize=12, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n# Create scatter plot colored by peligrosidad\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio[range_by_barrio[\"peligrosidad\"] == peligro]\n\n    plt.scatter(\n        peligro_data[\"familias_aproximadas\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Familias Aproximadas (Total Barrio Population)\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Barrio Size (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# First, get the area data from final_tidy\narea_data = barrio_tidy[[\"id_renabap\", \"area\"]].drop_duplicates()\n\n# Merge area back into range_by_barrio\nrange_by_barrio_with_area = range_by_barrio.merge(\n    area_data, on=\"id_renabap\", how=\"left\"\n)\n\n\n\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio_with_area[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio_with_area[\n        range_by_barrio_with_area[\"peligrosidad\"] == peligro\n    ]\n\n    plt.scatter(\n        peligro_data[\"area\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Area\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Area (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n# Filter for high exposure (alta peligrosidad) using the joined dataframe\nalta_data = barrio_tidy[barrio_tidy[\"peligrosidad\"] == \"alta\"].copy()\n\n# Aggregate by nombre_barrio and sum fam_expuestas for each method\n# This handles cases where there are multiple geometries with the same barrio name\nalta_aggregated = (\n    alta_data.groupby([\"nombre_barrio\", \"metodo\"])[\"fam_expuestas\"].sum().reset_index()\n)\n\n# Remove cases where the barrio name is \"Sin Nombre\"\nalta_aggregated = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"] != \"Sin Nombre\"\n].copy()\n\n# Calculate total exposure per barrio across all methods\ntotal_exposure = (\n    alta_aggregated.groupby(\"nombre_barrio\")[\"fam_expuestas\"]\n    .sum()\n    .sort_values(ascending=False)\n)\ntop_10_barrios = total_exposure.head(10).index\n\n# Filter aggregated data for top 10 barrios\ntop_10_data = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"].isin(top_10_barrios)\n].copy()\n\n# Create range plot showing min, max, and individual points\nplt.figure(figsize=(14, 10))  # Increased height to accommodate longer barrio names\n\n\n# Use color constants defined at the top\nplasma_cmap = PLASMA_CMAP\npeligrosidad_colors = PELIGROSIDAD_COLORS.copy()\nmethod_colors = METHOD_COLORS.copy()\n\nfor i, barrio in enumerate(top_10_barrios):\n    barrio_data = top_10_data[top_10_data[\"nombre_barrio\"] == barrio]\n    if len(barrio_data) &gt; 0:\n        values = barrio_data[\"fam_expuestas\"].values\n        min_val = values.min()\n        max_val = values.max()\n\n        # Plot range line\n        plt.plot([min_val, max_val], [i, i], \"k-\", alpha=0.5, linewidth=2)\n\n        # Plot individual points colored by method\n        for _, row in barrio_data.iterrows():\n            color = method_colors[row[\"metodo\"]]\n            plt.plot(row[\"fam_expuestas\"], i, \"o\", color=color, markersize=6, alpha=0.8)\n\nplt.yticks(range(len(top_10_barrios)), top_10_barrios)\nplt.xlabel(\"Familias Expuestas\")\nplt.ylabel(\"Barrio\")\nplt.title(\"Range of High Exposure Estimates for Top 10 Barrios\", fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# Add legend\nlegend_elements = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=color,\n        markersize=8,\n        label=method,\n    )\n    for method, color in method_colors.items()\n]\nplt.legend(handles=legend_elements, title=\"Método\")\n\nplt.tight_layout()\nplt.show()\n\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"area\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_area\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_expuestas_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n/tmp/ipykernel_638950/442953318.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=method_counts.index, y=method_counts.values, palette='viridis')\n\n\n/tmp/ipykernel_638950/442953318.py:55: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=lowest_method_counts.index, y=lowest_method_counts.values, palette='viridis')\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Discrepancia vs población total del barrio\n\n\n\n\n\n\n\n\n\n\n\n(b) Discrepancia vs área del barrio\n\n\n\n\n\n\n\n\n\n\n\n(c) Rango de estimaciones para barrios con mayor exposición\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n\n\n\n\n(f)\n\n\n\n\n\n\n\nFigure 3.2: Análisis comparativo de métodos de estimación por barrio\n\n\n\n\n\nMostrar código\ndef plot_method_map(\n    method_name,\n    final_tidy,\n    la_plata,\n    peligrosidad_colors,\n    common_bounds,\n    create_consistent_map,\n):\n    fig, ax = create_consistent_map(\n        f\"Barrios por población expuesta estimada - {method_name.capitalize()}\",\n        common_bounds,\n    )\n\n    method_data = final_tidy[\n        (final_tidy[\"metodo\"] == method_name)\n        & (final_tidy[\"peligrosidad\"].isin([\"alta\", \"media\"]))\n    ].copy()\n\n    method_gdf = gpd.GeoDataFrame(method_data, geometry=\"geometry\", crs=USE_CRS)\n    method_gdf = method_gdf.clip(la_plata)\n    method_gdf_3857 = method_gdf.to_crs(WEB_MERCATOR_CRS)\n\n    plotting_order = [\"media\", \"alta\"]\n\n    np.random.seed(42)\n    for peligrosidad in plotting_order:\n        level_data = method_gdf_3857[method_gdf_3857[\"peligrosidad\"] == peligrosidad]\n        for _, row in level_data.iterrows():\n            centroid = row[\"geometry\"].centroid\n            jitter_x = np.random.uniform(-200, 200)\n            jitter_y = np.random.uniform(-200, 200)\n            x_pos = centroid.x + jitter_x\n            y_pos = centroid.y + jitter_y\n            color = peligrosidad_colors[row[\"peligrosidad\"]]\n            size = max(10, row[\"fam_expuestas\"] * 2 + 15)\n            ax.scatter(\n                x_pos,\n                y_pos,\n                s=size,\n                color=color,\n                alpha=0.9,\n                edgecolors=\"white\",\n                linewidth=1.0,\n            )\n\n    legend_elements = [\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"o\",\n            color=\"w\",\n            markerfacecolor=color,\n            markersize=8,\n            label=level.capitalize(),\n        )\n        for level, color in peligrosidad_colors.items()\n    ]\n    ax.legend(handles=legend_elements, title=\"Nivel de Peligrosidad\", loc=\"upper right\")\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nMostrar código\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"area\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_area\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_expuestas_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n\n\n3.6.2 Exposición por barrio\n\nMostrar código\nmethods = barrio_tidy[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        barrio_tidy,\n        la_plata,\n        peligrosidad_colors,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.3: Comparación de métodos de estimación de exposición por barrio\n\n\n\n\n\nMostrar código\nshow(barrio_summary)\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.3 Exposición por cuenca\n\nMostrar código\ncuencas_centroids = cuencas.copy()\ncuencas_centroids[\"geometry\"] = cuencas_centroids[\"geometry\"].centroid\n\n# Create a lowercase version of Cuenca for matching\ncuencas_centroids[\"cuenca_lower\"] = cuencas_centroids[\"Cuenca\"].str.lower()\n\ncuenca_tidy = pd.melt(\n    cuenca_wide,\n    id_vars=[\"cuenca\", \"peligrosidad\"],  \n    value_vars=EXPOSURE_COLUMNS, \n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\ncuenca_tidy[\"metodo\"] = cuenca_tidy[\"metodo\"].str.replace(COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\")\n\ncuenca_tidy_with_geometry = cuenca_tidy.merge(\n    cuencas_centroids[[\"cuenca_lower\", \"geometry\"]],\n    left_on=\"cuenca\",\n    right_on=\"cuenca_lower\",\n    how=\"left\",\n)\n\ncuenca_tidy_gdf = gpd.GeoDataFrame(\n    cuenca_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = cuenca_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        cuenca_tidy_gdf,\n        la_plata,\n        peligrosidad_colors,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.4: Comparación de métodos de estimación de exposición por cuenca\n\n\n\n\n\nMostrar código\nshow(cuenca_wide)\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.4 Exposición por eje\n\nMostrar código\neje_tidy = pd.melt(\n    eje_wide,\n    id_vars=[\"eje\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\neje_tidy[\"metodo\"] = eje_tidy[\"metodo\"].str.replace(COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\")\n\n# Create eje geodataframe by dissolving cuencas by eje and then taking centroids\nejes = cuencas.dissolve(by=\"eje\").reset_index()\nejes_centroids = ejes.copy()\nejes_centroids[\"geometry\"] = ejes_centroids[\"geometry\"].centroid\n\neje_tidy_with_geometry = eje_tidy.merge(\n    ejes_centroids[[\"eje\", \"geometry\"]], on=\"eje\", how=\"left\"\n)\n\neje_tidy_gdf = gpd.GeoDataFrame(\n    eje_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = eje_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        eje_tidy_gdf,\n        la_plata,\n        peligrosidad_colors,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.5: Comparación de métodos de estimación de exposición por eje de cuenca\n\n\n\n\n\nMostrar código\nshow(eje_wide)\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#conclusiones",
    "href": "renabap.html#conclusiones",
    "title": "3  RENABAP",
    "section": "3.7 Conclusiones",
    "text": "3.7 Conclusiones\n\n\n\n\nSchiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023. “GHS-POP R2023A - GHS Population Grid Multitemporal (1975-2030).” European Commission, Joint Research Centre (JRC). https://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of Flood Exposure in Developing Countries Using High-Resolution Population Data.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite Imaging Reveals Increased Proportion of Population Exposed to Floods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by VIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Schiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023.\n“GHS-POP R2023A - GHS Population Grid Multitemporal\n(1975-2030).” European Commission, Joint Research Centre (JRC).\nhttps://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of\nFlood Exposure in Developing Countries Using High-Resolution Population\nData.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite\nImaging Reveals Increased Proportion of Population Exposed to\nFloods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by\nVIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "References"
    ]
  }
]