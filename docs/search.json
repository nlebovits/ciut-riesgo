[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CIUT Riesgo",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "exposicion.html",
    "href": "exposicion.html",
    "title": "1  Exposición",
    "section": "",
    "text": "1.1 Introducción a la Exposición\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#análisis-de-exposición",
    "href": "exposicion.html#análisis-de-exposición",
    "title": "1  Exposición",
    "section": "1.2 Análisis de Exposición",
    "text": "1.2 Análisis de Exposición\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#evaluación-de-riesgos",
    "href": "exposicion.html#evaluación-de-riesgos",
    "title": "1  Exposición",
    "section": "1.3 Evaluación de Riesgos",
    "text": "1.3 Evaluación de Riesgos\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "suavizacion.html",
    "href": "suavizacion.html",
    "title": "2  Suavización",
    "section": "",
    "text": "2.1 Conceptos de Suavización\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#métodos-de-suavización",
    "href": "suavizacion.html#métodos-de-suavización",
    "title": "2  Suavización",
    "section": "2.2 Métodos de Suavización",
    "text": "2.2 Métodos de Suavización\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#aplicaciones-prácticas",
    "href": "suavizacion.html#aplicaciones-prácticas",
    "title": "2  Suavización",
    "section": "2.3 Aplicaciones Prácticas",
    "text": "2.3 Aplicaciones Prácticas\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "renabap.html",
    "href": "renabap.html",
    "title": "3  RENABAP",
    "section": "",
    "text": "3.1 Resumen ejecutivo\nLos datos procesados, incluyendo las estimaciones de exposición por barrio popular para los tres métodos de estimación, desglosados por nivel de peligro, están disponibles para descarga en formato CSV. Haga clic aquí para descargar los datos por barrio. Los datos agregados por cuenca también están disponibles, incluyendo una columna “eje” que permite resumir los datos al nivel de eje de cuenca. Haga clic aquí para descargar los datos por cuenca.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#objetivos",
    "href": "renabap.html#objetivos",
    "title": "3  RENABAP",
    "section": "3.2 Objetivos",
    "text": "3.2 Objetivos\nEl objetivo principal de este análisis es calcular con mayor precisión la exposición poblacional en la región del Partido de La Plata, comparando el enfoque actual de interpolación por área de datos del RENABAP con enfoques de mapeo dasimétrico de mayor resolución utilizando datos de la Capa Global de Asentamientos Humanos (GHSL) y el conjunto de datos de edificios abiertos de Google-Microsoft OpenStreetMap.\nPara lograr este objetivo, necesitamos:\n\nExplicar y comparar metodologías: Desarrollar una comprensión clara de las diferencias entre interpolación por área y mapeo dasimétrico\nEvaluar fuentes de datos: Analizar las ventajas y limitaciones de cada conjunto de datos utilizado\nCrear estimaciones robustas: Generar un rango de posibles exposiciones poblacionales para informar la toma de decisiones\nPriorizar recursos: Identificar áreas donde se requiera recopilación de datos más precisa",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#contexto",
    "href": "renabap.html#contexto",
    "title": "3  RENABAP",
    "section": "3.3 Contexto",
    "text": "3.3 Contexto\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\nfrom io import BytesIO, StringIO\nfrom owslib.wfs import WebFeatureService\nfrom shapely.geometry import box\nimport geopandas as gpd\nimport requests\nimport pandas as pd\nimport os\n\nimport boto3\nimport duckdb\n\n\nimport numpy as np\nimport s2sphere\nfrom botocore.config import Config\nfrom rasterstats import zonal_stats\nimport rasterstats\nfrom rasterio.features import rasterize\nimport numpy.ma as ma\nimport itables\nfrom itables import show\nimport json\nimport requests\nimport matplotlib.cm as cm\nfrom IPython.display import HTML, display\n\nimport seaborn as sns\nimport rioxarray\n\n# =============================================================================\n# ITABLES SPANISH CONFIGURATION\n# =============================================================================\n\n# Configure Argentine Spanish for itables\ntry:\n    spanish_url = \"https://cdn.datatables.net/plug-ins/2.3.3/i18n/es-AR.json\"\n    response = requests.get(spanish_url)\n    response.raise_for_status()\n    spanish_config = response.json()\n    itables.options.language = spanish_config\nexcept Exception:\n    pass  # Fall back to English if configuration fails\n\n# Configure smaller font size for all itables\ncss = \"\"\"\n.dt-container {\n  font-size: small;\n}\n\"\"\"\ndisplay(HTML(f\"&lt;style&gt;{css}&lt;/style&gt;\"))\n\n# Helper function to round numeric columns for display\ndef round_numeric_columns(df, decimals=0):\n    \"\"\"Round all numeric columns in a DataFrame to specified decimal places.\"\"\"\n    df_display = df.copy()\n    numeric_columns = df_display.select_dtypes(include=[np.number]).columns\n    df_display[numeric_columns] = df_display[numeric_columns].round(decimals)\n    return df_display\n\n# =============================================================================\n# CONSTANTS AND CONFIGURATION\n# =============================================================================\n\n# Coordinate Reference Systems\nUSE_CRS = \"EPSG:5349\"  # POSGAR 2007 / Argentina 4\nWEB_MERCATOR_CRS = \"EPSG:3857\"  # Web Mercator for visualization\nWGS84_CRS = \"EPSG:4326\"  # WGS84 for API calls\n\n# File paths\nBASE_PATH = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo\"\nDATA_PATH = f\"{BASE_PATH}/notebooks/data\"\nPELIGRO_PATH = f\"{DATA_PATH}/la_plata_pelig_2023_datos_originales.geojson\"\nPARTIDOS_PATH = f\"{DATA_PATH}/pba_partidos.geojson\"\nCUENCAS_PATH = f\"{BASE_PATH}/notebooks/cuencas_buenos_aires.geojson\"\nBUILDINGS_PATH = f\"{BASE_PATH}/notebooks/buildings_filtered.parquet\"\nGHSL_PATH = \"/home/nissim/Downloads/spatial/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13.tif\"\n\n# Data URLs\nRENABAP_URL = (\n    \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\n)\nPARTIDOS_WFS_URL = \"https://geo.arba.gov.ar/geoserver/idera/wfs\"\nCUENCAS_API_URL = \"https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query\"\n\n# Data processing constants\nHAZARD_LEVELS = [\"baja\", \"media\", \"alta\"]\nMETHOD_NAMES = [\"edificios\", \"ghsl\", \"areal\"]\nEXPOSURE_COLUMNS = [\n    \"fam_exp_edificios\",\n    \"fam_exp_ghsl\",\n    \"fam_exp_areal\",\n]\nNON_HAZARD_VALUE = \"none\"\nNODATA_VALUE = -200\n\n# Column mappings and renaming\nCOLUMN_MAPPINGS = {\n    \"buildings_to_edificios\": {\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"},\n    \"method_cleanup_prefix\": \"fam_expuestas_\",\n}\n\n# Basic visualization settings (only for repeated values)\nDEFAULT_FIGSIZE = (12, 10)\nMAP_PADDING = 500\nPLASMA_CMAP = plt.cm.plasma\n\n# Color schemes for visualization\nPELIGROSIDAD_COLORS = {\n    \"alta\": PLASMA_CMAP(0.8),\n    \"media\": PLASMA_CMAP(0.5),\n    \"baja\": PLASMA_CMAP(0.2),\n}\n\nMETHOD_COLORS = {\n    \"fam_exp_areal\": PLASMA_CMAP(0.8),\n    \"fam_exp_ghsl\": PLASMA_CMAP(0.5),\n    \"fam_exp_edificios\": PLASMA_CMAP(0.2),\n}\n\n# Eje mapping for watershed analysis\nEJE_MAPPING = {\n    \"noreste\": [\"Area de Bañados\", \"Cuenca Arroyo Rodriguez-Don Carlos\"],\n    \"noroeste\": [\"Cuenca Arroyo Martín-Carnaval\", \"Cuenca Arroyo Pereyra\"],\n    \"central\": [\"Cuenca Arroyo del Gato\"],\n    \"sudoeste\": [\"Cuenca A° Maldonado\", \"Cuenca Río Samborombón\"],\n    \"sudeste\": [\"Cuenca Arroyo El Pescado\"],\n}\n\n\ndef setup_base_map(figsize=None, bounds=None, padding_x=None, padding_y=None):\n    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n    if figsize is None:\n        figsize = DEFAULT_FIGSIZE\n    if padding_x is None:\n        padding_x = MAP_PADDING\n    if padding_y is None:\n        padding_y = MAP_PADDING\n\n    if bounds is None:\n        bounds = renabap_pba_intersect.total_bounds\n\n    # Convert bounds to Web Mercator for basemap compatibility\n    if bounds is not None:\n        # Create a temporary GeoDataFrame with the bounds to reproject\n        temp_bounds = gpd.GeoDataFrame(\n            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS\n        )\n        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds\n    else:\n        bounds_3857 = bounds\n\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)\n    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)\n    return fig, ax\n\n\ndef add_basemap(ax, zoom=13):\n    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n\n    ctx.add_basemap(\n        ax,\n        source=ctx.providers.CartoDB.PositronNoLabels,\n        zorder=0,\n        zoom=zoom,\n    )\n\n    return ax\n\n\ndef add_north_arrow(ax, x=0.95, y=0.05, arrow_length=0.04):\n    \"\"\"Add a north arrow to the map.\"\"\"\n    # Add north arrow, https://stackoverflow.com/a/58110049/604456\n    ax.annotate(\n        \"N\",\n        xy=(x, y),\n        xytext=(x, y - arrow_length),\n        arrowprops=dict(facecolor=\"black\", width=3, headwidth=10),\n        ha=\"center\",\n        va=\"center\",\n        fontsize=14,\n        xycoords=ax.transAxes,\n    )\n\n\ndef add_la_plata_outline(ax):\n    \"\"\"Add the outline of Partido de La Plata to a map.\"\"\"\n    la_plata_3857 = la_plata.to_crs(WEB_MERCATOR_CRS)\n    la_plata_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"black\",\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=5,\n    )\n\n\ndef create_consistent_map(title, bounds=None):\n    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n    fig, ax = setup_base_map(bounds=bounds)\n\n    add_basemap(ax)\n\n    add_north_arrow(ax)\n\n    add_la_plata_outline(ax)\n\n    ax.set_title(title, fontsize=16, fontweight=\"bold\", pad=20)\n\n    ax.set_axis_off()\n\n    return fig, ax\n\n\ndef wfs_to_gdf(\n    wfs_url: str, layer_name: str, srs: str = \"EPSG:4326\"\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Descarga una capa WFS y la devuelve como GeoDataFrame.\n\n    Args:\n        wfs_url (str): URL del servicio WFS.\n        layer_name (str): Nombre de la capa (typename).\n        srs (str): Código EPSG del sistema de referencia de coordenadas.\n\n    Returns:\n        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.\n    \"\"\"\n    wfs = WebFeatureService(url=wfs_url, version=\"2.0.0\")\n    response = wfs.getfeature(typename=layer_name, srsname=srs)\n    gdf = gpd.read_file(BytesIO(response.read()))\n    return gdf\n\n\ndef create_exposure_tidy_data(\n    data,\n    id_column,\n    peligrosidad_column,\n    method_suffix,\n    exposure_values,\n    exclude_zero=True,\n):\n    \"\"\"\n    Create tidy exposure dataset in a standardized format.\n\n    Args:\n        data: DataFrame containing the base data\n        id_column: Column name for the identifier (e.g., 'id_renabap', 'Cuenca', 'eje')\n        peligrosidad_column: Column name for hazard level\n        method_suffix: Suffix for the exposure column (e.g., 'areal', 'ghsl', 'edificios')\n        exposure_values: Series or array of exposure values matching data rows\n        exclude_zero: Whether to exclude zero exposure values\n\n    Returns:\n        pd.DataFrame: Tidy format dataframe with id, peligrosidad, and exposure columns\n    \"\"\"\n    tidy_data = []\n    for idx, (_, row) in enumerate(data.iterrows()):\n        exposure_value = (\n            exposure_values.iloc[idx]\n            if hasattr(exposure_values, \"iloc\")\n            else exposure_values[idx]\n        )\n\n        if exclude_zero and exposure_value &lt;= 0:\n            continue\n\n        tidy_data.append(\n            {\n                id_column: row[id_column],\n                \"peligrosidad\": row[peligrosidad_column],\n                f\"fam_expuestas_{method_suffix}\": exposure_value,\n            }\n        )\n\n    return pd.DataFrame(tidy_data)\n\n\ndef create_wide_exposure_dataframe(\n    areal_data, ghsl_data, buildings_data, id_columns, exclude_hazard_value=\"none\"\n):\n    \"\"\"\n    Create wide format exposure dataframe by merging tidy datasets.\n\n    Args:\n        areal_data: Tidy dataframe with areal interpolation results\n        ghsl_data: Tidy dataframe with GHSL dasymetric results\n        buildings_data: Tidy dataframe with buildings dasymetric results\n        id_columns: List of columns to merge on (e.g., ['id_renabap', 'peligrosidad'])\n        exclude_hazard_value: Hazard value to exclude from results\n\n    Returns:\n        pd.DataFrame: Wide format dataframe with all exposure methods\n    \"\"\"\n    # Filter out non-hazard values\n    areal_filtered = areal_data[areal_data[\"peligrosidad\"] != exclude_hazard_value]\n    ghsl_filtered = ghsl_data[ghsl_data[\"peligrosidad\"] != exclude_hazard_value]\n    buildings_filtered = buildings_data[\n        buildings_data[\"peligrosidad\"] != exclude_hazard_value\n    ]\n\n    # Apply column mapping for buildings if needed\n    if \"fam_expuestas_buildings\" in buildings_filtered.columns:\n        buildings_filtered = buildings_filtered.rename(\n            columns={\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"}\n        )\n\n    # Merge all datasets\n    wide_data = areal_filtered.merge(ghsl_filtered, on=id_columns, how=\"outer\").merge(\n        buildings_filtered, on=id_columns, how=\"outer\"\n    )\n\n    # Fill NaN values with 0\n    wide_data = wide_data.fillna(0)\n    \n    # Rename columns to shorter format\n    column_mapping = {\n        \"fam_expuestas_areal\": \"fam_exp_areal\",\n        \"fam_expuestas_ghsl\": \"fam_exp_ghsl\", \n        \"fam_expuestas_edificios\": \"fam_exp_edificios\"\n    }\n    wide_data = wide_data.rename(columns=column_mapping)\n\n    return wide_data\n\n\nresponse = requests.get(RENABAP_URL)\nrenabap = gpd.read_file(StringIO(response.text))\nrenabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\nrenabap_pba = renabap_pba.to_crs(USE_CRS)\n\npeligro = gpd.read_file(PELIGRO_PATH)\npeligro = peligro.to_crs(USE_CRS)\n\npeligro_bounds = peligro.total_bounds\npeligro_bbox = box(*peligro_bounds)\n\nif os.path.exists(PARTIDOS_PATH):\n    partidos = gpd.read_file(PARTIDOS_PATH)\nelse:\n    partidos = wfs_to_gdf(\n        wfs_url=PARTIDOS_WFS_URL,\n        layer_name=\"idera:Departamento\",\n        srs=\"EPSG:5347\",\n    )\n\n    partidos.to_file(PARTIDOS_PATH, driver=\"GeoJSON\")\n\npartidos = partidos.to_crs(USE_CRS)\nla_plata = partidos[partidos[\"fna\"] == \"Partido de La Plata\"]\n\n# Obtener la geometría principal\nmain_geom = la_plata.geometry.iloc[0]\n\n# Si es un MultiPolygon, mantener solo el polígono más grande (el partido principal)\n# Esto elimina la pequeña isla que aparece en los datos\nif main_geom.geom_type == \"MultiPolygon\":\n    # Obtener todos los polígonos y mantener el que tenga mayor área\n    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)\n    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning\n    la_plata.loc[la_plata.index[0], \"geometry\"] = largest_polygon\n\nla_plata_bbox = la_plata.geometry.iloc[0]\n\nrenabap_pba_intersect = renabap_pba[\n    renabap_pba.geometry.intersects(la_plata_bbox)\n].copy()\n\n\nif os.path.exists(CUENCAS_PATH):\n    cuencas = gpd.read_file(CUENCAS_PATH)\nelse:\n    params = {\"where\": \"1=1\", \"outFields\": \"*\", \"f\": \"geojson\"}\n\n    cuencas_response = requests.get(CUENCAS_API_URL, params=params)\n    with open(CUENCAS_PATH, \"w\", encoding=\"utf-8\") as f:\n        f.write(cuencas_response.text)\n\n    cuencas = gpd.read_file(StringIO(cuencas_response.text))\n\ncuencas = cuencas.to_crs(USE_CRS)\ncuencas = cuencas.clip(la_plata)\n\n# Map watershed names to axes based on the EJE_MAPPING\ncuencas[\"eje\"] = (\n    cuencas[\"Cuenca\"]\n    .map(\n        {\n            cuenca: eje\n            for eje, cuencas_list in EJE_MAPPING.items()\n            for cuenca in cuencas_list\n        }\n    )\n    .fillna(\"otro\")\n)\n\n# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)\nrenabap_total_area_ha = (\n    renabap_pba_intersect.geometry.area.sum() / 10000\n)  # Convert m² to hectares\nla_plata_area_ha = la_plata.geometry.iloc[0].area / 10000\npercentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100\n\n# Get common bounds for all maps\ncommon_bounds = la_plata.total_bounds\n\n# Intersect settlements with hazard zones\nsettlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n\nsettle_hazard_cuencas = gpd.overlay(\n    settlement_hazard, cuencas, how=\"intersection\", keep_geom_type=True\n)\n\n\n\n\n\nHay un total de 166 barrios populares en el Partido de La Plata, que representan 33888 familias. Estos barrios ocupan 1760 hectáreas del Partido de La Plata, o 2.0 por ciento del partido.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#fuentes-de-datos",
    "href": "renabap.html#fuentes-de-datos",
    "title": "3  RENABAP",
    "section": "3.4 Fuentes de datos",
    "text": "3.4 Fuentes de datos\n\n3.4.1 RENABAP\nEl Registro Nacional de Barrios Populares (RENABAP) es producido por la Subsecretaría de Integración Socio Urbana y proporciona información sobre asentamientos informales en Argentina, incluyendo estimaciones de población y delimitaciones geográficas de estos barrios. Más información sobre el RENABAP está disponible en el Observatorio de Barrios Populares. Los datos fueron obtenidos a través del Mapa de Barrios Populares y están disponibles para descarga como GeoJSON.\n\n\n3.4.2 GHSL\nLa Capa Global de Asentamientos Humanos (Global Human Settlement Layer) (Schiavina et al. 2023) es un conjunto de datos de resolución de 100 metros que proporciona estimaciones de población multitemporales (1975-2030) derivadas de datos censales y administrativos, informadas por la distribución y clasificación de áreas construidas. El GHSL ya tiene un uso científico establecido para mapear la exposición poblacional a peligros de inundación (Tellman et al. 2021). Sin embargo, esta fuente presenta limitaciones importantes: estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución (Smith et al. 2019).\n\n\nMostrar código\n# Load GHSL data with dask chunking for memory efficiency\nghsl = rioxarray.open_rasterio(\n    GHSL_PATH,\n    chunks={\"x\": 1024, \"y\": 1024},  # Adjust chunk size based on your memory constraints\n)\n\nghsl = ghsl.rio.reproject(dst_crs=USE_CRS)\n\n\nghsl_clipped = ghsl.rio.clip(\n    [la_plata.geometry.iloc[0]],\n    from_disk=True,  # Process from disk to avoid loading entire dataset into memory\n)\n\n\n\n\n3.4.3 Peligro de inundación\nLos datos de peligro de inundación utilizados en este análisis fueron desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata (Romanazzi et al. 2019). Estos datos fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que permitió simular la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. El modelo calcula las principales variables hidráulicas (altura del agua, velocidad y caudal) a lo largo del tiempo, y a partir de estos resultados se generaron los mapas de peligrosidad que combinan el efecto de la profundidad con la velocidad de la corriente, ofreciendo un indicador más completo que los mapas tradicionales de máximas profundidades.\n\n\n3.4.4 Google-Microsoft-OSM Open Buildings\nLos datos de Google-Microsoft-OSM Open Buildings - combined by VIDA (VIDA 2023) representan una forma más precisa de evaluar dónde se ubican los asentamientos humanos. Este conjunto de datos combina Google’s V3 Open Buildings, Microsoft’s GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo más de 2.7 mil millones de huellas de edificios. Estos datos han sido exitosamente aplicados a evaluaciones de riesgo de inundación por empresas globales de riesgo financiero como ICE, demostrando su utilidad para mapear la exposición climática a nivel de huella de edificio individual. Sin embargo, en ausencia de información sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el número total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de dónde se ubican las personas, sin tener una comprensión precisa de quién vive realmente allí y cuántas personas.\n\n\nMostrar código\ndef fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n\n    # Get S2 cell and bounds\n    center = geodataframe.to_crs(WEB_MERCATOR_CRS).union_all().centroid\n    center_wgs84 = (\n        gpd.GeoDataFrame(geometry=[center], crs=WEB_MERCATOR_CRS)\n        .to_crs(WGS84_CRS)\n        .geometry.iloc[0]\n    )\n    cell = s2sphere.CellId.from_lat_lng(\n        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n    ).parent(10)\n    bounds = geodataframe.to_crs(WGS84_CRS).total_bounds\n\n    # Find matching S2 partition\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=\"https://data.source.coop\",\n        aws_access_key_id=\"\",\n        aws_secret_access_key=\"\",\n        config=Config(s3={\"addressing_style\": \"path\"}),\n    )\n\n    partitions = {\n        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n        for obj in s3.list_objects_v2(\n            Bucket=\"vida\",\n            Prefix=\"google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n        ).get(\"Contents\", [])\n    }\n\n    parent_id = next(\n        str(cell.parent(level).id())\n        for level in range(10, 0, -1)\n        if str(cell.parent(level).id()) in partitions\n    )\n\n    # Setup DuckDB and query\n    con = duckdb.connect()\n    for cmd in [\n        \"INSTALL spatial\",\n        \"LOAD spatial\",\n        \"INSTALL httpfs\",\n        \"LOAD httpfs\",\n        \"SET s3_region='us-east-1'\",\n        \"SET s3_endpoint='data.source.coop'\",\n        \"SET s3_use_ssl=true\",\n        \"SET s3_url_style='path'\",\n    ]:\n        con.execute(cmd)\n\n    # Export and read back\n    query = f\"\"\"\n    COPY (SELECT * FROM 's3://vida/google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n          WHERE bbox.xmax &gt;= {bounds[0]} AND bbox.xmin &lt;= {bounds[2]} AND\n                bbox.ymax &gt;= {bounds[1]} AND bbox.ymin &lt;= {bounds[3]}\n    ) TO '{temp_file}' (FORMAT PARQUET);\n    \"\"\"\n\n    con.execute(query)\n    df = pd.read_parquet(temp_file)\n    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n\n    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=WGS84_CRS)\n\n\nif os.path.exists(BUILDINGS_PATH):\n    buildings = gpd.read_parquet(BUILDINGS_PATH)\nelse:\n    buildings = fetch_buildings(renabap_pba_intersect)\n\n\nbuildings_proj = buildings.to_crs(USE_CRS)\n\nbuildings_proj = buildings_proj.clip(la_plata)\n\n\n\nMostrar código\nfig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", common_bounds)\n\nrenabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(WEB_MERCATOR_CRS)\n\nrenabap_pba_intersect_3857.plot(\n    ax=ax1, facecolor=\"none\", edgecolor=\"black\", linewidth=0.5, legend=False, zorder=10\n)\n\nplt.tight_layout()\nplt.show()\n\npeligro_clipped = gpd.clip(peligro, la_plata)\n\npeligro_clipped_3857 = peligro_clipped.to_crs(WEB_MERCATOR_CRS)\n\n# Reorder the categories so they map correctly to plasma colormap\npeligro_clipped_3857[\"PELIGROSID_ordered\"] = pd.Categorical(\n    peligro_clipped_3857[\"PELIGROSID\"],\n    categories=[\"baja\", \"media\", \"alta\"],\n    ordered=True,\n)\n\n\nfig2, ax2 = create_consistent_map(\"Zonas de Peligro en La Plata\", common_bounds)\n\n\npeligro_clipped_3857.plot(\n    ax=ax2,\n    column=\"PELIGROSID_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    zorder=5,\n)\n\nplt.tight_layout()\nplt.show()\n\nfig3, ax3 = create_consistent_map(\"Datos de población GHSL\", common_bounds)\n\nghsl_masked = ma.masked_where(ghsl_clipped.values[0] == 0, ghsl_clipped.values[0])\n\nghsl_valid = (ghsl_clipped.values[0] != NODATA_VALUE) & (ghsl_clipped.values[0] != 0)\nghsl_valid_data = ghsl_clipped.values[0][ghsl_valid]\n\nplasma_cmap = PLASMA_CMAP\n\nghsl_clipped_3857 = ghsl_clipped.rio.reproject(WEB_MERCATOR_CRS)\n\n# Mask out zeros AND nodata values\nghsl_masked_3857 = ma.masked_where(\n    (ghsl_clipped_3857.values[0] == 0) | (ghsl_clipped_3857.values[0] == NODATA_VALUE),\n    ghsl_clipped_3857.values[0],\n)\n\nim = ax3.imshow(\n    ghsl_masked_3857,\n    extent=[\n        ghsl_clipped_3857.x.min(),\n        ghsl_clipped_3857.x.max(),\n        ghsl_clipped_3857.y.min(),\n        ghsl_clipped_3857.y.max(),\n    ],\n    cmap=plasma_cmap,\n    alpha=0.75,\n)\n\nplt.tight_layout()\nplt.show()\n\nfig4, ax4 = create_consistent_map(\"Huellas de edificios\", common_bounds)\n\nbuildings_3857 = buildings_proj.to_crs(WEB_MERCATOR_CRS)\n\nbuildings_3857.plot(ax=ax4, facecolor=\"grey\", edgecolor=\"none\", alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Asentamientos RENABAP en La Plata\n\n\n\n\n\n\n\n\n\n\n\n(b) Zonas de Peligro en La Plata\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Datos de población GHSL\n\n\n\n\n\n\n\n\n\n\n\n(d) Huellas de edificios\n\n\n\n\n\n\n\nFigure 3.1: Fuentes de datos para análisis de exposición",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#metodología-y-procesamiento",
    "href": "renabap.html#metodología-y-procesamiento",
    "title": "3  RENABAP",
    "section": "3.5 Metodología y procesamiento",
    "text": "3.5 Metodología y procesamiento\n\n3.5.1 Interpolación por area\nLa interpolación areal es un método simple en el que las variables de los datos fuente se ponderan según la superposición entre polígonos fuente y objetivo, luego se reagregan para ajustarse a las geometrías de los polígonos objetivo. En nuestro análisis, esto significa distribuir proporcionalmente la población de cada barrio popular según el área de intersección con diferentes niveles de peligro de inundación. El analasis original de la exposición poblacional a peligros de inundación en la región del Partido de La Plata se realizó utilizando este método.\n\n\nMostrar código\nif renabap_pba_intersect.crs != peligro.crs:\n    peligro = peligro.to_crs(renabap_pba_intersect.crs)\n\nhazard_levels = peligro[\"PELIGROSID\"].unique()\n\nrenabap_with_porciones = renabap_pba_intersect.copy()\nfor level in hazard_levels:\n    renabap_with_porciones[f\"porcion_{level}\"] = 0.0\n\nrenabap_with_porciones[\"total_area\"] = renabap_with_porciones.geometry.area\n\nfor idx, barrio in renabap_with_porciones.iterrows():\n    barrio_geom = barrio.geometry\n    barrio_total_area = barrio_geom.area\n\n    if barrio_total_area == 0:\n        continue\n\n    for level in hazard_levels:\n        hazard_subset = peligro[peligro[\"PELIGROSID\"] == level]\n\n        if hazard_subset.empty:\n            continue\n\n        intersection_area = 0\n        for _, hazard_row in hazard_subset.iterrows():\n            try:\n                intersection = barrio_geom.intersection(hazard_row.geometry)\n                if not intersection.is_empty:\n                    intersection_area += intersection.area\n            except Exception as e:\n                print(\n                    f\"Error calculating intersection for {barrio.get('nombre_barrio', idx)}: {e}\"\n                )\n                continue\n\n        proportion = (\n            intersection_area / barrio_total_area if barrio_total_area &gt; 0 else 0\n        )\n        renabap_with_porciones.at[idx, f\"porcion_{level}\"] = proportion\n\n# Create barrio tidy format using consolidated function\nbarrio_areal_rows = []\nfor idx, row in renabap_with_porciones.iterrows():\n    for level in hazard_levels:\n        familias_expuestas = row[f\"porcion_{level}\"] * row[\"familias_aproximadas\"]\n        if familias_expuestas &gt; 0:\n            barrio_areal_rows.append(\n                {\n                    \"id_renabap\": row[\"id_renabap\"],\n                    \"PELIGROSID\": level,\n                    \"fam_expuestas\": familias_expuestas,\n                }\n            )\n\nbarrio_areal_temp = pd.DataFrame(barrio_areal_rows)\nbarrio_areal_tidy = create_exposure_tidy_data(\n    data=barrio_areal_temp,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"areal\",\n    exposure_values=barrio_areal_temp[\"fam_expuestas\"],\n    exclude_zero=True,\n)\n\n# 2. CUENCA AREAL EXPOSURE - aggregate from barrio level, avoiding double counting\n# Get the cuenca for each settlement - but handle settlements that cross cuenca boundaries\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\n\n# Check if any settlements appear in multiple cuencas\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\n\nif len(multi_cuenca_settlements) &gt; 0:\n    # For settlements in multiple cuencas, assign to the cuenca with largest intersection\n    # For now, just take the first occurrence\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\ncuenca_areal_tidy = barrio_areal_tidy[\n    barrio_areal_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE\n].merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\ncuenca_areal_tidy = (\n    cuenca_areal_tidy.groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n# 3. EJE AREAL EXPOSURE - same fix\ncuenca_eje_mapping = settle_hazard_cuencas[[\"Cuenca\", \"eje\"]].drop_duplicates()\n\neje_areal_tidy = cuenca_areal_tidy.merge(cuenca_eje_mapping, on=\"Cuenca\")\neje_areal_tidy = (\n    eje_areal_tidy.groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n\n\n\n3.5.2 Mapeo dasymetrico\nEl mapeo dasimétrico reorganiza datos cartográficos de una unidad de recolección en áreas más precisas, modificando los límites originales usando datos de apoyo relacionados. Por ejemplo, un atributo de población organizado por tracto censal se vuelve más significativo cuando se eliminan áreas donde es razonable inferir que la gente no vive (cuerpos de agua, terrenos vacíos). En nuestro caso, utilizamos datos GHSL y huellas de edificios como información auxiliar para mejorar la precisión de las estimaciones de distribución poblacional.\n\n\nMostrar código\n### BUILDINGS\n\n# Get ALL buildings per settlement (not just hazard-intersected ones)\nbuildings_settlement = gpd.overlay(\n    buildings_proj, renabap_pba_intersect, how=\"intersection\"\n)\ntotal_buildings_per_settlement = (\n    buildings_settlement.groupby(\"id_renabap\")\n    .size()\n    .reset_index(name=\"total_buildings\")\n)\n\n# Get buildings intersected with hazard zones\nbuildings_hazard = gpd.overlay(\n    buildings_proj, settle_hazard_cuencas, how=\"intersection\"\n)\n\n# 1. Buildings per barrio-hazard (including non-hazard areas)\nbuildings_barrio_hazard = (\n    buildings_hazard.groupby([\"id_renabap\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\n\n# Calculate ratios using TOTAL buildings per settlement (not just hazard buildings)\nbarrio_ratios = buildings_barrio_hazard.merge(\n    total_buildings_per_settlement, on=\"id_renabap\"\n)\nbarrio_ratios[\"ratio\"] = (\n    barrio_ratios[\"buildings_count\"] / barrio_ratios[\"total_buildings\"]\n)\nbarrio_pop = renabap_pba_intersect[\n    [\"id_renabap\", \"familias_aproximadas\"]\n].drop_duplicates()\nbarrio_exposure = barrio_ratios.merge(barrio_pop, on=\"id_renabap\")\nbarrio_exposure[\"fam_expuestas\"] = (\n    barrio_exposure[\"ratio\"] * barrio_exposure[\"familias_aproximadas\"]\n)\n\n# Add non-hazard population for each settlement\nsettlements_with_hazards = barrio_exposure[\"id_renabap\"].unique()\nall_settlements = total_buildings_per_settlement[\"id_renabap\"].unique()\n\nfor settlement in all_settlements:\n    if settlement in settlements_with_hazards:\n        # Calculate non-hazard population\n        hazard_pop = barrio_exposure[barrio_exposure[\"id_renabap\"] == settlement][\n            \"fam_expuestas\"\n        ].sum()\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        non_hazard_pop = total_pop - hazard_pop\n\n        if non_hazard_pop &gt; 0:\n            barrio_exposure = pd.concat(\n                [\n                    barrio_exposure,\n                    pd.DataFrame(\n                        [\n                            {\n                                \"id_renabap\": settlement,\n                                \"PELIGROSID\": \"none\",\n                                \"buildings_count\": 0,\n                                \"total_buildings\": total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0],\n                                \"ratio\": (\n                                    total_buildings_per_settlement[\n                                        total_buildings_per_settlement[\"id_renabap\"]\n                                        == settlement\n                                    ][\"total_buildings\"].iloc[0]\n                                    - buildings_hazard[\n                                        buildings_hazard[\"id_renabap\"] == settlement\n                                    ].shape[0]\n                                )\n                                / total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                if total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                &gt; 0\n                                else 0,\n                                \"familias_aproximadas\": total_pop,\n                                \"fam_expuestas\": non_hazard_pop,\n                            }\n                        ]\n                    ),\n                ],\n                ignore_index=True,\n            )\n    else:\n        # Settlement with no hazard intersection - all population is non-hazard\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        barrio_exposure = pd.concat(\n            [\n                barrio_exposure,\n                pd.DataFrame(\n                    [\n                        {\n                            \"id_renabap\": settlement,\n                            \"PELIGROSID\": \"none\",\n                            \"buildings_count\": 0,\n                            \"total_buildings\": total_buildings_per_settlement[\n                                total_buildings_per_settlement[\"id_renabap\"]\n                                == settlement\n                            ][\"total_buildings\"].iloc[0],\n                            \"ratio\": 1.0,\n                            \"familias_aproximadas\": total_pop,\n                            \"fam_expuestas\": total_pop,\n                        }\n                    ]\n                ),\n            ],\n            ignore_index=True,\n        )\n\n# Create buildings tidy dataframe for barrio level using consolidated function\nbuildings_barrio_tidy = create_exposure_tidy_data(\n    data=barrio_exposure,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\",\n    exposure_values=barrio_exposure[\"fam_expuestas\"],\n    exclude_zero=False,  # Keep all values including zeros for completeness\n)\n\n# 2. Cuenca exposure - using total buildings across all settlements in cuenca\nbuildings_cuenca_hazard = (\n    buildings_hazard.groupby([\"Cuenca\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_cuenca_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"Cuenca\"]].drop_duplicates(),\n        on=\"id_renabap\",\n    )\n    .groupby(\"Cuenca\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\ncuenca_ratios = buildings_cuenca_hazard.merge(buildings_cuenca_total, on=\"Cuenca\")\ncuenca_ratios[\"ratio\"] = (\n    cuenca_ratios[\"buildings_count\"] / cuenca_ratios[\"total_buildings_all\"]\n)\n\ncuenca_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"Cuenca\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\ncuenca_exposure = cuenca_ratios.merge(cuenca_pop, on=\"Cuenca\")\ncuenca_exposure[\"fam_expuestas\"] = (\n    cuenca_exposure[\"ratio\"] * cuenca_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for cuenca level using consolidated function\nbuildings_cuenca_tidy = create_exposure_tidy_data(\n    data=cuenca_exposure,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\",\n    exposure_values=cuenca_exposure[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n# 3. Eje exposure - using total buildings across all settlements in eje\nbuildings_eje_hazard = (\n    buildings_hazard.groupby([\"eje\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_eje_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates(), on=\"id_renabap\"\n    )\n    .groupby(\"eje\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\neje_ratios = buildings_eje_hazard.merge(buildings_eje_total, on=\"eje\")\neje_ratios[\"ratio\"] = eje_ratios[\"buildings_count\"] / eje_ratios[\"total_buildings_all\"]\n\neje_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"eje\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\neje_exposure = eje_ratios.merge(eje_pop, on=\"eje\")\neje_exposure[\"fam_expuestas\"] = (\n    eje_exposure[\"ratio\"] * eje_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for eje level using consolidated function\nbuildings_eje_tidy = create_exposure_tidy_data(\n    data=eje_exposure,\n    id_column=\"eje\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"buildings\",\n    exposure_values=eje_exposure[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n\n### GHSL \n\n# Convert to the format expected by rasterstats\ngeometries = [geom for geom in renabap_pba_intersect.geometry]\n\n# Use rasterstats for vectorized zonal statistics\nstats = rasterstats.zonal_stats(\n    geometries,\n    ghsl_clipped.values[0],  # rasterstats expects 2D array\n    affine=ghsl_clipped.rio.transform(),\n    stats=[\"sum\"],\n    nodata=ghsl_clipped.rio.nodata,\n)\n\n# Extract the sum values\nghsl_totals = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n\n# Add the GHSL population estimates as a new column\nrenabap_pba_intersect[\"ghsl_pop_est\"] = ghsl_totals\n\n\n# Get the reference raster properties from GHSL data\nreference_raster = ghsl_clipped\nreference_transform = reference_raster.rio.transform()\nreference_crs = reference_raster.rio.crs\nreference_shape = reference_raster.shape[1:]  # Get 2D shape (height, width)\n\n\n# Prepare geometries and values for rasterization\ngeometries_ghsl = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"ghsl_pop_est\"]\n    )\n]\ngeometries_familias = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"familias_aproximadas\"]\n    )\n]\n\n# Create GHSL population raster\nghsl_pop_raster = rasterize(\n    geometries_ghsl,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Create familias aproximadas raster\nfamilias_raster = rasterize(\n    geometries_familias,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n\n# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n# Use masking to avoid division on invalid cells\nmask = (ghsl_clipped.values[0] != NODATA_VALUE) & (ghsl_pop_raster &gt; 0.1)\nghsl_fractional = np.full_like(ghsl_clipped.values[0], NODATA_VALUE, dtype=np.float64)\nghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n\n# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\nmask2 = (ghsl_fractional != NODATA_VALUE) & (familias_raster &gt; 0)\nfamilias_downscaled = np.full_like(\n    ghsl_clipped.values[0], NODATA_VALUE, dtype=np.float64\n)\nfamilias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n\n# Verify the results - exclude NODATA_VALUE from range calculations\nghsl_valid = ghsl_clipped.values[0] != NODATA_VALUE\nfractional_valid = ghsl_fractional != NODATA_VALUE\ndownscaled_valid = familias_downscaled != NODATA_VALUE\n\n# GHSL downscaling for all three levels using the same approach\n\n# 1. BARRIO-HAZARD EXPOSURE using consolidated approach\nghsl_barrio_exposure = []\nfor idx, row in settlement_hazard.iterrows():\n    stats = zonal_stats(\n        [row.geometry],\n        familias_downscaled,\n        affine=reference_transform,\n        stats=[\"sum\"],\n        nodata=NODATA_VALUE,\n    )[0]\n\n    ghsl_barrio_exposure.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"PELIGROSID\": row[\"PELIGROSID\"],\n            \"fam_expuestas\": stats[\"sum\"] if stats[\"sum\"] is not None else 0,\n        }\n    )\n\nghsl_barrio_temp = pd.DataFrame(ghsl_barrio_exposure)\nghsl_barrio_tidy = create_exposure_tidy_data(\n    data=ghsl_barrio_temp,\n    id_column=\"id_renabap\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_barrio_temp[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n# 2. CUENCA-HAZARD EXPOSURE using consolidated approach\nghsl_cuenca_exposure = []\nfor cuenca in settle_hazard_cuencas[\"Cuenca\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this cuenca-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"Cuenca\"] == cuenca)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=NODATA_VALUE,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_cuenca_exposure.append(\n                {\n                    \"Cuenca\": cuenca,\n                    \"PELIGROSID\": peligro,\n                    \"fam_expuestas\": total_pop,\n                }\n            )\n\nghsl_cuenca_temp = pd.DataFrame(ghsl_cuenca_exposure)\nghsl_cuenca_tidy = create_exposure_tidy_data(\n    data=ghsl_cuenca_temp,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_cuenca_temp[\"fam_expuestas\"],\n    exclude_zero=False,\n)\n\n# 3. EJE-HAZARD EXPOSURE using consolidated approach\nghsl_eje_exposure = []\nfor eje in settle_hazard_cuencas[\"eje\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this eje-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"eje\"] == eje)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=NODATA_VALUE,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_eje_exposure.append(\n                {\n                    \"eje\": eje,\n                    \"PELIGROSID\": peligro,\n                    \"fam_expuestas\": total_pop,\n                }\n            )\n\nghsl_eje_temp = pd.DataFrame(ghsl_eje_exposure)\nghsl_eje_tidy = create_exposure_tidy_data(\n    data=ghsl_eje_temp,\n    id_column=\"eje\",\n    peligrosidad_column=\"PELIGROSID\",\n    method_suffix=\"ghsl\",\n    exposure_values=ghsl_eje_temp[\"fam_expuestas\"],\n    exclude_zero=False,\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#resultados",
    "href": "renabap.html#resultados",
    "title": "3  RENABAP",
    "section": "3.6 Resultados",
    "text": "3.6 Resultados\n\n3.6.1 Comparación de métodos\n\nMostrar código\n# 1. BARRIO-LEVEL WIDE DATAFRAME using consolidated function\nrenabap_info = renabap_pba_intersect[[\"id_renabap\", \"nombre_barrio\"]].drop_duplicates()\n\nbarrio_wide = create_wide_exposure_dataframe(\n    areal_data=barrio_areal_tidy,\n    ghsl_data=ghsl_barrio_tidy,\n    buildings_data=buildings_barrio_tidy,\n    id_columns=[\"id_renabap\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE,\n)\n\n# Add barrio names and reorder columns\nbarrio_wide = barrio_wide.merge(renabap_info, on=\"id_renabap\", how=\"left\")\nbarrio_wide = barrio_wide[\n    [\n        \"id_renabap\",\n        \"nombre_barrio\",\n        \"peligrosidad\",\n    ]\n    + EXPOSURE_COLUMNS\n]\n\n# 2. CUENCA-LEVEL WIDE DATAFRAME using consolidated function\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\nif len(multi_cuenca_settlements) &gt; 0:\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\n# Aggregate buildings data from barrio to cuenca level\ncuenca_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE]\n    .merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\n\n# Convert to tidy format for the consolidated function\ncuenca_buildings_tidy_for_merge = create_exposure_tidy_data(\n    data=cuenca_buildings_wide,\n    id_column=\"Cuenca\",\n    peligrosidad_column=\"peligrosidad\",\n    method_suffix=\"buildings\",\n    exposure_values=cuenca_buildings_wide[\"fam_expuestas_buildings\"],\n    exclude_zero=False,\n)\n\ncuenca_wide = create_wide_exposure_dataframe(\n    areal_data=cuenca_areal_tidy,\n    ghsl_data=ghsl_cuenca_tidy,\n    buildings_data=cuenca_buildings_tidy_for_merge,\n    id_columns=[\"Cuenca\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE,\n)\n\ncuenca_wide[\"cuenca\"] = cuenca_wide[\"Cuenca\"].str.lower()\ncuenca_wide = cuenca_wide[\n    [\n        \"cuenca\",\n        \"peligrosidad\",\n    ]\n    + EXPOSURE_COLUMNS\n]\n\n# 3. EJE-LEVEL WIDE DATAFRAME using consolidated function\nsettlement_eje_mapping = settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates()\neje_settlement_counts = settlement_eje_mapping[\"id_renabap\"].value_counts()\nmulti_eje_settlements = eje_settlement_counts[eje_settlement_counts &gt; 1].index\nif len(multi_eje_settlements) &gt; 0:\n    settlement_eje_mapping = settlement_eje_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\n# Aggregate buildings data from barrio to eje level\neje_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != NON_HAZARD_VALUE]\n    .merge(settlement_eje_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\n\n# Convert to tidy format for the consolidated function\neje_buildings_tidy_for_merge = create_exposure_tidy_data(\n    data=eje_buildings_wide,\n    id_column=\"eje\",\n    peligrosidad_column=\"peligrosidad\",\n    method_suffix=\"buildings\",\n    exposure_values=eje_buildings_wide[\"fam_expuestas_buildings\"],\n    exclude_zero=False,\n)\n\neje_wide = create_wide_exposure_dataframe(\n    areal_data=eje_areal_tidy,\n    ghsl_data=ghsl_eje_tidy,\n    buildings_data=eje_buildings_tidy_for_merge,\n    id_columns=[\"eje\", \"peligrosidad\"],\n    exclude_hazard_value=NON_HAZARD_VALUE,\n)\n\neje_wide = eje_wide[\n    [\n        \"eje\",\n        \"peligrosidad\",\n    ]\n    + EXPOSURE_COLUMNS\n]\n\nbarrio_tidy = pd.melt(\n    barrio_wide,\n    id_vars=[\"id_renabap\", \"nombre_barrio\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\nbarrio_tidy[\"metodo\"] = barrio_tidy[\"metodo\"].str.replace(\n    COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\"\n)\n\nbarrio_tidy = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"geometry\"]], on=\"id_renabap\", how=\"left\"\n)\n\nbarrio_tidy[\"area\"] = barrio_tidy.geometry.apply(lambda geom: geom.area)\n\n\n# Group by id_renabap and peligro, then find which method has the highest fam_expuestas\nhighest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmax()\n\n# Get the method names for the highest estimates\nmethod_counts = barrio_tidy.loc[highest_methods, \"metodo\"].value_counts()\n\nplt.figure(figsize=(12, 7))\nsns.barplot(x=method_counts.index, y=method_counts.values, hue=method_counts.index, palette=\"viridis\", legend=False)\nplt.title(\n    \"Métodos que Más Frecuentemente Devuelven la Mayor Estimación de Familias Expuestas\",\n    fontsize=14,\n    fontweight=\"bold\",\n    pad=20,\n)\nplt.xlabel(\"Método\", fontsize=12, fontweight=\"bold\")\nplt.ylabel(\"Frecuencia\", fontsize=12, fontweight=\"bold\")\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.tight_layout()\nplt.show()\n\n\n# Group by id_renabap and peligro, then find which method has the lowest fam_expuestas\nlowest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmin()\n\n# Get the method names for the lowest estimates\nlowest_method_counts = barrio_tidy.loc[lowest_methods, \"metodo\"].value_counts()\n\n# Crear gráfico de barras para métodos con menor estimación\nplt.figure(figsize=(12, 7))\nsns.barplot(\n    x=lowest_method_counts.index, y=lowest_method_counts.values, hue=lowest_method_counts.index, palette=\"viridis\", legend=False\n)\nplt.title(\n    \"Métodos que Más Frecuentemente Devuelven la Menor Estimación de Familias Expuestas\",\n    fontsize=14,\n    fontweight=\"bold\",\n    pad=20,\n)\nplt.xlabel(\"Método\", fontsize=12, fontweight=\"bold\")\nplt.ylabel(\"Frecuencia\", fontsize=12, fontweight=\"bold\")\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.tight_layout()\nplt.show()\n\n\n# First, left join familias_aproximadas from renabap_pba_intersect\nfinal_tidy_with_pop = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"familias_aproximadas\"]],\n    on=\"id_renabap\",\n    how=\"left\",\n)\n\n# Calculate the range (highest - lowest) per id_renabap and peligro\nrange_by_barrio = final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].agg([\"max\", \"min\"])\nrange_by_barrio[\"range\"] = range_by_barrio[\"max\"] - range_by_barrio[\"min\"]\n\n# Merge back to get the total population for each barrio\nrange_by_barrio = range_by_barrio.reset_index().merge(\n    final_tidy_with_pop[[\"id_renabap\", \"familias_aproximadas\"]].drop_duplicates(),\n    on=\"id_renabap\",\n)\n\n# Calculate absolute percent difference as fraction of total barrio population\nrange_by_barrio[\"abs_pct_diff\"] = (\n    range_by_barrio[\"range\"] / range_by_barrio[\"familias_aproximadas\"]\n) * 100\n\n# Calculate average absolute percent difference per peligro level\navg_pct_diff_by_peligro = range_by_barrio.groupby(\"peligrosidad\")[\"abs_pct_diff\"].mean()\n\n# Calculate absolute percent difference by method\nmethod_errors = final_tidy_with_pop.copy()\n\n\n# Calculate absolute error as percent of total population for each method\nmethod_errors[\"abs_error_pct\"] = (\n    abs(\n        method_errors[\"fam_expuestas\"]\n        - method_errors.groupby([\"id_renabap\", \"peligrosidad\"])[\n            \"fam_expuestas\"\n        ].transform(\"mean\")\n    )\n    / method_errors[\"familias_aproximadas\"]\n    * 100\n)\n\n# Calculate coefficient of variation for each barrio-peligro combination\nbarrio_reliability = (\n    final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"])\n    .agg({\"fam_expuestas\": [\"mean\", \"std\"], \"familias_aproximadas\": \"first\"})\n    .reset_index()\n)\n\nbarrio_reliability.columns = [\n    \"id_renabap\",\n    \"peligrosidad\",\n    \"mean_estimate\",\n    \"std_estimate\",\n    \"familias_aproximadas\",\n]\nbarrio_reliability[\"coefficient_variation\"] = (\n    barrio_reliability[\"std_estimate\"] / barrio_reliability[\"mean_estimate\"]\n)\n\n# Create box plot\nplt.figure(figsize=(12, 3))\nsns.boxplot(\n    data=barrio_reliability,\n    y=\"peligrosidad\",\n    x=\"coefficient_variation\",\n    hue=\"peligrosidad\",\n    palette=\"viridis\",\n    legend=False,\n    width=0.4,\n)\nplt.title(\n    \"Variabilidad de Estimaciones entre Métodos\", fontsize=16, fontweight=\"bold\", pad=20\n)\nplt.ylabel(\"Peligrosidad\", fontsize=14, fontweight=\"bold\")\nplt.xlabel(\n    \"Coeficiente de Variación (0 = estimaciones idénticas, 1 = muy variables)\",\n    fontsize=12,\n    fontweight=\"bold\",\n)\nplt.tight_layout()\nplt.show()\n\n\n# Create scatter plot colored by peligrosidad\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio[range_by_barrio[\"peligrosidad\"] == peligro]\n\n    plt.scatter(\n        peligro_data[\"familias_aproximadas\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Familias Aproximadas (Total Barrio Population)\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Barrio Size (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# First, get the area data from final_tidy\narea_data = barrio_tidy[[\"id_renabap\", \"area\"]].drop_duplicates()\n\n# Merge area back into range_by_barrio\nrange_by_barrio_with_area = range_by_barrio.merge(\n    area_data, on=\"id_renabap\", how=\"left\"\n)\n\n\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio_with_area[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio_with_area[\n        range_by_barrio_with_area[\"peligrosidad\"] == peligro\n    ]\n\n    plt.scatter(\n        peligro_data[\"area\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Area\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Area (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n# Filter for high exposure (alta peligrosidad) using the joined dataframe\nalta_data = barrio_tidy[barrio_tidy[\"peligrosidad\"] == \"alta\"].copy()\n\n# Aggregate by nombre_barrio and sum fam_expuestas for each method\n# This handles cases where there are multiple geometries with the same barrio name\nalta_aggregated = (\n    alta_data.groupby([\"nombre_barrio\", \"metodo\"])[\"fam_expuestas\"].sum().reset_index()\n)\n\n# Remove cases where the barrio name is \"Sin Nombre\"\nalta_aggregated = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"] != \"Sin Nombre\"\n].copy()\n\n# Calculate total exposure per barrio across all methods\ntotal_exposure = (\n    alta_aggregated.groupby(\"nombre_barrio\")[\"fam_expuestas\"]\n    .sum()\n    .sort_values(ascending=False)\n)\ntop_10_barrios = total_exposure.head(10).index\n\n# Filter aggregated data for top 10 barrios\ntop_10_data = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"].isin(top_10_barrios)\n].copy()\n\n# Create range plot showing min, max, and individual points\nplt.figure(figsize=(14, 10))  # Increased height to accommodate longer barrio names\n\n\nfor i, barrio in enumerate(top_10_barrios):\n    barrio_data = top_10_data[top_10_data[\"nombre_barrio\"] == barrio]\n    if len(barrio_data) &gt; 0:\n        values = barrio_data[\"fam_expuestas\"].values\n        min_val = values.min()\n        max_val = values.max()\n\n        # Plot range line\n        plt.plot([min_val, max_val], [i, i], \"k-\", alpha=0.5, linewidth=2)\n\n        # Plot individual points colored by method\n        for _, row in barrio_data.iterrows():\n            color = METHOD_COLORS[row[\"metodo\"]]\n            plt.plot(row[\"fam_expuestas\"], i, \"o\", color=color, markersize=6, alpha=0.8)\n\nplt.yticks(range(len(top_10_barrios)), top_10_barrios)\nplt.xlabel(\"Familias Expuestas\")\nplt.ylabel(\"Barrio\")\nplt.title(\"Range of High Exposure Estimates for Top 10 Barrios\", fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# Add legend\nlegend_elements = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=color,\n        markersize=8,\n        label=method,\n    )\n    for method, color in METHOD_COLORS.items()\n]\nplt.legend(handles=legend_elements, title=\"Método\")\n\nplt.tight_layout()\nplt.show()\n\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_areal\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_exp_areal\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_exp_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_exp_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Discrepancia vs población total del barrio\n\n\n\n\n\n\n\n\n\n\n\n(b) Discrepancia vs área del barrio\n\n\n\n\n\n\n\n\n\n\n\n(c) Rango de estimaciones para barrios con mayor exposición\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n\n\n\n\n(f)\n\n\n\n\n\n\n\nFigure 3.2: Análisis comparativo de métodos de estimación por barrio\n\n\n\n\n\nMostrar código\ndef plot_method_map(\n    method_name,\n    final_tidy,\n    la_plata,\n    PELIGROSIDAD_COLORS,\n    common_bounds,\n    create_consistent_map,\n):\n    fig, ax = create_consistent_map(\n        f\"Barrios por población expuesta estimada - {method_name.capitalize()}\",\n        common_bounds,\n    )\n\n    method_data = final_tidy[\n        (final_tidy[\"metodo\"] == method_name)\n        & (final_tidy[\"peligrosidad\"].isin([\"alta\", \"media\"]))\n    ].copy()\n\n    method_gdf = gpd.GeoDataFrame(method_data, geometry=\"geometry\", crs=USE_CRS)\n    method_gdf = method_gdf.clip(la_plata)\n    method_gdf_3857 = method_gdf.to_crs(WEB_MERCATOR_CRS)\n\n    plotting_order = [\"media\", \"alta\"]\n\n    np.random.seed(42)\n    for peligrosidad in plotting_order:\n        level_data = method_gdf_3857[method_gdf_3857[\"peligrosidad\"] == peligrosidad]\n        for _, row in level_data.iterrows():\n            centroid = row[\"geometry\"].centroid\n            jitter_x = np.random.uniform(-200, 200)\n            jitter_y = np.random.uniform(-200, 200)\n            x_pos = centroid.x + jitter_x\n            y_pos = centroid.y + jitter_y\n            color = PELIGROSIDAD_COLORS[row[\"peligrosidad\"]]\n            size = max(10, row[\"fam_expuestas\"] * 2 + 15)\n            ax.scatter(\n                x_pos,\n                y_pos,\n                s=size,\n                color=color,\n                alpha=0.9,\n                edgecolors=\"white\",\n                linewidth=1.0,\n            )\n\n    legend_elements = [\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"o\",\n            color=\"w\",\n            markerfacecolor=color,\n            markersize=8,\n            label=level.capitalize(),\n        )\n        for level, color in PELIGROSIDAD_COLORS.items()\n    ]\n    ax.legend(handles=legend_elements, title=\"Nivel de Peligrosidad\", loc=\"upper right\")\n    plt.tight_layout()\n    plt.show()\n\n\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_areal\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_exp_areal\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_exp_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"fam_exp_edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_exp_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n\n\n3.6.2 Exposición por barrio\n\nMostrar código\nmethods = barrio_tidy[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        barrio_tidy,\n        la_plata,\n        PELIGROSIDAD_COLORS,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.3: Comparación de métodos de estimación de exposición por barrio\n\n\n\n\n\nMostrar código\nshow(round_numeric_columns(barrio_summary))\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.3 Exposición por cuenca\n\nMostrar código\ncuencas_centroids = cuencas.copy()\ncuencas_centroids[\"geometry\"] = cuencas_centroids[\"geometry\"].centroid\n\n# Create a lowercase version of Cuenca for matching\ncuencas_centroids[\"cuenca_lower\"] = cuencas_centroids[\"Cuenca\"].str.lower()\n\ncuenca_tidy = pd.melt(\n    cuenca_wide,\n    id_vars=[\"cuenca\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\ncuenca_tidy[\"metodo\"] = cuenca_tidy[\"metodo\"].str.replace(\n    COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\"\n)\n\ncuenca_tidy_with_geometry = cuenca_tidy.merge(\n    cuencas_centroids[[\"cuenca_lower\", \"geometry\"]],\n    left_on=\"cuenca\",\n    right_on=\"cuenca_lower\",\n    how=\"left\",\n)\n\ncuenca_tidy_gdf = gpd.GeoDataFrame(\n    cuenca_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = cuenca_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        cuenca_tidy_gdf,\n        la_plata,\n        PELIGROSIDAD_COLORS,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.4: Comparación de métodos de estimación de exposición por cuenca\n\n\n\n\n\nMostrar código\nshow(round_numeric_columns(cuenca_wide))\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.4 Exposición por eje\n\nMostrar código\neje_tidy = pd.melt(\n    eje_wide,\n    id_vars=[\"eje\", \"peligrosidad\"],\n    value_vars=EXPOSURE_COLUMNS,\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\neje_tidy[\"metodo\"] = eje_tidy[\"metodo\"].str.replace(\n    COLUMN_MAPPINGS[\"method_cleanup_prefix\"], \"\"\n)\n\n# Create eje geodataframe by dissolving cuencas by eje and then taking centroids\nejes = cuencas.dissolve(by=\"eje\").reset_index()\nejes_centroids = ejes.copy()\nejes_centroids[\"geometry\"] = ejes_centroids[\"geometry\"].centroid\n\neje_tidy_with_geometry = eje_tidy.merge(\n    ejes_centroids[[\"eje\", \"geometry\"]], on=\"eje\", how=\"left\"\n)\n\neje_tidy_gdf = gpd.GeoDataFrame(\n    eje_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = eje_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        eje_tidy_gdf,\n        la_plata,\n        PELIGROSIDAD_COLORS,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.5: Comparación de métodos de estimación de exposición por eje de cuenca\n\n\n\n\n\nMostrar código\nshow(round_numeric_columns(eje_wide))\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#conclusiones",
    "href": "renabap.html#conclusiones",
    "title": "3  RENABAP",
    "section": "3.7 Conclusiones",
    "text": "3.7 Conclusiones\n\n\n\n\nRomanazzi, Pablo et al. 2019. Plan de Reducción Del Riesgo Por Inundaciones En La Región de La Plata. Edited by Sebastián Guerrini, Pablo Morosi, Eduardo Pablo Spinelli, and Josefina López MacKenzie. 1st ed. La Plata: Universidad Nacional de La Plata. Facultad de Ingeniería; Municipalidad de La Plata. https://sedici.unlp.edu.ar/bitstream/handle/10915/165109/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y.\n\n\nSchiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023. “GHS-POP R2023A - GHS Population Grid Multitemporal (1975-2030).” European Commission, Joint Research Centre (JRC). https://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of Flood Exposure in Developing Countries Using High-Resolution Population Data.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite Imaging Reveals Increased Proportion of Population Exposed to Floods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by VIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Romanazzi, Pablo et al. 2019. Plan de Reducción Del Riesgo Por\nInundaciones En La Región de La Plata. Edited by Sebastián\nGuerrini, Pablo Morosi, Eduardo Pablo Spinelli, and Josefina López\nMacKenzie. 1st ed. La Plata: Universidad Nacional de La Plata. Facultad\nde Ingeniería; Municipalidad de La Plata. https://sedici.unlp.edu.ar/bitstream/handle/10915/165109/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y.\n\n\nSchiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023.\n“GHS-POP R2023A - GHS Population Grid Multitemporal\n(1975-2030).” European Commission, Joint Research Centre (JRC).\nhttps://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of\nFlood Exposure in Developing Countries Using High-Resolution Population\nData.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite\nImaging Reveals Increased Proportion of Population Exposed to\nFloods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by\nVIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "twi.html",
    "href": "twi.html",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "",
    "text": "4.1 Resumen\nEste documento desarrolla un índice de humedad topográfica para el Partido de La Plata empleando datos de elevación FABDEM de acceso libre y las bibliotecas pysheds y xDEM mediante metodologías consolidadas. Los resultados se contrastan con modelado hidrológico de la Facultad de Ingeniería, evidenciando que el TWI representa una alternativa viable para contextos con limitaciones de datos donde no existe modelado hidrológico avanzado disponible, especialmente considerando que el proceso completo requiere únicamente unos minutos y no tiene costo asociado. Este enfoque, respaldado científicamente pero con limitaciones reconocidas, constituye una solución práctica para evaluaciones preliminares de riesgo de inundación a escala municipal cuando se carece de información más detallada.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#introducción",
    "href": "twi.html#introducción",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "4.2 Introducción",
    "text": "4.2 Introducción\n\n4.2.1 ¿Qué es el TWI?\nEl TWI es un índice establecido que combina la pendiente del terreno con el área de drenaje aguas arriba para identificar zonas propensas a la acumulación de agua e inundaciones. Calcula valores distribuidos espacialmente donde números más altos indican mayor potencial de encharcamiento y valores más bajos sugieren condiciones más secas. Es una herramienta ampliamente reconocida en hidrología para modelar condiciones de humedad del paisaje (Atlas 2025).\n\n\n4.2.2 ¿Por qué usarlo?\nEl TWI es un método establecido que ha sido utilizado por agencias como el Illinois State Water Survey para identificar áreas urbanas con riesgo de inundación, demostrando su validez científica y aplicación práctica. La principal ventaja del TWI es que proporciona información valiosa sobre riesgo de inundaciones a un costo extremadamente bajo comparado con estudios hidrológicos detallados. Es gratuito, rápido de calcular usando datos topográficos que suelen estar disponibles, y fácil de interpretar, lo que lo convierte en una excelente herramienta de planificación inicial (Ballerine 2017).\n\n\n4.2.3 Limitaciones\nEs fundamental entender que el TWI es una medida derivada puramente del terreno y no considera factores como infraestructura urbana, sistemas de drenaje, vegetación, o patrones climáticos locales. Por tanto, es una herramienta muy general que solo proporciona una noción del riesgo relativo de inundación. No debe utilizarse para tomar decisiones a nivel de parcela específica, ni puede estimar la profundidad de agua de inundación, que es crucial para el manejo detallado de aguas pluviales. El índice se correlaciona principalmente con flujo superficial y no puede capturar interacciones complejas con aguas subterráneas.\n\n\n4.2.4 Uso apropiado\nLas investigaciones han confirmado que existe correlación entre valores altos de TWI y reportes ciudadanos de inundaciones urbanas menores, validando su utilidad en contextos urbanizados (Kelleher and McPhillips 2020). El TWI es especialmente valioso para gobiernos municipales con recursos limitados como primera aproximación para identificar áreas de riesgo relativo de inundaciones, desarrollar planes de emergencia y priorizar estudios más detallados en zonas críticas. Proporciona un punto de partida sólido y científicamente respaldado para la gestión del riesgo de inundaciones sin requerir inversión significativa en estudios especializados.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#herramientasd",
    "href": "twi.html#herramientasd",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "4.3 Herramientasd",
    "text": "4.3 Herramientasd\n\n4.3.1 PySHEDS\n“Pysheds es una biblioteca de Python de código abierto diseñada por Matt Bartos para ayudar con el procesamiento de modelos digitales de elevación (DEMs), particularmente para análisis hidrológico. Pysheds realiza muchas de las funciones hidrológicas básicas ofrecidas por software comercial como ArcGIS, incluyendo delineación de cuencas y cálculo de acumulación.” Aquí, utilizamos PySheds para calcular la acumulación de flujo, que se incorpora en nuestro cálculo del TWI.\n\n\n4.3.2 xDEM\nxDEM “fue creado por un grupo de investigadores con experiencia en análisis de datos de elevación para detección de cambios aplicado a glaciología. Hoy en día, su desarrollo es liderado conjuntamente por investigadores en análisis de datos de elevación (incluyendo financiamiento de NASA y SNSF) e ingenieros de CNES (Agencia Espacial Francesa).” Utilizamos xDEM para todo nuestro procesamiento y cálculos de modelos digitales de elevación más allá de la acumulación de flujo.\n\n\n4.3.3 FABDEM 30m\nFathom, líder de la industria en modelado global de inundaciones, creó FABDEM específicamente para el desarrollo de sus modelos. A diferencia de otros modelos que conservan la altura de construcciones y vegetación, este utiliza técnicas de inteligencia artificial para eliminar dichas interferencias y mostrar únicamente la topografía del suelo (Hawker et al. 2022). Su desarrollo involucró datos de referencia de alta precisión provenientes de doce países con características climáticas y urbanas diversas, lo que garantiza su aplicabilidad en distintos contextos geográficos. Los datos están disponibles para descarga en este enlace. Para nuestros propósitos, FABDEM resulta especialmente valioso dado que las investigaciones han demostrado que la calidad del modelo de elevación constituye el factor más influyente en la precisión del modelado de riesgo de inundaciones. Al eliminar las distorsiones causadas por elementos como edificaciones y árboles, este modelo nos permite obtener cálculos de TWI más precisos y representativos de las condiciones reales del terreno, aspecto crucial para la planificación municipal del riesgo de inundaciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#comparativa-de-modelación-flo-2d-y",
    "href": "twi.html#comparativa-de-modelación-flo-2d-y",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "4.4 Comparativa de modelación FLO-2D y",
    "text": "4.4 Comparativa de modelación FLO-2D y\n\n\n\n\nAtlas. 2025. “Topographic Wetness Index—GIS Use Cases.” https://atlas.co/gis-use-cases/topographic-wetness-index/.\n\n\nBallerine, C. 2017. “Topographic Wetness Index Urban Flooding Awareness Act Action Support.” Technical report; University of Illinois at Urbana-Champaign, Prairie Research Institute.\n\n\nHawker, L., P. Uhe, L. Paulo, J. Sosa, J. Savage, C. Sampson, and J. Neal. 2022. “A 30 m Global Map of Elevation with Forests and Buildings Removed.” Environmental Research Letters 17 (2): 024016. https://doi.org/10.1088/1748-9326/ac4d4f.\n\n\nKelleher, C., and L. McPhillips. 2020. “Exploring the Application of Topographic Indices in Urban Areas as Indicators of Pluvial Flooding Locations.” Hydrological Processes 34 (3): 780–94. https://doi.org/10.1002/hyp.13628.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#footnotes",
    "href": "twi.html#footnotes",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "",
    "text": "Ver Ballerine (n.d.) para más detalles sobre aplicaciones del TWI en contextos urbanos.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#herramientas",
    "href": "twi.html#herramientas",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "4.3 Herramientas",
    "text": "4.3 Herramientas\n\n4.3.1 PySHEDS\n“Pysheds es una biblioteca de Python de código abierto diseñada por Matt Bartos para ayudar con el procesamiento de modelos digitales de elevación (DEMs), particularmente para análisis hidrológico. Pysheds realiza muchas de las funciones hidrológicas básicas ofrecidas por software comercial como ArcGIS, incluyendo delineación de cuencas y cálculo de acumulación.” Aquí, utilizamos PySheds para calcular la acumulación de flujo, que se incorpora en nuestro cálculo del TWI.\n\n\n4.3.2 xDEM\nxDEM “fue creado por un grupo de investigadores con experiencia en análisis de datos de elevación para detección de cambios aplicado a glaciología. Hoy en día, su desarrollo es liderado conjuntamente por investigadores en análisis de datos de elevación (incluyendo financiamiento de NASA y SNSF) e ingenieros de CNES (Agencia Espacial Francesa).” Utilizamos xDEM para todo nuestro procesamiento y cálculos de modelos digitales de elevación más allá de la acumulación de flujo.\n\n\n4.3.3 FABDEM 30m\nFathom, líder de la industria en modelado global de inundaciones, creó FABDEM específicamente para el desarrollo de sus modelos. A diferencia de otros modelos que conservan la altura de construcciones y vegetación, este utiliza técnicas de inteligencia artificial para eliminar dichas interferencias y mostrar únicamente la topografía del suelo (Hawker et al. 2022). Su desarrollo involucró datos de referencia de alta precisión provenientes de doce países con características climáticas y urbanas diversas, lo que garantiza su aplicabilidad en distintos contextos geográficos. Los datos están disponibles para descarga en este enlace. Para nuestros propósitos, FABDEM resulta especialmente valioso dado que las investigaciones han demostrado que la calidad del modelo de elevación constituye el factor más influyente en la precisión del modelado de riesgo de inundaciones. Al eliminar las distorsiones causadas por elementos como edificaciones y árboles, este modelo nos permite obtener cálculos de TWI más precisos y representativos de las condiciones reales del terreno, aspecto crucial para la planificación municipal del riesgo de inundaciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#análisis",
    "href": "twi.html#análisis",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "4.4 Análisis",
    "text": "4.4 Análisis\n\n4.4.1 Importar datos\nEn esta sección importamos los datos de elevación FABDEM. Hemos descargado previamente los tiles necesarios para cubrir el área del Partido de La Plata y los importamos usando rioxarray para crear un modelo digital de elevación fusionado que servirá como base para nuestros cálculos hidrológicos.\n\n\nMostrar código\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nimport xarray as xr\nimport rioxarray\nfrom rioxarray.merge import merge_arrays\nimport xdem\nimport tempfile\nimport numpy as np\nfrom matplotlib import colors\nimport leafmap.leafmap as leafmap\nfrom pysheds.grid import Grid\n\nCRS_ARGENTINA = \"EPSG:5349\"\nCRS_WGS84 = \"EPSG:4326\"\n\nRUTA_BASE = Path(\"/home/nissim/Documents/dev/fulbright/ciut-riesgo\")\nRUTA_DATOS = RUTA_BASE / \"notebooks/data\"\nRUTA_PARTIDOS = RUTA_DATOS / \"pba_partidos.geojson\"\n\nCMAP = \"BuPu\"\n\npartidos = gpd.read_file(RUTA_PARTIDOS)\npartidos = partidos.to_crs(CRS_ARGENTINA)\nla_plata = partidos[partidos[\"fna\"] == \"Partido de La Plata\"]\n\n# Quitar la isla de La Plata - mantener solo el polígono más grande\ngeometria_principal = la_plata.geometry.iloc[0]\nif geometria_principal.geom_type == \"MultiPolygon\":\n    poligono_mayor = max(geometria_principal.geoms, key=lambda p: p.area)\n    la_plata = la_plata.copy()\n    la_plata.loc[la_plata.index[0], \"geometry\"] = poligono_mayor\n\nbbox_la_plata_4326 = la_plata.to_crs(CRS_WGS84).total_bounds\n\nrutas_tiles = [\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S35W058_FABDEM_V1-2.tif\",\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S36W058_FABDEM_V1-2.tif\",\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S35W059_FABDEM_V1-2.tif\",\n    RUTA_DATOS / \"fabdem/S40W060-S30W050_FABDEM_V1-2/S36W059_FABDEM_V1-2.tif\",\n]\n\ntiles = [rioxarray.open_rasterio(path, chunks=True) for path in rutas_tiles]\ndem_fusionado = merge_arrays(tiles)\n\ndem_recortado = dem_fusionado.rio.clip_box(\n    minx=bbox_la_plata_4326[0],\n    miny=bbox_la_plata_4326[1],\n    maxx=bbox_la_plata_4326[2],\n    maxy=bbox_la_plata_4326[3],\n)\n\ndem_recortado.plot(cmap=CMAP)\nax = plt.gca()\nla_plata_wgs84 = la_plata.to_crs(CRS_WGS84)\nla_plata_wgs84.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)\n\n\n\n\n\n\n\n\n\n\n\n4.4.2 Calcular acumulación de flujo\nCalculamos la acumulación de flujo, que es esencial para el cálculo del índice de humedad topográfica, siguiendo el tutorial de pysheds. No calculamos esto usando xarray porque pysheds no es compatible con xarray, pero luego convertiremos estos datos a xarray para nuestro cálculo del TWI. El proceso incluye acondicionar el DEM eliminando pozos y depresiones, calcular direcciones de flujo, y finalmente determinar la acumulación de flujo.\n\n\nMostrar código\nwith tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False) as tmp_file:\n    ruta_temporal = tmp_file.name\n\n\ndem_recortado.rio.to_raster(ruta_temporal)\ngrilla = Grid.from_raster(ruta_temporal)\n\ndem = grilla.read_raster(ruta_temporal)\n\nvalor_nodata = dem_recortado.attrs.get(\"_FillValue\", -9999.0)\n\n# Acondicionar DEM\ndem_pozos_rellenos = grilla.fill_pits(dem)\ndem_inundado = grilla.fill_depressions(dem_pozos_rellenos)\ndem_inflado = grilla.resolve_flats(dem_inundado)\n\n\ndem_inflado_xarray = xr.DataArray(\n    dem_inflado,\n    coords={\"y\": dem_recortado.y, \"x\": dem_recortado.x},\n    dims=[\"y\", \"x\"],\n    attrs=dem_recortado.attrs,\n).rio.write_crs(\"EPSG:4326\")\n\n\nmapa_direcciones = (64, 128, 1, 2, 4, 8, 16, 32)\n\n\ndirecciones_flujo = grilla.flowdir(\n    dem_inflado, dirmap=mapa_direcciones, nodata_out=np.int32(0)\n)\n\ndirecciones_flujo_xarray = xr.DataArray(\n    direcciones_flujo,\n    coords={\"y\": dem_recortado.y, \"x\": dem_recortado.x},\n    dims=[\"y\", \"x\"],\n    attrs=dem_recortado.attrs,\n).rio.write_crs(\"EPSG:4326\")\n\n\nacumulacion = grilla.accumulation(\n    direcciones_flujo, dirmap=mapa_direcciones, nodata_out=np.int32(0)\n)\n\n\nacumulacion_xarray = xr.DataArray(\n    acumulacion,\n    coords={\"y\": dem_recortado.y, \"x\": dem_recortado.x},\n    dims=[\"y\", \"x\"],\n    attrs=dem_recortado.attrs,\n).rio.write_crs(\"EPSG:4326\")\n\nfig, ax = plt.subplots(figsize=(8, 6))\nfig.patch.set_alpha(0)\nplt.grid(\"on\", zorder=0)\nim = ax.imshow(\n    acumulacion,\n    extent=grilla.extent,\n    zorder=2,\n    cmap=CMAP,\n    norm=colors.LogNorm(1, acumulacion.max()),\n    interpolation=\"bilinear\",\n)\nplt.colorbar(im, ax=ax, label=\"Celdas Aguas Arriba\")\n\nla_plata_wgs84.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)\nplt.title(\"Acumulación de Flujo\", size=14)\nplt.xlabel(\"Longitud\")\nplt.ylabel(\"Latitud\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n4.4.3 Calcular pendiente\nCalculamos la pendiente, otra variable necesaria para el cálculo del índice de humedad topográfica, siguiendo el tutorial de xDEM. La pendiente es un componente fundamental de la fórmula del TWI y debe calcularse con precisión en un sistema de coordenadas métricas para obtener resultados confiables.\n\n\nMostrar código\nwith tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False) as tmp_file:\n    ruta_temporal = tmp_file.name\n\n# Reproyectar con resolución y proyeccion explícita igual\ndem_reproyectado = dem_recortado.rio.reproject(\n    CRS_ARGENTINA,\n    resolution=30,\n)\n\ndem_reproyectado.rio.to_raster(ruta_temporal)\ndem = xdem.DEM(ruta_temporal)\n\natributos = xdem.terrain.get_terrain_attribute(\n    dem.data,\n    resolution=dem.res,\n    attribute=[\n        \"hillshade\",\n        \"slope\",\n        \"aspect\",\n        \"curvature\",\n        \"terrain_ruggedness_index\",\n        \"rugosity\",\n    ],\n)\n\ndatos_pendiente = atributos[1]\n\ncoordenadas_y = np.arange(dem.bounds.bottom, dem.bounds.top, dem.res[1])\ncoordenadas_x = np.arange(dem.bounds.left, dem.bounds.right, dem.res[0])\n\npendiente_xarray = xr.DataArray(\n    datos_pendiente,\n    coords={\"y\": coordenadas_y, \"x\": coordenadas_x},\n    dims=[\"y\", \"x\"],\n    attrs={\"crs\": dem.crs, \"units\": \"degrees\", \"long_name\": \"slope\"},\n)\n\npendiente_xarray.plot(cmap=CMAP)\nax = plt.gca()\nla_plata.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)\n\n\n\n\n\n\n\n\n\n\n\n4.4.4 Calcular TWI\nCombinamos la acumulación de flujo y la pendiente para calcular el índice de humedad topográfica usando la fórmula estándar TWI = ln(α / tan(β)), donde α es la acumulación de flujo y β es la pendiente. Ajustamos los valores extremos que surgen de dividir por pendiente cero para evitar valores infinitos en áreas completamente planas.\n\n\nMostrar código\nacumulacion_xarray_reproyectada = acumulacion_xarray.rio.reproject(CRS_ARGENTINA)\n\n# Remuestrear pendiente para coincidir con acumulación\npendiente_remuestreada = pendiente_xarray.rio.reproject(\n    acumulacion_xarray_reproyectada.rio.crs,\n    shape=acumulacion_xarray_reproyectada.shape,\n    transform=acumulacion_xarray_reproyectada.rio.transform(),\n)\n\npendiente_rad = np.radians(pendiente_remuestreada)\ndatos_twi = np.log(acumulacion_xarray_reproyectada / np.tan(pendiente_rad))\n\n# Reemplazar valores infinitos y valores muy altos\ndatos_twi = np.where(np.isinf(datos_twi), 25, datos_twi)\ndatos_twi = np.where(datos_twi &gt; 25, 25, datos_twi)\n\ntwi_xarray = xr.DataArray(\n    datos_twi,\n    coords=acumulacion_xarray_reproyectada.coords,\n    dims=acumulacion_xarray_reproyectada.dims,\n    attrs={\n        \"crs\": acumulacion_xarray_reproyectada.rio.crs,\n        \"units\": \"dimensionless\",\n        \"long_name\": \"Topographic Wetness Index\",\n        \"description\": \"ln(flow_accumulation / tan(slope + 0.0001))\",\n    },\n)\n\nplt.figure()\ntwi_xarray.plot(cmap=CMAP)\nax = plt.gca()\nla_plata.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"black\",\n    linewidth=0.5,\n    linestyle=\"--\",\n    zorder=5,\n)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#comparativa-de-modelación-flo-2d-y-twi",
    "href": "twi.html#comparativa-de-modelación-flo-2d-y-twi",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "4.5 Comparativa de modelación FLO-2D y TWI",
    "text": "4.5 Comparativa de modelación FLO-2D y TWI\nDisponemos de datos oficiales de peligro de inundación desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata (Romanazzi et al. 2019). Estos datos fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que simuló la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. La comparación visual entre nuestros resultados del TWI y estos mapas oficiales de peligrosidad permite evaluar qué tan bien corresponde este índice topográfico simple con el modelado hidráulico más completo.\n\n\nMostrar código\nruta_twi = RUTA_DATOS / \"twi.tif\"\ntwi_xarray.rio.to_raster(ruta_twi)\n\nruta_peligro = RUTA_DATOS / \"peligro_raster_10m.tif\"\n\nla_plata_centroid = la_plata.to_crs(CRS_WGS84).centroid.iloc[0]\ncenter_lat = la_plata_centroid.y\ncenter_lon = la_plata_centroid.x\n\nm = leafmap.Map(center=[center_lat, center_lon], zoom=9)\nm.add_tile_layer(\n    url=\"https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}\",\n    name=\"Google Satellite\",\n    attribution=\"Google\",\n)\nm.add_raster(str(ruta_twi), colormap=CMAP, layer_name=\"TWI\")\nm.add_raster(str(ruta_peligro), colormap=CMAP, layer_name=\"Peligrosidad\")\n\nla_plata_geojson = la_plata.to_crs(CRS_WGS84).__geo_interface__\nm.add_geojson(\n    la_plata_geojson,\n    layer_name=\"Partido de La Plata\",\n    style={\"color\": \"black\", \"weight\": 2, \"fillOpacity\": 0},\n)\n\nm.add_layer_control()\nm",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  },
  {
    "objectID": "twi.html#conclusión",
    "href": "twi.html#conclusión",
    "title": "4  Índice de Humedad Topográfica (TWI)",
    "section": "4.6 Conclusión",
    "text": "4.6 Conclusión\nEncontramos que estos datos del TWI son relativamente comparables con los datos de salida del modelo FLO-2D en nuestra comparativa y por lo tanto nos dan un buen grado de confianza para usarlos en evaluar el riesgo relativo a esta escala particular. Consideramos que son útiles como herramienta para evaluar peligros de inundación a nivel urbano. Esto es consistente con estudios internacionales que se han realizado en otras ciudades alrededor del mundo y nos da una sensación de confianza para usar estos datos en evaluaciones preliminares de peligro de inundación en lugares que no tienen mejores fuentes de datos disponibles.\n\n\n\n\nAtlas. 2025. “Topographic Wetness Index—GIS Use Cases.” https://atlas.co/gis-use-cases/topographic-wetness-index/.\n\n\nBallerine, C. 2017. “Topographic Wetness Index Urban Flooding Awareness Act Action Support.” Technical report; University of Illinois at Urbana-Champaign, Prairie Research Institute.\n\n\nHawker, L., P. Uhe, L. Paulo, J. Sosa, J. Savage, C. Sampson, and J. Neal. 2022. “A 30 m Global Map of Elevation with Forests and Buildings Removed.” Environmental Research Letters 17 (2): 024016. https://doi.org/10.1088/1748-9326/ac4d4f.\n\n\nKelleher, C., and L. McPhillips. 2020. “Exploring the Application of Topographic Indices in Urban Areas as Indicators of Pluvial Flooding Locations.” Hydrological Processes 34 (3): 780–94. https://doi.org/10.1002/hyp.13628.\n\n\nRomanazzi, Pablo et al. 2019. Plan de Reducción Del Riesgo Por Inundaciones En La Región de La Plata. Edited by Sebastián Guerrini, Pablo Morosi, Eduardo Pablo Spinelli, and Josefina López MacKenzie. 1st ed. La Plata: Universidad Nacional de La Plata. Facultad de Ingeniería; Municipalidad de La Plata. https://sedici.unlp.edu.ar/bitstream/handle/10915/165109/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Índice de Humedad Topográfica (TWI)</span>"
    ]
  }
]