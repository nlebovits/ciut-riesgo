[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CIUT Riesgo",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "exposicion.html",
    "href": "exposicion.html",
    "title": "1  Exposición",
    "section": "",
    "text": "1.1 Introducción a la Exposición\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#análisis-de-exposición",
    "href": "exposicion.html#análisis-de-exposición",
    "title": "1  Exposición",
    "section": "1.2 Análisis de Exposición",
    "text": "1.2 Análisis de Exposición\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "exposicion.html#evaluación-de-riesgos",
    "href": "exposicion.html#evaluación-de-riesgos",
    "title": "1  Exposición",
    "section": "1.3 Evaluación de Riesgos",
    "text": "1.3 Evaluación de Riesgos\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exposición</span>"
    ]
  },
  {
    "objectID": "suavizacion.html",
    "href": "suavizacion.html",
    "title": "2  Suavización",
    "section": "",
    "text": "2.1 Conceptos de Suavización\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#métodos-de-suavización",
    "href": "suavizacion.html#métodos-de-suavización",
    "title": "2  Suavización",
    "section": "2.2 Métodos de Suavización",
    "text": "2.2 Métodos de Suavización\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "suavizacion.html#aplicaciones-prácticas",
    "href": "suavizacion.html#aplicaciones-prácticas",
    "title": "2  Suavización",
    "section": "2.3 Aplicaciones Prácticas",
    "text": "2.3 Aplicaciones Prácticas\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Suavización</span>"
    ]
  },
  {
    "objectID": "renabap.html",
    "href": "renabap.html",
    "title": "3  RENABAP",
    "section": "",
    "text": "3.1 Resumen ejecutivo",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#análisis-de-datos-renabap",
    "href": "renabap.html#análisis-de-datos-renabap",
    "title": "3  RENABAP",
    "section": "3.2 Análisis de Datos RENABAP",
    "text": "3.2 Análisis de Datos RENABAP\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#resultados-y-conclusiones",
    "href": "renabap.html#resultados-y-conclusiones",
    "title": "3  RENABAP",
    "section": "3.6 Resultados y conclusiones",
    "text": "3.6 Resultados y conclusiones\n\n\nMostrar código\n# 1. BARRIO-LEVEL WIDE DATAFRAME\nrenabap_info = renabap_pba_intersect[[\"id_renabap\", \"nombre_barrio\"]].drop_duplicates()\n\nbarrio_wide = (\n    barrio_areal_tidy[barrio_areal_tidy[\"peligrosidad\"] != \"none\"]\n    .merge(\n        ghsl_barrio_tidy[ghsl_barrio_tidy[\"peligrosidad\"] != \"none\"],\n        on=[\"id_renabap\", \"peligrosidad\"],\n        how=\"outer\",\n    )\n    .merge(\n        buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != \"none\"].rename(\n            columns={\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"}\n        ),\n        on=[\"id_renabap\", \"peligrosidad\"],\n        how=\"outer\",\n    )\n    .merge(renabap_info, on=\"id_renabap\", how=\"left\")\n)\n\nbarrio_wide = barrio_wide[\n    [\n        \"id_renabap\",\n        \"nombre_barrio\",\n        \"peligrosidad\",\n        \"fam_expuestas_edificios\",\n        \"fam_expuestas_ghsl\",\n        \"fam_expuestas_areal\",\n    ]\n]\nbarrio_wide = barrio_wide.fillna(0)\n\n# 2. CUENCA-LEVEL WIDE DATAFRAME\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\nif len(multi_cuenca_settlements) &gt; 0:\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\ncuenca_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != \"none\"]\n    .merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\ncuenca_buildings_wide = cuenca_buildings_wide.rename(\n    columns={\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"}\n)\n\ncuenca_wide = (\n    cuenca_areal_tidy[cuenca_areal_tidy[\"peligrosidad\"] != \"none\"]\n    .merge(\n        ghsl_cuenca_tidy[ghsl_cuenca_tidy[\"peligrosidad\"] != \"none\"],\n        on=[\"Cuenca\", \"peligrosidad\"],\n        how=\"outer\",\n    )\n    .merge(cuenca_buildings_wide, on=[\"Cuenca\", \"peligrosidad\"], how=\"outer\")\n)\n\ncuenca_wide[\"cuenca\"] = cuenca_wide[\"Cuenca\"].str.lower()\ncuenca_wide = cuenca_wide[\n    [\n        \"cuenca\",\n        \"peligrosidad\",\n        \"fam_expuestas_edificios\",\n        \"fam_expuestas_ghsl\",\n        \"fam_expuestas_areal\",\n    ]\n]\ncuenca_wide = cuenca_wide.fillna(0)\n\n# 3. EJE-LEVEL WIDE DATAFRAME\nsettlement_eje_mapping = settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates()\neje_settlement_counts = settlement_eje_mapping[\"id_renabap\"].value_counts()\nmulti_eje_settlements = eje_settlement_counts[eje_settlement_counts &gt; 1].index\nif len(multi_eje_settlements) &gt; 0:\n    settlement_eje_mapping = settlement_eje_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\neje_buildings_wide = (\n    buildings_barrio_tidy[buildings_barrio_tidy[\"peligrosidad\"] != \"none\"]\n    .merge(settlement_eje_mapping, on=\"id_renabap\", how=\"left\")\n    .groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_buildings\"]\n    .sum()\n    .reset_index()\n)\neje_buildings_wide = eje_buildings_wide.rename(\n    columns={\"fam_expuestas_buildings\": \"fam_expuestas_edificios\"}\n)\n\neje_wide = (\n    eje_areal_tidy[eje_areal_tidy[\"peligrosidad\"] != \"none\"]\n    .merge(\n        ghsl_eje_tidy[ghsl_eje_tidy[\"peligrosidad\"] != \"none\"],\n        on=[\"eje\", \"peligrosidad\"],\n        how=\"outer\",\n    )\n    .merge(eje_buildings_wide, on=[\"eje\", \"peligrosidad\"], how=\"outer\")\n)\n\neje_wide = eje_wide[\n    [\n        \"eje\",\n        \"peligrosidad\",\n        \"fam_expuestas_edificios\",\n        \"fam_expuestas_ghsl\",\n        \"fam_expuestas_areal\",\n    ]\n]\neje_wide = eje_wide.fillna(0)\n\n\n\n3.6.1 Comparación de métodos\n\nMostrar código\nbarrio_tidy = pd.melt(\n    barrio_wide,\n    id_vars=[\"id_renabap\", \"nombre_barrio\", \"peligrosidad\"],\n    value_vars=[\"fam_expuestas_edificios\", \"fam_expuestas_ghsl\", \"fam_expuestas_areal\"],\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\nbarrio_tidy[\"metodo\"] = barrio_tidy[\"metodo\"].str.replace(\"fam_expuestas_\", \"\")\n\nbarrio_tidy = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"geometry\"]], on=\"id_renabap\", how=\"left\"\n)\n\nbarrio_tidy[\"area\"] = barrio_tidy.geometry.apply(lambda geom: geom.area)\n\n\n\n\n\n\n# Group by id_renabap and peligro, then find which method has the highest fam_expuestas\nhighest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmax()\n\n# Get the method names for the highest estimates\nmethod_counts = barrio_tidy.loc[highest_methods, \"metodo\"].value_counts()\n\nplt.figure(figsize=(12, 7))\nsns.barplot(x=method_counts.index, y=method_counts.values, palette='viridis')\nplt.title('Métodos que Más Frecuentemente Devuelven la Mayor Estimación de Familias Expuestas', \n          fontsize=14, fontweight='bold', pad=20)\nplt.xlabel('Método', fontsize=12, fontweight='bold')\nplt.ylabel('Frecuencia', fontsize=12, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Group by id_renabap and peligro, then find which method has the lowest fam_expuestas\nlowest_methods = barrio_tidy.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].idxmin()\n\n# Get the method names for the lowest estimates\nlowest_method_counts = barrio_tidy.loc[lowest_methods, \"metodo\"].value_counts()\n\n# Crear gráfico de barras para métodos con menor estimación\nplt.figure(figsize=(12, 7))\nsns.barplot(x=lowest_method_counts.index, y=lowest_method_counts.values, palette='viridis')\nplt.title('Métodos que Más Frecuentemente Devuelven la Menor Estimación de Familias Expuestas', \n          fontsize=14, fontweight='bold', pad=20)\nplt.xlabel('Método', fontsize=12, fontweight='bold')\nplt.ylabel('Frecuencia', fontsize=12, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# First, left join familias_aproximadas from renabap_pba_intersect\nfinal_tidy_with_pop = barrio_tidy.merge(\n    renabap_pba_intersect[[\"id_renabap\", \"familias_aproximadas\"]],\n    on=\"id_renabap\",\n    how=\"left\",\n)\n\n# Calculate the range (highest - lowest) per id_renabap and peligro\nrange_by_barrio = final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"])[\n    \"fam_expuestas\"\n].agg([\"max\", \"min\"])\nrange_by_barrio[\"range\"] = range_by_barrio[\"max\"] - range_by_barrio[\"min\"]\n\n# Merge back to get the total population for each barrio\nrange_by_barrio = range_by_barrio.reset_index().merge(\n    final_tidy_with_pop[[\"id_renabap\", \"familias_aproximadas\"]].drop_duplicates(),\n    on=\"id_renabap\",\n)\n\n# Calculate absolute percent difference as fraction of total barrio population\nrange_by_barrio[\"abs_pct_diff\"] = (\n    range_by_barrio[\"range\"] / range_by_barrio[\"familias_aproximadas\"]\n) * 100\n\n# Calculate average absolute percent difference per peligro level\navg_pct_diff_by_peligro = range_by_barrio.groupby(\"peligrosidad\")[\"abs_pct_diff\"].mean()\n\n# Calculate absolute percent difference by method\nmethod_errors = final_tidy_with_pop.copy()\n\n\n# Calculate absolute error as percent of total population for each method\nmethod_errors[\"abs_error_pct\"] = abs(\n    method_errors[\"fam_expuestas\"] - method_errors.groupby([\"id_renabap\", \"peligrosidad\"])[\"fam_expuestas\"].transform(\"mean\")\n) / method_errors[\"familias_aproximadas\"] * 100\n\n# Calculate coefficient of variation for each barrio-peligro combination\nbarrio_reliability = final_tidy_with_pop.groupby([\"id_renabap\", \"peligrosidad\"]).agg({\n    \"fam_expuestas\": [\"mean\", \"std\"],\n    \"familias_aproximadas\": \"first\"\n}).reset_index()\n\nbarrio_reliability.columns = [\"id_renabap\", \"peligrosidad\", \"mean_estimate\", \"std_estimate\", \"familias_aproximadas\"]\nbarrio_reliability[\"coefficient_variation\"] = barrio_reliability[\"std_estimate\"] / barrio_reliability[\"mean_estimate\"]\n\n# Create box plot\nplt.figure(figsize=(12, 3))\nsns.boxplot(data=barrio_reliability, y=\"peligrosidad\", x=\"coefficient_variation\", \n           hue=\"peligrosidad\", palette=\"viridis\", legend=False, width=0.4)\nplt.title(\"Variabilidad de Estimaciones entre Métodos\", fontsize=16, fontweight='bold', pad=20)\nplt.ylabel(\"Peligrosidad\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Coeficiente de Variación (0 = estimaciones idénticas, 1 = muy variables)\", fontsize=12, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n# Create scatter plot colored by peligrosidad\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio[range_by_barrio[\"peligrosidad\"] == peligro]\n\n    plt.scatter(\n        peligro_data[\"familias_aproximadas\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Familias Aproximadas (Total Barrio Population)\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Barrio Size (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# First, get the area data from final_tidy\narea_data = barrio_tidy[[\"id_renabap\", \"area\"]].drop_duplicates()\n\n# Merge area back into range_by_barrio\nrange_by_barrio_with_area = range_by_barrio.merge(\n    area_data, on=\"id_renabap\", how=\"left\"\n)\n\n\n\nplt.figure(figsize=(10, 6))\n\n# Get unique peligrosidad levels\npeligrosidad_levels = range_by_barrio_with_area[\"peligrosidad\"].unique()\n\nfor peligro in peligrosidad_levels:\n    # Filter data for this peligrosidad level\n    peligro_data = range_by_barrio_with_area[\n        range_by_barrio_with_area[\"peligrosidad\"] == peligro\n    ]\n\n    plt.scatter(\n        peligro_data[\"area\"],\n        peligro_data[\"abs_pct_diff\"],\n        alpha=0.7,\n        label=f\"Peligro: {peligro}\",\n    )\n\nplt.xlabel(\"Area\")\nplt.ylabel(\"Absolute Percent Difference (%)\")\nplt.title(\"Method Disagreement vs Area (Colored by Peligrosidad)\")\n\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n# Filter for high exposure (alta peligrosidad) using the joined dataframe\nalta_data = barrio_tidy[barrio_tidy[\"peligrosidad\"] == \"alta\"].copy()\n\n# Aggregate by nombre_barrio and sum fam_expuestas for each method\n# This handles cases where there are multiple geometries with the same barrio name\nalta_aggregated = (\n    alta_data.groupby([\"nombre_barrio\", \"metodo\"])[\"fam_expuestas\"].sum().reset_index()\n)\n\n# Remove cases where the barrio name is \"Sin Nombre\"\nalta_aggregated = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"] != \"Sin Nombre\"\n].copy()\n\n# Calculate total exposure per barrio across all methods\ntotal_exposure = (\n    alta_aggregated.groupby(\"nombre_barrio\")[\"fam_expuestas\"]\n    .sum()\n    .sort_values(ascending=False)\n)\ntop_10_barrios = total_exposure.head(10).index\n\n# Filter aggregated data for top 10 barrios\ntop_10_data = alta_aggregated[\n    alta_aggregated[\"nombre_barrio\"].isin(top_10_barrios)\n].copy()\n\n# Create range plot showing min, max, and individual points\nplt.figure(figsize=(14, 10))  # Increased height to accommodate longer barrio names\n\n\n# Get RdPu colormap using the correct syntax\nplasma_cmap = cm.plasma\n\n# Define colors for peligrosidad levels using RdPu colormap\npeligrosidad_colors = {\n    \"alta\": plasma_cmap(0.8),  # Darker red-purple for high risk\n    \"media\": plasma_cmap(0.5),  # Lighter red-purple for medium risk\n    \"baja\": plasma_cmap(0.2),  # Lighter red-purple for medium risk\n}\n\n# Define colors for methods using categorical color scheme\nmethod_colors = {\n    \"areal\": plasma_cmap(0.9),\n    \"ghsl\": plasma_cmap(0.5),\n    \"edificios\": plasma_cmap(0.1),\n}\n\nfor i, barrio in enumerate(top_10_barrios):\n    barrio_data = top_10_data[top_10_data[\"nombre_barrio\"] == barrio]\n    if len(barrio_data) &gt; 0:\n        values = barrio_data[\"fam_expuestas\"].values\n        min_val = values.min()\n        max_val = values.max()\n\n        # Plot range line\n        plt.plot([min_val, max_val], [i, i], \"k-\", alpha=0.5, linewidth=2)\n\n        # Plot individual points colored by method\n        for _, row in barrio_data.iterrows():\n            color = method_colors[row[\"metodo\"]]\n            plt.plot(row[\"fam_expuestas\"], i, \"o\", color=color, markersize=6, alpha=0.8)\n\nplt.yticks(range(len(top_10_barrios)), top_10_barrios)\nplt.xlabel(\"Familias Expuestas\")\nplt.ylabel(\"Barrio\")\nplt.title(\"Range of High Exposure Estimates for Top 10 Barrios\", fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# Add legend\nlegend_elements = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=color,\n        markersize=8,\n        label=method,\n    )\n    for method, color in method_colors.items()\n]\nplt.legend(handles=legend_elements, title=\"Método\")\n\nplt.tight_layout()\nplt.show()\n\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"area\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_area\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_expuestas_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n/tmp/ipykernel_524317/2541737214.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=method_counts.index, y=method_counts.values, palette='viridis')\n\n\n/tmp/ipykernel_524317/2541737214.py:55: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=lowest_method_counts.index, y=lowest_method_counts.values, palette='viridis')\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Discrepancia vs población total del barrio\n\n\n\n\n\n\n\n\n\n\n\n(b) Discrepancia vs área del barrio\n\n\n\n\n\n\n\n\n\n\n\n(c) Rango de estimaciones para barrios con mayor exposición\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n\n\n\n\n(f)\n\n\n\n\n\n\n\nFigure 3.1: Análisis comparativo de métodos de estimación por barrio\n\n\n\n\n\nMostrar código\ndef plot_method_map(\n    method_name,\n    final_tidy,\n    la_plata,\n    peligrosidad_colors,\n    common_bounds,\n    create_consistent_map,\n):\n    fig, ax = create_consistent_map(\n        f\"Barrios por población expuesta estimada - {method_name.capitalize()}\",\n        common_bounds,\n    )\n\n    method_data = final_tidy[\n        (final_tidy[\"metodo\"] == method_name)\n        & (final_tidy[\"peligrosidad\"].isin([\"alta\", \"media\"]))\n    ].copy()\n\n    method_gdf = gpd.GeoDataFrame(method_data, geometry=\"geometry\", crs=\"EPSG:5349\")\n    method_gdf = method_gdf.clip(la_plata)\n    method_gdf_3857 = method_gdf.to_crs(\"EPSG:3857\")\n\n    plotting_order = [\"media\", \"alta\"]\n\n    np.random.seed(42)\n    for peligrosidad in plotting_order:\n        level_data = method_gdf_3857[method_gdf_3857[\"peligrosidad\"] == peligrosidad]\n        for _, row in level_data.iterrows():\n            centroid = row[\"geometry\"].centroid\n            jitter_x = np.random.uniform(-200, 200)\n            jitter_y = np.random.uniform(-200, 200)\n            x_pos = centroid.x + jitter_x\n            y_pos = centroid.y + jitter_y\n            color = peligrosidad_colors[row[\"peligrosidad\"]]\n            size = max(10, row[\"fam_expuestas\"] * 2 + 15)\n            ax.scatter(\n                x_pos,\n                y_pos,\n                s=size,\n                color=color,\n                alpha=0.9,\n                edgecolors=\"white\",\n                linewidth=1.0,\n            )\n\n    legend_elements = [\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"o\",\n            color=\"w\",\n            markerfacecolor=color,\n            markersize=8,\n            label=level.capitalize(),\n        )\n        for level, color in peligrosidad_colors.items()\n    ]\n    ax.legend(handles=legend_elements, title=\"Nivel de Peligrosidad\", loc=\"upper right\")\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nMostrar código\narea_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"area\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\narea_data = area_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_area\"})\n\nghsl_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"ghsl\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nghsl_data = ghsl_data.rename(columns={\"fam_expuestas\": \"fam_expuestas_ghsl\"})\n\nedificios_data = (\n    barrio_tidy[barrio_tidy[\"metodo\"] == \"edificios\"]\n    .groupby([\"nombre_barrio\", \"peligrosidad\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\nedificios_data = edificios_data.rename(\n    columns={\"fam_expuestas\": \"fam_expuestas_edificios\"}\n)\n\n# Merge all methods together\nbarrio_summary = area_data.merge(\n    ghsl_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nbarrio_summary = barrio_summary.merge(\n    edificios_data, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\nbarrio_summary = barrio_summary.fillna(0)\n\n\n\n# Sort by nombre_barrio and peligrosidad in descending order\nbarrio_summary = barrio_summary.sort_values(\n    [\"nombre_barrio\", \"peligrosidad\"], ascending=True\n)\n\n\n\n\n3.6.2 Exposición por barrio\n\nMostrar código\nmethods = barrio_tidy[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        barrio_tidy,\n        la_plata,\n        peligrosidad_colors,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.2: Comparación de métodos de estimación de exposición por barrio\n\n\n\n\n\nMostrar código\nshow(barrio_summary)\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.3 Exposición por cuenca\n\nMostrar código\ncuencas_centroids = cuencas.copy()\ncuencas_centroids[\"geometry\"] = cuencas_centroids[\"geometry\"].centroid\n\n# Create a lowercase version of Cuenca for matching\ncuencas_centroids[\"cuenca_lower\"] = cuencas_centroids[\"Cuenca\"].str.lower()\n\ncuenca_tidy = pd.melt(\n    cuenca_wide,\n    id_vars=[\"cuenca\", \"peligrosidad\"],  \n    value_vars=[\n        \"fam_expuestas_edificios\",\n        \"fam_expuestas_ghsl\",\n        \"fam_expuestas_areal\",\n    ], \n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\ncuenca_tidy[\"metodo\"] = cuenca_tidy[\"metodo\"].str.replace(\"fam_expuestas_\", \"\")\n\ncuenca_tidy_with_geometry = cuenca_tidy.merge(\n    cuencas_centroids[[\"cuenca_lower\", \"geometry\"]],\n    left_on=\"cuenca\",\n    right_on=\"cuenca_lower\",\n    how=\"left\",\n)\n\ncuenca_tidy_gdf = gpd.GeoDataFrame(\n    cuenca_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = cuenca_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        cuenca_tidy_gdf,\n        la_plata,\n        peligrosidad_colors,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.3: Comparación de métodos de estimación de exposición por cuenca\n\n\n\n\n\nMostrar código\nshow(cuenca_wide)\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n3.6.4 Exposición por eje\n\nMostrar código\neje_tidy = pd.melt(\n    eje_wide,\n    id_vars=[\"eje\", \"peligrosidad\"],\n    value_vars=[\"fam_expuestas_edificios\", \"fam_expuestas_ghsl\", \"fam_expuestas_areal\"],\n    var_name=\"metodo\",\n    value_name=\"fam_expuestas\",\n)\n\n\neje_tidy[\"metodo\"] = eje_tidy[\"metodo\"].str.replace(\"fam_expuestas_\", \"\")\n\n# Create eje geodataframe by dissolving cuencas by eje and then taking centroids\nejes = cuencas.dissolve(by=\"eje\").reset_index()\nejes_centroids = ejes.copy()\nejes_centroids[\"geometry\"] = ejes_centroids[\"geometry\"].centroid\n\neje_tidy_with_geometry = eje_tidy.merge(\n    ejes_centroids[[\"eje\", \"geometry\"]], on=\"eje\", how=\"left\"\n)\n\neje_tidy_gdf = gpd.GeoDataFrame(\n    eje_tidy_with_geometry, geometry=\"geometry\", crs=cuencas.crs\n)\n\nmethods = eje_tidy_gdf[\"metodo\"].unique()\n\nfor method in methods:\n    plot_method_map(\n        method,\n        eje_tidy_gdf,\n        la_plata,\n        peligrosidad_colors,\n        common_bounds,\n        create_consistent_map,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimación basada en edificios\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimación basada en GHSL\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimación basada en interpolación areal\n\n\n\n\n\n\n\nFigure 3.4: Comparación de métodos de estimación de exposición por eje de cuenca\n\n\n\n\n\nMostrar código\nshow(eje_wide)\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n\n\nSchiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023. “GHS-POP R2023A - GHS Population Grid Multitemporal (1975-2030).” European Commission, Joint Research Centre (JRC). https://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of Flood Exposure in Developing Countries Using High-Resolution Population Data.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite Imaging Reveals Increased Proportion of Population Exposed to Floods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by VIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#fuentes-de-datos-y-metodología",
    "href": "renabap.html#fuentes-de-datos-y-metodología",
    "title": "3  RENABAP",
    "section": "3.2 Fuentes de datos y metodología",
    "text": "3.2 Fuentes de datos y metodología\n\n3.2.1 Datos\n\n3.2.1.1 RENABAP\n\n\n3.2.1.2 Censo Argentino\n\n\n3.2.1.3 GHSL\n\n\n3.2.1.4 Google-Microsoft Open Buildings\n\n\n\n3.2.2 Metodología\n\n3.2.2.1 Interpolación por area\n\n\n3.2.2.2 Mapeo dasymetrico",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#procesamiento-y-resultados",
    "href": "renabap.html#procesamiento-y-resultados",
    "title": "3  RENABAP",
    "section": "3.3 Procesamiento y resultados",
    "text": "3.3 Procesamiento y resultados\n\n\nMostrar código\nimport pandas as pd\nimport geopandas as gpd\nimport requests\nfrom io import StringIO\n\nimport boto3\nimport duckdb\n\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport s2sphere\nfrom botocore.config import Config\nfrom rasterstats import zonal_stats\n\n\nfrom shapely.geometry import box\n\n\nUSE_CRS = \"EPSG:5349\"\n\n\n\n### import data\n\nresponse = requests.get(\n    \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\n)\nrenabap = gpd.read_file(StringIO(response.text))\nrenabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\nrenabap_pba = renabap_pba.to_crs(USE_CRS)\n\npeligro_path = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/la_plata_pelig_2023_datos_originales.geojson\"\npeligro = gpd.read_file(peligro_path)\npeligro = peligro.to_crs(USE_CRS)\n\npeligro_bounds = peligro.total_bounds\npeligro_bbox = box(*peligro_bounds)\n\nrenabap_pba_intersect = renabap_pba[\n    renabap_pba.geometry.intersects(peligro_bbox)\n].copy()\n\n\n\n3.3.1 Interpolación por area\n\n\nMostrar código\n# Ensure both GeoDataFrames have the same CRS\nif renabap_pba_intersect.crs != peligro.crs:\n    peligro = peligro.to_crs(renabap_pba_intersect.crs)\n\n# Get unique hazard levels\nhazard_levels = peligro[\"PELIGROSID\"].unique()\n\n# Initialize result columns\nrenabap_with_porciones = renabap_pba_intersect.copy()\nfor level in hazard_levels:\n    renabap_with_porciones[f\"porcion_{level}\"] = 0.0\n\n# Calculate total area of each barrio\nrenabap_with_porciones['total_area'] = renabap_with_porciones.geometry.area\n\n# For each barrio, calculate intersection with each hazard level\nfor idx, barrio in renabap_with_porciones.iterrows():\n    barrio_geom = barrio.geometry\n    barrio_total_area = barrio_geom.area\n    \n    if barrio_total_area == 0:\n        continue\n        \n    for level in hazard_levels:\n        hazard_subset = peligro[peligro[\"PELIGROSID\"] == level]\n        \n        if hazard_subset.empty:\n            continue\n        \n        # Calculate intersection area\n        intersection_area = 0\n        for _, hazard_row in hazard_subset.iterrows():\n            try:\n                intersection = barrio_geom.intersection(hazard_row.geometry)\n                if not intersection.is_empty:\n                    intersection_area += intersection.area\n            except Exception as e:\n                print(f\"Error calculating intersection for {barrio.get('nombre_barrio', idx)}: {e}\")\n                continue\n        \n        # Calculate proportion\n        proportion = intersection_area / barrio_total_area if barrio_total_area &gt; 0 else 0\n        renabap_with_porciones.at[idx, f\"porcion_{level}\"] = proportion\n\n# Create tidy format dataframe\nrenabap_tidy = []\n\nfor idx, row in renabap_with_porciones.iterrows():\n    for level in hazard_levels:\n        familias_expuestas = row[f\"porcion_{level}\"] * row[\"familias_aproximadas\"]\n        \n        renabap_tidy.append({\n            \"id_renabap\": row[\"id_renabap\"],\n            \"nombre_barrio\": row[\"nombre_barrio\"],\n            \"peligrosidad\": level,\n            \"fam_expuestas_areal\": familias_expuestas\n        })\n\nrenabap_tidy = pd.DataFrame(renabap_tidy)\n\nprint(renabap_tidy.head())\n\n\n   id_renabap nombre_barrio peligrosidad  fam_expuestas_areal\n0           2   Malvinas II         alta             0.000000\n1           2   Malvinas II         baja             1.001885\n2           2   Malvinas II        media             0.000000\n3           3   Ferroviario         alta             0.000000\n4           3   Ferroviario         baja            18.936166\n\n\n\n\n3.3.2 Cuenta de edificios\n\n\nMostrar código\ndef fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n\n    # Get S2 cell and bounds\n    center = geodataframe.to_crs(\"epsg:3857\").union_all().centroid\n    center_wgs84 = (\n        gpd.GeoDataFrame(geometry=[center], crs=\"EPSG:3857\")\n        .to_crs(epsg=4326)\n        .geometry.iloc[0]\n    )\n    cell = s2sphere.CellId.from_lat_lng(\n        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n    ).parent(10)\n    bounds = geodataframe.to_crs(\"epsg:4326\").total_bounds\n\n    # Find matching S2 partition\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=\"https://data.source.coop\",\n        aws_access_key_id=\"\",\n        aws_secret_access_key=\"\",\n        config=Config(s3={\"addressing_style\": \"path\"}),\n    )\n\n    partitions = {\n        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n        for obj in s3.list_objects_v2(\n            Bucket=\"vida\",\n            Prefix=\"google-microsoft-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n        ).get(\"Contents\", [])\n    }\n\n    parent_id = next(\n        str(cell.parent(level).id())\n        for level in range(10, 0, -1)\n        if str(cell.parent(level).id()) in partitions\n    )\n\n    # Setup DuckDB and query\n    con = duckdb.connect()\n    for cmd in [\n        \"INSTALL spatial\",\n        \"LOAD spatial\",\n        \"INSTALL httpfs\",\n        \"LOAD httpfs\",\n        \"SET s3_region='us-east-1'\",\n        \"SET s3_endpoint='data.source.coop'\",\n        \"SET s3_use_ssl=true\",\n        \"SET s3_url_style='path'\",\n    ]:\n        con.execute(cmd)\n\n    # Export and read back\n    query = f\"\"\"\n    COPY (SELECT * FROM 's3://vida/google-microsoft-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n          WHERE bbox.xmax &gt;= {bounds[0]} AND bbox.xmin &lt;= {bounds[2]} AND\n                bbox.ymax &gt;= {bounds[1]} AND bbox.ymin &lt;= {bounds[3]}\n    ) TO '{temp_file}' (FORMAT PARQUET);\n    \"\"\"\n\n    con.execute(query)\n    df = pd.read_parquet(temp_file)\n    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n\n    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n\n\n# Usage:\nbuildings = fetch_buildings(renabap_pba_intersect)\n\n\n\n\n\n\n\n3.3.3 Mapeo dasymetrico con datos GHSL\n\n\nMostrar código\nimport rioxarray\nfrom shapely.geometry import box\n\n# Load GHSL data with dask chunking for memory efficiency\nghsl = rioxarray.open_rasterio(\n    \"/home/nissim/Downloads/spatial/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13.tif\",\n    chunks={\"x\": 1024, \"y\": 1024},  # Adjust chunk size based on your memory constraints\n)\n\n# Reproject to your target CRS with streaming\nghsl = ghsl.rio.reproject(dst_crs=USE_CRS)\n\n# Clip to renabap_pba_intersect bounding box using streaming\nbounding_box = box(\n    *renabap_pba_intersect.total_bounds\n)  # Create a box from the bounding box coordinates\n\nghsl_clipped = ghsl.rio.clip(\n    [bounding_box],  # Use the bounding box as a geometry (wrapped in a list)\n    from_disk=True,  # Process from disk to avoid loading entire dataset into memory\n)\n\n\nimport rasterstats\n\n# Step 1: Calculate the total GHSL population per barrio popular using zonal statistics\nprint(\"Calculating GHSL population totals per barrio popular...\")\n\n# Convert to the format expected by rasterstats\ngeometries = [geom for geom in renabap_pba_intersect.geometry]\n\n# Use rasterstats for vectorized zonal statistics\nstats = rasterstats.zonal_stats(\n    geometries,\n    ghsl_clipped.values[0],  # rasterstats expects 2D array\n    affine=ghsl_clipped.rio.transform(),\n    stats=[\"sum\"],\n    nodata=ghsl_clipped.rio.nodata,\n)\n\n# Extract the sum values\nghsl_totals = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n\n# Add the GHSL population estimates as a new column\nrenabap_pba_intersect[\"ghsl_pop_est\"] = ghsl_totals\n\n# Verify the results\nprint(f\"Added GHSL population estimates to {len(ghsl_totals)} barrios\")\nprint(f\"Total estimated population: {sum(ghsl_totals):,.0f}\")\nprint(f\"Range: {min(ghsl_totals):.0f} - {max(ghsl_totals):.0f}\")\n\n# Show a few examples\nprint(\"\\nFirst 5 barrios with GHSL estimates:\")\nprint(renabap_pba_intersect[[\"geometry\", \"ghsl_pop_est\"]].head())\n\nfrom rasterio.features import rasterize\nimport numpy as np\n\n# Get the reference raster properties from GHSL data\nreference_raster = ghsl_clipped\nreference_transform = reference_raster.rio.transform()\nreference_crs = reference_raster.rio.crs\nreference_shape = reference_raster.shape[1:]  # Get 2D shape (height, width)\n\nprint(f\"Reference raster shape: {reference_shape}\")\nprint(f\"Reference CRS: {reference_crs}\")\n\n# Prepare geometries and values for rasterization\ngeometries_ghsl = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"ghsl_pop_est\"]\n    )\n]\ngeometries_familias = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"familias_aproximadas\"]\n    )\n]\n\n# Create GHSL population raster\nghsl_pop_raster = rasterize(\n    geometries_ghsl,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Create familias aproximadas raster\nfamilias_raster = rasterize(\n    geometries_familias,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Verify the rasters\nprint(\n    f\"GHSL population range: {np.nanmin(ghsl_pop_raster):.2f} - {np.nanmax(ghsl_pop_raster):.2f}\"\n)\nprint(\n    f\"Familias range: {np.nanmin(familias_raster):.2f} - {np.nanmax(familias_raster):.2f}\"\n)\n\n# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n# Use masking to avoid division on invalid cells\nmask = (ghsl_clipped.values[0] != -200) & (ghsl_pop_raster &gt; 0.1)\nghsl_fractional = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n\n# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\nmask2 = (ghsl_fractional != -200) & (familias_raster &gt; 0)\nfamilias_downscaled = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nfamilias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n\n# Verify the results - exclude -200 from range calculations\nghsl_valid = ghsl_clipped.values[0] != -200\nfractional_valid = ghsl_fractional != -200\ndownscaled_valid = familias_downscaled != -200\n\nprint(\n    f\"Original GHSL range: {np.min(ghsl_clipped.values[0][ghsl_valid]):.2f} - {np.max(ghsl_clipped.values[0][ghsl_valid]):.2f}\"\n)\nprint(\n    f\"Fractional population range: {np.min(ghsl_fractional[fractional_valid]):.4f} - {np.max(ghsl_fractional[fractional_valid]):.4f}\"\n)\nprint(\n    f\"Downscaled familias range: {np.min(familias_downscaled[downscaled_valid]):.2f} - {np.max(familias_downscaled[downscaled_valid]):.2f}\"\n)\n\n# Check that the sum of downscaled familias equals the original familias aproximadas\ntotal_original_familias = renabap_pba_intersect[\"familias_aproximadas\"].sum()\ntotal_downscaled_familias = np.sum(familias_downscaled[downscaled_valid])\nprint(f\"\\nTotal original familias: {total_original_familias:,.0f}\")\nprint(f\"Total downscaled familias: {total_downscaled_familias:,.0f}\")\nprint(f\"Difference: {abs(total_original_familias - total_downscaled_familias):,.2f}\")\n\n# Intersect settlements with hazard zones\nsettlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n\n# Create GHSL tidy dataframe with matching structure\nghsl_tidy = []\n\nfor idx, row in settlement_hazard.iterrows():\n    stats = zonal_stats(\n        [row.geometry],\n        familias_downscaled,  # your numpy array\n        affine=reference_transform,  # get transform from your xarray\n        stats=[\"sum\"],\n        nodata=-200,  # use your actual nodata value\n    )[0]\n\n    ghsl_tidy.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"peligrosidad\": row[\"PELIGROSID\"],\n            \"fam_expuestas_ghsl\": stats[\"sum\"] if stats[\"sum\"] is not None else 0,\n        }\n    )\n\nghsl_tidy = pd.DataFrame(ghsl_tidy)\n\nprint(ghsl_tidy.head())\n\n\nCalculating GHSL population totals per barrio popular...\nAdded GHSL population estimates to 323 barrios\nTotal estimated population: 257,167\nRange: 0 - 9332\n\nFirst 5 barrios with GHSL estimates:\n                                            geometry  ghsl_pop_est\n1  MULTIPOLYGON (((7133413.584 6125858.719, 71336...    729.961555\n2  MULTIPOLYGON (((7127613.216 6115863.573, 71276...    240.369900\n3  MULTIPOLYGON (((7136174.621 6130304.579, 71361...    265.001049\n4  MULTIPOLYGON (((7128546.05 6130775.49, 7128519...     10.639407\n5  MULTIPOLYGON (((7129976.453 6132330.669, 71299...      0.000000\nReference raster shape: (490, 711)\nReference CRS: EPSG:5349\nGHSL population range: 0.00 - 9332.04\nFamilias range: 0.00 - 2640.00\nOriginal GHSL range: 0.00 - 304.95\nFractional population range: 0.0000 - 1.0000\nDownscaled familias range: 0.00 - 383.00\n\nTotal original familias: 88,856\nTotal downscaled familias: 88,680\nDifference: 176.00\n   id_renabap peligrosidad  fam_expuestas_ghsl\n0           2         baja            0.000000\n1           3         baja           14.286419\n2           3        media           32.931858\n3           4         alta            0.000000\n4           4        media          134.000006\n\n\n\n\n3.3.4 Mapeo dasymetrico con datos de edificios\n\n\nMostrar código\n# Reproject buildings to match the analysis CRS\nbuildings_proj = buildings.to_crs(USE_CRS)\n\n# Step 1: Calculate buildings per settlement-hazard intersection\nbuildings_hazard = gpd.overlay(buildings_proj, settlement_hazard, how=\"intersection\")\n\n# Count buildings per settlement-hazard combination\nbuildings_per_hazard = (\n    buildings_hazard.groupby([\"id_renabap\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\n\n# Step 2: Calculate total buildings per settlement (barrio popular)\nbuildings_settlement = gpd.overlay(\n    buildings_proj, renabap_pba_intersect, how=\"intersection\"\n)\ntotal_buildings_per_settlement = (\n    buildings_settlement.groupby(\"id_renabap\")\n    .size()\n    .reset_index(name=\"total_buildings\")\n)\n\n# Step 3: Merge and calculate ratios\nhazard_ratios = buildings_per_hazard.merge(\n    total_buildings_per_settlement, on=\"id_renabap\", how=\"left\"\n)\nhazard_ratios[\"building_ratio\"] = (\n    hazard_ratios[\"buildings_count\"] / hazard_ratios[\"total_buildings\"]\n)\n\n# Step 4: Get total population per settlement and apply ratios\nsettlement_population = renabap_pba_intersect[\n    [\"id_renabap\", \"familias_aproximadas\"]\n].copy()\n\n# Merge with ratios and calculate population estimates\npopulation_estimates = hazard_ratios.merge(\n    settlement_population, on=\"id_renabap\", how=\"left\"\n)\npopulation_estimates[\"estimated_population_hazard\"] = (\n    population_estimates[\"building_ratio\"]\n    * population_estimates[\"familias_aproximadas\"]\n)\n\n# Step 5: Create final results with totals\nfinal_results = population_estimates[\n    [\"id_renabap\", \"PELIGROSID\", \"estimated_population_hazard\"]\n].copy()\n\n# Add total population rows (no hazard breakdown)\ntotal_pop_rows = settlement_population.copy()\ntotal_pop_rows[\"PELIGROSID\"] = \"total\"\ntotal_pop_rows[\"estimated_population_hazard\"] = total_pop_rows[\"familias_aproximadas\"]\n\n# Combine\nfinal_results = pd.concat(\n    [\n        final_results,\n        total_pop_rows[[\"id_renabap\", \"PELIGROSID\", \"estimated_population_hazard\"]],\n    ],\n    ignore_index=True,\n)\n\n# Create buildings tidy dataframe with matching structure\nbuildings_tidy = final_results[\n    [\"id_renabap\", \"PELIGROSID\", \"estimated_population_hazard\"]\n].copy()\n\n# Rename columns to match the structure\nbuildings_tidy = buildings_tidy.rename(\n    columns={\n        \"PELIGROSID\": \"peligrosidad\",\n        \"estimated_population_hazard\": \"fam_expuestas_edificios\",\n    }\n)\n\n# Filter out the 'total' rows since we only want hazard-specific data\nbuildings_tidy = buildings_tidy[buildings_tidy[\"peligrosidad\"] != \"total\"].copy()\n\nprint(buildings_tidy.head())\n\n\n   id_renabap peligrosidad  fam_expuestas_edificios\n0           2         baja                 3.538827\n1           3         baja                33.654237\n2           3        media                22.766102\n3           4         alta                36.258824\n4           4        media               122.964706",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#conclusions",
    "href": "renabap.html#conclusions",
    "title": "3  RENABAP",
    "section": "3.4 Conclusions",
    "text": "3.4 Conclusions\n\n3.4.1 Comparación de resuldatos\n\n\nMostrar código\n# Join all three dataframes by id_renabap and peligrosidad\nfinal_df = renabap_tidy.merge(\n    ghsl_tidy, on=[\"id_renabap\", \"peligrosidad\"], how=\"outer\"\n)\nfinal_df = final_df.merge(\n    buildings_tidy, on=[\"id_renabap\", \"peligrosidad\"], how=\"outer\"\n)\n\n# Impute 0s for NA values in fam_expuestas columns\nfam_expuestas_columns = [col for col in final_df.columns if 'fam_expuestas' in col]\nfinal_df[fam_expuestas_columns] = final_df[fam_expuestas_columns].fillna(0)\n\n# Create long format dataframe with aggregation\nfinal_tidy = []\n\n# Add renabap data\nfor _, row in renabap_tidy.iterrows():\n    final_tidy.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"peligrosidad\": row[\"peligrosidad\"],\n            \"metodo\": \"area\",\n            \"fam_expuestas\": row[\"fam_expuestas_areal\"],\n        }\n    )\n\n# Add ghsl data\nfor _, row in ghsl_tidy.iterrows():\n    final_tidy.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"peligrosidad\": row[\"peligrosidad\"],\n            \"metodo\": \"ghsl\",\n            \"fam_expuestas\": row[\"fam_expuestas_ghsl\"],\n        }\n    )\n\n# Add buildings data\nfor _, row in buildings_tidy.iterrows():\n    final_tidy.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"peligrosidad\": row[\"peligrosidad\"],\n            \"metodo\": \"edificios\",\n            \"fam_expuestas\": row[\"fam_expuestas_edificios\"],\n        }\n    )\n\nfinal_tidy = pd.DataFrame(final_tidy)\n\n# Aggregate to get one observation per barrio per hazard level per method\nfinal_tidy = (\n    final_tidy.groupby([\"id_renabap\", \"peligrosidad\", \"metodo\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\n\n# Create complete combination of all barrios, hazard levels, and methods\nall_barrios = final_tidy[\"id_renabap\"].unique()\nall_hazard_levels = [\"alta\", \"baja\", \"media\"]\nall_methods = [\"area\", \"ghsl\", \"edificios\"]\n\ncomplete_combinations = pd.DataFrame([\n    {\"id_renabap\": barrio, \"peligrosidad\": hazard, \"metodo\": method}\n    for barrio in all_barrios\n    for hazard in all_hazard_levels\n    for method in all_methods\n])\n\n# Merge with actual data and fill missing values with 0\nfinal_tidy = complete_combinations.merge(\n    final_tidy, on=[\"id_renabap\", \"peligrosidad\", \"metodo\"], how=\"left\"\n)\nfinal_tidy[\"fam_expuestas\"] = final_tidy[\"fam_expuestas\"].fillna(0)\n\nprint(final_tidy.head(10))\nprint(f\"Shape: {final_tidy.shape}\")\n\n# Calculate total exposure per hazard level per method\nsummary = (\n    final_tidy.groupby([\"peligrosidad\", \"metodo\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n    .pivot(index=\"peligrosidad\", columns=\"metodo\", values=\"fam_expuestas\")\n)\n\nprint(\"Total Familias Expuestas por Peligrosidad y Método:\")\nprint(\"=\" * 50)\nprint(summary.round(2))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter for high exposure (alta peligrosidad)\nalta_data = final_tidy[final_tidy[\"peligrosidad\"] == \"alta\"].copy()\n\n# Calculate total exposure per barrio across all methods\ntotal_exposure = (\n    alta_data.groupby(\"id_renabap\")[\"fam_expuestas\"]\n    .sum()\n    .sort_values(ascending=False)\n)\ntop_25_barrios = total_exposure.head(25).index\n\n# Filter data for top 25 barrios\ntop_25_data = alta_data[\n    alta_data[\"id_renabap\"].isin(top_25_barrios)\n].copy()\n\n# Create range plot showing min, max, and individual points\nplt.figure(figsize=(15, 10))\n\n# Define colors for methods\nmethod_colors = {\"area\": \"blue\", \"ghsl\": \"red\", \"edificios\": \"green\"}\n\nfor i, barrio in enumerate(top_25_barrios):\n    barrio_data = top_25_data[top_25_data[\"id_renabap\"] == barrio]\n    if len(barrio_data) &gt; 0:\n        values = barrio_data[\"fam_expuestas\"].values\n        min_val = values.min()\n        max_val = values.max()\n\n        # Plot range line\n        plt.plot([min_val, max_val], [i, i], \"k-\", alpha=0.5, linewidth=2)\n\n        # Plot individual points colored by method\n        for _, row in barrio_data.iterrows():\n            color = method_colors[row[\"metodo\"]]\n            plt.plot(row[\"fam_expuestas\"], i, \"o\", color=color, markersize=6, alpha=0.8)\n\nplt.yticks(range(len(top_25_barrios)), top_25_barrios)\nplt.xlabel(\"Familias Expuestas\")\nplt.ylabel(\"Barrio ID\")\nplt.title(\"Range of High Exposure Estimates for Top 25 Barrios\", fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# Add legend\nlegend_elements = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=color,\n        markersize=8,\n        label=method,\n    )\n    for method, color in method_colors.items()\n]\nplt.legend(handles=legend_elements, title=\"Método\")\n\nplt.tight_layout()\nplt.show()\n\n\n   id_renabap peligrosidad     metodo  fam_expuestas\n0           2         alta       area       0.000000\n1           2         alta       ghsl       0.000000\n2           2         alta  edificios       0.000000\n3           2         baja       area       1.001885\n4           2         baja       ghsl       0.000000\n5           2         baja  edificios       3.538827\n6           2        media       area       0.000000\n7           2        media       ghsl       0.000000\n8           2        media  edificios       0.000000\n9           3         alta       area       0.000000\nShape: (2907, 4)\nTotal Familias Expuestas por Peligrosidad y Método:\n==================================================\nmetodo           area  edificios     ghsl\npeligrosidad                             \nalta          3552.36    3646.34  2831.97\nbaja          7581.05    9911.60  7726.58\nmedia         8555.48    9678.24  8400.36",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#referencias",
    "href": "renabap.html#referencias",
    "title": "3  RENABAP",
    "section": "3.5 Referencias",
    "text": "3.5 Referencias\n\n\n\n\nSchiavina, M., S. Freire, A. Carioli, and K. MacManus. 2023. “GHS-POP R2023A - GHS Population Grid Multitemporal (1975-2030).” European Commission, Joint Research Centre (JRC). https://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE.\n\n\nSmith, A., P. D. Bates, O. Wing, et al. 2019. “New Estimates of Flood Exposure in Developing Countries Using High-Resolution Population Data.” Nature Communications 10: 1814. https://doi.org/10.1038/s41467-019-09282-y.\n\n\nTellman, B., J. A. Sullivan, C. Kuhn, et al. 2021. “Satellite Imaging Reveals Increased Proportion of Population Exposed to Floods.” Nature 596: 80–86. https://doi.org/10.1038/s41586-021-03695-w.\n\n\nVIDA. 2023. “Google-Microsoft-OSM Open Buildings - Combined by VIDA.” https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#fuentes-de-datos",
    "href": "renabap.html#fuentes-de-datos",
    "title": "3  RENABAP",
    "section": "3.4 Fuentes de datos",
    "text": "3.4 Fuentes de datos\n\n3.4.1 RENABAP\nEl Registro Nacional de Barrios Populares (RENABAP) es producido por la Subsecretaría de Integración Socio Urbana y proporciona información sobre asentamientos informales en Argentina, incluyendo estimaciones de población y delimitaciones geográficas de estos barrios. Más información sobre el RENABAP está disponible en el Observatorio de Barrios Populares. Los datos fueron obtenidos a través del Mapa de Barrios Populares y están disponibles para descarga como GeoJSON.\n\n\nMostrar código\nfig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", common_bounds)\n\nrenabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(\"EPSG:3857\")\n\nrenabap_pba_intersect_3857.plot(\n    ax=ax1, facecolor=\"none\", edgecolor=\"black\", linewidth=0.5, legend=False, zorder=10\n)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nMostrar código\npeligro_clipped = gpd.clip(peligro, la_plata)\n\npeligro_clipped_3857 = peligro_clipped.to_crs(\"EPSG:3857\")\n\n# Reorder the categories so they map correctly to plasma colormap\npeligro_clipped_3857[\"PELIGROSID_ordered\"] = pd.Categorical(\n    peligro_clipped_3857[\"PELIGROSID\"],\n    categories=[\"baja\", \"media\", \"alta\"],\n    ordered=True,\n)\n\n\nfig2, ax2 = create_consistent_map(\"Zonas de Peligro en La Plata\", common_bounds)\n\n\npeligro_clipped_3857.plot(\n    ax=ax2,\n    column=\"PELIGROSID_ordered\",\n    cmap=\"plasma\",\n    alpha=0.75,\n    legend=True,\n    zorder=5,\n)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 GHSL\nLa Capa Global de Asentamientos Humanos (Global Human Settlement Layer) (Schiavina et al. 2023) es un conjunto de datos de resolución de 100 metros que proporciona estimaciones de población multitemporales (1975-2030) derivadas de datos censales y administrativos, informadas por la distribución y clasificación de áreas construidas. El GHSL ya tiene un uso científico establecido para mapear la exposición poblacional a peligros de inundación (Tellman et al. 2021). Sin embargo, esta fuente presenta limitaciones importantes: estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución (Smith et al. 2019).\n\n\nMostrar código\n# Load GHSL data with dask chunking for memory efficiency\nghsl = rioxarray.open_rasterio(\n    \"/home/nissim/Downloads/spatial/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13.tif\",\n    chunks={\"x\": 1024, \"y\": 1024},  # Adjust chunk size based on your memory constraints\n)\n\nghsl = ghsl.rio.reproject(dst_crs=USE_CRS)\n\n\nghsl_clipped = ghsl.rio.clip(\n    [la_plata.geometry.iloc[0]],\n    from_disk=True,  # Process from disk to avoid loading entire dataset into memory\n)\n\n\n\n\nMostrar código\nfig2, ax2 = create_consistent_map(\"Datos de población GHSL\", common_bounds)\n\nghsl_masked = ma.masked_where(ghsl_clipped.values[0] == 0, ghsl_clipped.values[0])\n\nghsl_valid = (ghsl_clipped.values[0] != -200) & (ghsl_clipped.values[0] != 0)\nghsl_valid_data = ghsl_clipped.values[0][ghsl_valid]\n\nplasma_cmap = plt.cm.plasma\n\nghsl_clipped_3857 = ghsl_clipped.rio.reproject(\"EPSG:3857\")\n\n# Mask out zeros AND nodata values\nghsl_masked_3857 = ma.masked_where(\n    (ghsl_clipped_3857.values[0] == 0) | (ghsl_clipped_3857.values[0] == -200),\n    ghsl_clipped_3857.values[0],\n)\n\nim = ax2.imshow(\n    ghsl_masked_3857,\n    extent=[\n        ghsl_clipped_3857.x.min(),\n        ghsl_clipped_3857.x.max(),\n        ghsl_clipped_3857.y.min(),\n        ghsl_clipped_3857.y.max(),\n    ],\n    cmap=plasma_cmap,\n    alpha=0.75,\n)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n3.4.3 Google-Microsoft-OSM Open Buildings\nLos datos de Google-Microsoft-OSM Open Buildings - combined by VIDA (VIDA 2023) representan una forma más precisa de evaluar dónde se ubican los asentamientos humanos. Este conjunto de datos combina Google’s V3 Open Buildings, Microsoft’s GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo más de 2.7 mil millones de huellas de edificios. Estos datos han sido exitosamente aplicados a evaluaciones de riesgo de inundación por empresas globales de riesgo financiero como ICE, demostrando su utilidad para mapear la exposición climática a nivel de huella de edificio individual. Sin embargo, en ausencia de información sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el número total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de dónde se ubican las personas, sin tener una comprensión precisa de quién vive realmente allí y cuántas personas.\n\n\nMostrar código\ndef fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n\n    # Get S2 cell and bounds\n    center = geodataframe.to_crs(\"epsg:3857\").union_all().centroid\n    center_wgs84 = (\n        gpd.GeoDataFrame(geometry=[center], crs=\"EPSG:3857\")\n        .to_crs(epsg=4326)\n        .geometry.iloc[0]\n    )\n    cell = s2sphere.CellId.from_lat_lng(\n        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n    ).parent(10)\n    bounds = geodataframe.to_crs(\"epsg:4326\").total_bounds\n\n    # Find matching S2 partition\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=\"https://data.source.coop\",\n        aws_access_key_id=\"\",\n        aws_secret_access_key=\"\",\n        config=Config(s3={\"addressing_style\": \"path\"}),\n    )\n\n    partitions = {\n        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n        for obj in s3.list_objects_v2(\n            Bucket=\"vida\",\n            Prefix=\"google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n        ).get(\"Contents\", [])\n    }\n\n    parent_id = next(\n        str(cell.parent(level).id())\n        for level in range(10, 0, -1)\n        if str(cell.parent(level).id()) in partitions\n    )\n\n    # Setup DuckDB and query\n    con = duckdb.connect()\n    for cmd in [\n        \"INSTALL spatial\",\n        \"LOAD spatial\",\n        \"INSTALL httpfs\",\n        \"LOAD httpfs\",\n        \"SET s3_region='us-east-1'\",\n        \"SET s3_endpoint='data.source.coop'\",\n        \"SET s3_use_ssl=true\",\n        \"SET s3_url_style='path'\",\n    ]:\n        con.execute(cmd)\n\n    # Export and read back\n    query = f\"\"\"\n    COPY (SELECT * FROM 's3://vida/google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n          WHERE bbox.xmax &gt;= {bounds[0]} AND bbox.xmin &lt;= {bounds[2]} AND\n                bbox.ymax &gt;= {bounds[1]} AND bbox.ymin &lt;= {bounds[3]}\n    ) TO '{temp_file}' (FORMAT PARQUET);\n    \"\"\"\n\n    con.execute(query)\n    df = pd.read_parquet(temp_file)\n    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n\n    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n\n\n\nbuildings_file = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/buildings_filtered.parquet\"\n\nif os.path.exists(buildings_file):\n    buildings = gpd.read_parquet(buildings_file)\nelse:\n    buildings = fetch_buildings(renabap_pba_intersect)\n\n\nbuildings_proj = buildings.to_crs(USE_CRS)\n\nbuildings_proj = buildings_proj.clip(la_plata)\n\n\n\n\nMostrar código\nfig3, ax3 = create_consistent_map(\"Huellas de edificios\", common_bounds)\n\nbuildings_3857 = buildings_proj.to_crs(\"EPSG:3857\")\n\nbuildings_3857.plot(ax=ax3, facecolor=\"grey\", edgecolor=\"none\", alpha=0.7)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#metodología-y-procesamiento",
    "href": "renabap.html#metodología-y-procesamiento",
    "title": "3  RENABAP",
    "section": "3.5 Metodología y procesamiento",
    "text": "3.5 Metodología y procesamiento\n\n3.5.1 Interpolación por area\nLa interpolación areal es un método simple en el que las variables de los datos fuente se ponderan según la superposición entre polígonos fuente y objetivo, luego se reagregan para ajustarse a las geometrías de los polígonos objetivo. En nuestro análisis, esto significa distribuir proporcionalmente la población de cada barrio popular según el área de intersección con diferentes niveles de peligro de inundación. El analasis original de la exposición poblacional a peligros de inundación en la región del Partido de La Plata se realizó utilizando este método.\n\n\nMostrar código\nif renabap_pba_intersect.crs != peligro.crs:\n    peligro = peligro.to_crs(renabap_pba_intersect.crs)\n\nhazard_levels = peligro[\"PELIGROSID\"].unique()\n\nrenabap_with_porciones = renabap_pba_intersect.copy()\nfor level in hazard_levels:\n    renabap_with_porciones[f\"porcion_{level}\"] = 0.0\n\nrenabap_with_porciones[\"total_area\"] = renabap_with_porciones.geometry.area\n\nfor idx, barrio in renabap_with_porciones.iterrows():\n    barrio_geom = barrio.geometry\n    barrio_total_area = barrio_geom.area\n\n    if barrio_total_area == 0:\n        continue\n\n    for level in hazard_levels:\n        hazard_subset = peligro[peligro[\"PELIGROSID\"] == level]\n\n        if hazard_subset.empty:\n            continue\n\n        intersection_area = 0\n        for _, hazard_row in hazard_subset.iterrows():\n            try:\n                intersection = barrio_geom.intersection(hazard_row.geometry)\n                if not intersection.is_empty:\n                    intersection_area += intersection.area\n            except Exception as e:\n                print(\n                    f\"Error calculating intersection for {barrio.get('nombre_barrio', idx)}: {e}\"\n                )\n                continue\n\n        proportion = (\n            intersection_area / barrio_total_area if barrio_total_area &gt; 0 else 0\n        )\n        renabap_with_porciones.at[idx, f\"porcion_{level}\"] = proportion\n\n# Create barrio tidy format - only include hazard exposures &gt; 0\nbarrio_areal_tidy = []\nfor idx, row in renabap_with_porciones.iterrows():\n    # Add hazard exposures only if &gt; 0\n    for level in hazard_levels:\n        familias_expuestas = row[f\"porcion_{level}\"] * row[\"familias_aproximadas\"]\n        if familias_expuestas &gt; 0:\n            barrio_areal_tidy.append(\n                {\n                    \"id_renabap\": row[\"id_renabap\"],\n                    \"peligrosidad\": level,\n                    \"fam_expuestas_areal\": familias_expuestas,\n                }\n            )\n\nbarrio_areal_tidy = pd.DataFrame(barrio_areal_tidy)\n\n# 2. CUENCA AREAL EXPOSURE - aggregate from barrio level, avoiding double counting\n# Get the cuenca for each settlement - but handle settlements that cross cuenca boundaries\nsettlement_cuenca_mapping = settle_hazard_cuencas[\n    [\"id_renabap\", \"Cuenca\"]\n].drop_duplicates()\n\n# Check if any settlements appear in multiple cuencas\nsettlement_counts = settlement_cuenca_mapping[\"id_renabap\"].value_counts()\nmulti_cuenca_settlements = settlement_counts[settlement_counts &gt; 1].index\n\nif len(multi_cuenca_settlements) &gt; 0:\n    # For settlements in multiple cuencas, assign to the cuenca with largest intersection\n    # For now, just take the first occurrence\n    settlement_cuenca_mapping = settlement_cuenca_mapping.drop_duplicates(\n        subset=[\"id_renabap\"], keep=\"first\"\n    )\n\ncuenca_areal_tidy = barrio_areal_tidy[\n    barrio_areal_tidy[\"peligrosidad\"] != \"none\"\n].merge(settlement_cuenca_mapping, on=\"id_renabap\", how=\"left\")\ncuenca_areal_tidy = (\n    cuenca_areal_tidy.groupby([\"Cuenca\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n# 3. EJE AREAL EXPOSURE - same fix\ncuenca_eje_mapping = settle_hazard_cuencas[[\"Cuenca\", \"eje\"]].drop_duplicates()\n\neje_areal_tidy = cuenca_areal_tidy.merge(cuenca_eje_mapping, on=\"Cuenca\")\neje_areal_tidy = (\n    eje_areal_tidy.groupby([\"eje\", \"peligrosidad\"])[\"fam_expuestas_areal\"]\n    .sum()\n    .reset_index()\n)\n\n\n\n\n3.5.2 Cuenta de edificios\n\n\n3.5.3 Mapeo dasymetrico\nEl mapeo dasimétrico reorganiza datos cartográficos de una unidad de recolección en áreas más precisas, modificando los límites originales usando datos de apoyo relacionados. Por ejemplo, un atributo de población organizado por tracto censal se vuelve más significativo cuando se eliminan áreas donde es razonable inferir que la gente no vive (cuerpos de agua, terrenos vacíos). En nuestro caso, utilizamos datos GHSL y huellas de edificios como información auxiliar para mejorar la precisión de las estimaciones de distribución poblacional.\n\n3.5.3.1 Mapeo dasymetrico con datos de edificios\n\n\nMostrar código\n# Get ALL buildings per settlement (not just hazard-intersected ones)\nbuildings_settlement = gpd.overlay(\n    buildings_proj, renabap_pba_intersect, how=\"intersection\"\n)\ntotal_buildings_per_settlement = (\n    buildings_settlement.groupby(\"id_renabap\")\n    .size()\n    .reset_index(name=\"total_buildings\")\n)\n\n# Get buildings intersected with hazard zones\nbuildings_hazard = gpd.overlay(\n    buildings_proj, settle_hazard_cuencas, how=\"intersection\"\n)\n\n# 1. Buildings per barrio-hazard (including non-hazard areas)\nbuildings_barrio_hazard = (\n    buildings_hazard.groupby([\"id_renabap\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\n\n# Calculate ratios using TOTAL buildings per settlement (not just hazard buildings)\nbarrio_ratios = buildings_barrio_hazard.merge(\n    total_buildings_per_settlement, on=\"id_renabap\"\n)\nbarrio_ratios[\"ratio\"] = (\n    barrio_ratios[\"buildings_count\"] / barrio_ratios[\"total_buildings\"]\n)\nbarrio_pop = renabap_pba_intersect[\n    [\"id_renabap\", \"familias_aproximadas\"]\n].drop_duplicates()\nbarrio_exposure = barrio_ratios.merge(barrio_pop, on=\"id_renabap\")\nbarrio_exposure[\"fam_expuestas\"] = (\n    barrio_exposure[\"ratio\"] * barrio_exposure[\"familias_aproximadas\"]\n)\n\n# Add non-hazard population for each settlement\nsettlements_with_hazards = barrio_exposure[\"id_renabap\"].unique()\nall_settlements = total_buildings_per_settlement[\"id_renabap\"].unique()\n\nfor settlement in all_settlements:\n    if settlement in settlements_with_hazards:\n        # Calculate non-hazard population\n        hazard_pop = barrio_exposure[barrio_exposure[\"id_renabap\"] == settlement][\n            \"fam_expuestas\"\n        ].sum()\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        non_hazard_pop = total_pop - hazard_pop\n\n        if non_hazard_pop &gt; 0:\n            barrio_exposure = pd.concat(\n                [\n                    barrio_exposure,\n                    pd.DataFrame(\n                        [\n                            {\n                                \"id_renabap\": settlement,\n                                \"PELIGROSID\": \"none\",\n                                \"buildings_count\": 0,\n                                \"total_buildings\": total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0],\n                                \"ratio\": (\n                                    total_buildings_per_settlement[\n                                        total_buildings_per_settlement[\"id_renabap\"]\n                                        == settlement\n                                    ][\"total_buildings\"].iloc[0]\n                                    - buildings_hazard[\n                                        buildings_hazard[\"id_renabap\"] == settlement\n                                    ].shape[0]\n                                )\n                                / total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                if total_buildings_per_settlement[\n                                    total_buildings_per_settlement[\"id_renabap\"]\n                                    == settlement\n                                ][\"total_buildings\"].iloc[0]\n                                &gt; 0\n                                else 0,\n                                \"familias_aproximadas\": total_pop,\n                                \"fam_expuestas\": non_hazard_pop,\n                            }\n                        ]\n                    ),\n                ],\n                ignore_index=True,\n            )\n    else:\n        # Settlement with no hazard intersection - all population is non-hazard\n        total_pop = barrio_pop[barrio_pop[\"id_renabap\"] == settlement][\n            \"familias_aproximadas\"\n        ].iloc[0]\n        barrio_exposure = pd.concat(\n            [\n                barrio_exposure,\n                pd.DataFrame(\n                    [\n                        {\n                            \"id_renabap\": settlement,\n                            \"PELIGROSID\": \"none\",\n                            \"buildings_count\": 0,\n                            \"total_buildings\": total_buildings_per_settlement[\n                                total_buildings_per_settlement[\"id_renabap\"]\n                                == settlement\n                            ][\"total_buildings\"].iloc[0],\n                            \"ratio\": 1.0,\n                            \"familias_aproximadas\": total_pop,\n                            \"fam_expuestas\": total_pop,\n                        }\n                    ]\n                ),\n            ],\n            ignore_index=True,\n        )\n\n# Create buildings tidy dataframe for barrio level\nbuildings_barrio_tidy = barrio_exposure[\n    [\"id_renabap\", \"PELIGROSID\", \"fam_expuestas\"]\n].copy()\nbuildings_barrio_tidy = buildings_barrio_tidy.rename(\n    columns={\"PELIGROSID\": \"peligrosidad\", \"fam_expuestas\": \"fam_expuestas_buildings\"}\n)\n\n# 2. Cuenca exposure - using total buildings across all settlements in cuenca\nbuildings_cuenca_hazard = (\n    buildings_hazard.groupby([\"Cuenca\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_cuenca_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"Cuenca\"]].drop_duplicates(),\n        on=\"id_renabap\",\n    )\n    .groupby(\"Cuenca\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\ncuenca_ratios = buildings_cuenca_hazard.merge(buildings_cuenca_total, on=\"Cuenca\")\ncuenca_ratios[\"ratio\"] = (\n    cuenca_ratios[\"buildings_count\"] / cuenca_ratios[\"total_buildings_all\"]\n)\n\ncuenca_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"Cuenca\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\ncuenca_exposure = cuenca_ratios.merge(cuenca_pop, on=\"Cuenca\")\ncuenca_exposure[\"fam_expuestas\"] = (\n    cuenca_exposure[\"ratio\"] * cuenca_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for cuenca level\nbuildings_cuenca_tidy = cuenca_exposure[\n    [\"Cuenca\", \"PELIGROSID\", \"fam_expuestas\"]\n].copy()\nbuildings_cuenca_tidy = buildings_cuenca_tidy.rename(\n    columns={\"PELIGROSID\": \"peligrosidad\", \"fam_expuestas\": \"fam_expuestas_buildings\"}\n)\n\n# 3. Eje exposure - using total buildings across all settlements in eje\nbuildings_eje_hazard = (\n    buildings_hazard.groupby([\"eje\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\nbuildings_eje_total = (\n    buildings_settlement.merge(\n        settle_hazard_cuencas[[\"id_renabap\", \"eje\"]].drop_duplicates(), on=\"id_renabap\"\n    )\n    .groupby(\"eje\")\n    .size()\n    .reset_index(name=\"total_buildings_all\")\n)\n\neje_ratios = buildings_eje_hazard.merge(buildings_eje_total, on=\"eje\")\neje_ratios[\"ratio\"] = eje_ratios[\"buildings_count\"] / eje_ratios[\"total_buildings_all\"]\n\neje_pop = (\n    settle_hazard_cuencas.drop_duplicates(\"id_renabap\")\n    .groupby(\"eje\")[\"familias_aproximadas\"]\n    .sum()\n    .reset_index()\n)\neje_exposure = eje_ratios.merge(eje_pop, on=\"eje\")\neje_exposure[\"fam_expuestas\"] = (\n    eje_exposure[\"ratio\"] * eje_exposure[\"familias_aproximadas\"]\n)\n\n# Create buildings tidy dataframe for eje level\nbuildings_eje_tidy = eje_exposure[[\"eje\", \"PELIGROSID\", \"fam_expuestas\"]].copy()\nbuildings_eje_tidy = buildings_eje_tidy.rename(\n    columns={\"PELIGROSID\": \"peligrosidad\", \"fam_expuestas\": \"fam_expuestas_buildings\"}\n)\n\n\n\n\n3.5.3.2 Mapeo dasymetrico con datos GHSL\n\n\nMostrar código\n# Step 1: Calculate the total GHSL population per barrio popular using zonal statistics\n\n# Convert to the format expected by rasterstats\ngeometries = [geom for geom in renabap_pba_intersect.geometry]\n\n# Use rasterstats for vectorized zonal statistics\nstats = rasterstats.zonal_stats(\n    geometries,\n    ghsl_clipped.values[0],  # rasterstats expects 2D array\n    affine=ghsl_clipped.rio.transform(),\n    stats=[\"sum\"],\n    nodata=ghsl_clipped.rio.nodata,\n)\n\n# Extract the sum values\nghsl_totals = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n\n# Add the GHSL population estimates as a new column\nrenabap_pba_intersect[\"ghsl_pop_est\"] = ghsl_totals\n\n\n# Get the reference raster properties from GHSL data\nreference_raster = ghsl_clipped\nreference_transform = reference_raster.rio.transform()\nreference_crs = reference_raster.rio.crs\nreference_shape = reference_raster.shape[1:]  # Get 2D shape (height, width)\n\n\n# Prepare geometries and values for rasterization\ngeometries_ghsl = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"ghsl_pop_est\"]\n    )\n]\ngeometries_familias = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"familias_aproximadas\"]\n    )\n]\n\n# Create GHSL population raster\nghsl_pop_raster = rasterize(\n    geometries_ghsl,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Create familias aproximadas raster\nfamilias_raster = rasterize(\n    geometries_familias,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n\n# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n# Use masking to avoid division on invalid cells\nmask = (ghsl_clipped.values[0] != -200) & (ghsl_pop_raster &gt; 0.1)\nghsl_fractional = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n\n# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\nmask2 = (ghsl_fractional != -200) & (familias_raster &gt; 0)\nfamilias_downscaled = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nfamilias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n\n# Verify the results - exclude -200 from range calculations\nghsl_valid = ghsl_clipped.values[0] != -200\nfractional_valid = ghsl_fractional != -200\ndownscaled_valid = familias_downscaled != -200\n\n# GHSL downscaling for all three levels using the same approach\n\n# 1. BARRIO-HAZARD EXPOSURE (your existing approach)\nghsl_barrio_tidy = []\nfor idx, row in settlement_hazard.iterrows():\n    stats = zonal_stats(\n        [row.geometry],\n        familias_downscaled,\n        affine=reference_transform,\n        stats=[\"sum\"],\n        nodata=-200,\n    )[0]\n\n    ghsl_barrio_tidy.append(\n        {\n            \"id_renabap\": row[\"id_renabap\"],\n            \"peligrosidad\": row[\"PELIGROSID\"],\n            \"fam_expuestas_ghsl\": stats[\"sum\"] if stats[\"sum\"] is not None else 0,\n        }\n    )\n\nghsl_barrio_tidy = pd.DataFrame(ghsl_barrio_tidy)\n\n# 2. CUENCA-HAZARD EXPOSURE\nghsl_cuenca_tidy = []\nfor cuenca in settle_hazard_cuencas[\"Cuenca\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this cuenca-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"Cuenca\"] == cuenca)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=-200,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_cuenca_tidy.append(\n                {\n                    \"Cuenca\": cuenca,\n                    \"peligrosidad\": peligro,\n                    \"fam_expuestas_ghsl\": total_pop,\n                }\n            )\n\nghsl_cuenca_tidy = pd.DataFrame(ghsl_cuenca_tidy)\n\n# 3. EJE-HAZARD EXPOSURE\nghsl_eje_tidy = []\nfor eje in settle_hazard_cuencas[\"eje\"].unique():\n    for peligro in settle_hazard_cuencas[\"PELIGROSID\"].unique():\n        # Get all geometries for this eje-hazard combination\n        geoms = settle_hazard_cuencas[\n            (settle_hazard_cuencas[\"eje\"] == eje)\n            & (settle_hazard_cuencas[\"PELIGROSID\"] == peligro)\n        ].geometry.tolist()\n\n        if geoms:\n            stats = zonal_stats(\n                geoms,\n                familias_downscaled,\n                affine=reference_transform,\n                stats=[\"sum\"],\n                nodata=-200,\n            )\n\n            total_pop = sum(\n                [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n            )\n\n            ghsl_eje_tidy.append(\n                {\n                    \"eje\": eje,\n                    \"peligrosidad\": peligro,\n                    \"fam_expuestas_ghsl\": total_pop,\n                }\n            )\n\nghsl_eje_tidy = pd.DataFrame(ghsl_eje_tidy)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#objetivos",
    "href": "renabap.html#objetivos",
    "title": "3  RENABAP",
    "section": "3.2 Objetivos",
    "text": "3.2 Objetivos\nEl objetivo principal de este análisis es calcular con mayor precisión la exposición poblacional en la región del Partido de La Plata, comparando el enfoque actual de interpolación por área de datos del RENABAP con enfoques de mapeo dasimétrico de mayor resolución utilizando datos de la Capa Global de Asentamientos Humanos (GHSL) y el conjunto de datos de edificios abiertos de Google-Microsoft OpenStreetMap.\nPara lograr este objetivo, necesitamos:\n\nExplicar y comparar metodologías: Desarrollar una comprensión clara de las diferencias entre interpolación por área y mapeo dasimétrico\nEvaluar fuentes de datos: Analizar las ventajas y limitaciones de cada conjunto de datos utilizado\nCrear estimaciones robustas: Generar un rango de posibles exposiciones poblacionales para informar la toma de decisiones\nPriorizar recursos: Identificar áreas donde se requiera recopilación de datos más precisa",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  },
  {
    "objectID": "renabap.html#contexto",
    "href": "renabap.html#contexto",
    "title": "3  RENABAP",
    "section": "3.3 Contexto",
    "text": "3.3 Contexto\n\n\nMostrar código\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\nfrom io import BytesIO, StringIO\nfrom owslib.wfs import WebFeatureService\nfrom shapely.geometry import box\nimport geopandas as gpd\nimport requests\nimport pandas as pd\nimport os\n\nimport boto3\nimport duckdb\n\n\nimport numpy as np\nimport s2sphere\nfrom botocore.config import Config\nfrom rasterstats import zonal_stats\nimport rasterstats\nfrom rasterio.features import rasterize\nimport numpy.ma as ma\nfrom itables import show\nimport matplotlib.cm as cm\n\nimport seaborn as sns\nimport rioxarray\n\n\nUSE_CRS = \"EPSG:5349\"\n\n\n\ndef setup_base_map(figsize=(12, 10), bounds=None, padding_x=500, padding_y=500):\n    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n    if bounds is None:\n        bounds = renabap_pba_intersect.total_bounds\n\n    # Convert bounds to Web Mercator for basemap compatibility\n    if bounds is not None:\n        # Create a temporary GeoDataFrame with the bounds to reproject\n        temp_bounds = gpd.GeoDataFrame(\n            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS\n        )\n        bounds_3857 = temp_bounds.to_crs(\"EPSG:3857\").total_bounds\n    else:\n        bounds_3857 = bounds\n\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)\n    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)\n    return fig, ax\n\n\ndef add_basemap(ax, zoom=13):\n    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n\n    ctx.add_basemap(\n        ax,\n        source=ctx.providers.CartoDB.PositronNoLabels,\n        zorder=0,\n        zoom=zoom,\n    )\n\n    return ax\n\n\ndef add_north_arrow(ax, x=0.95, y=0.05, arrow_length=0.04):\n    \"\"\"Add a north arrow to the map.\"\"\"\n    # Add north arrow, https://stackoverflow.com/a/58110049/604456\n    ax.annotate(\n        \"N\",\n        xy=(x, y),\n        xytext=(x, y - arrow_length),\n        arrowprops=dict(facecolor=\"black\", width=3, headwidth=10),\n        ha=\"center\",\n        va=\"center\",\n        fontsize=14,\n        xycoords=ax.transAxes,\n    )\n\n\ndef add_la_plata_outline(ax):\n    \"\"\"Add the outline of Partido de La Plata to a map.\"\"\"\n    la_plata_3857 = la_plata.to_crs(\"EPSG:3857\")\n    la_plata_3857.plot(\n        ax=ax,\n        facecolor=\"none\",\n        edgecolor=\"black\",\n        linewidth=0.5,\n        linestyle=\"--\",\n        legend=False,\n        zorder=5,\n    )\n\n\ndef create_consistent_map(title, bounds=None):\n    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n    fig, ax = setup_base_map(bounds=bounds)\n\n\n    add_basemap(ax)\n\n\n    add_north_arrow(ax)\n\n    add_la_plata_outline(ax)\n\n    ax.set_title(title, fontsize=16, fontweight=\"bold\", pad=20)\n\n    ax.set_axis_off()\n\n    return fig, ax\n\n\ndef wfs_to_gdf(\n    wfs_url: str, layer_name: str, srs: str = \"EPSG:4326\"\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Descarga una capa WFS y la devuelve como GeoDataFrame.\n\n    Args:\n        wfs_url (str): URL del servicio WFS.\n        layer_name (str): Nombre de la capa (typename).\n        srs (str): Código EPSG del sistema de referencia de coordenadas.\n\n    Returns:\n        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.\n    \"\"\"\n    wfs = WebFeatureService(url=wfs_url, version=\"2.0.0\")\n    response = wfs.getfeature(typename=layer_name, srsname=srs)\n    gdf = gpd.read_file(BytesIO(response.read()))\n    return gdf\n\n\n\n\nMostrar código\nresponse = requests.get(\n    \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\n)\nrenabap = gpd.read_file(StringIO(response.text))\nrenabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\nrenabap_pba = renabap_pba.to_crs(USE_CRS)\n\npeligro_path = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/la_plata_pelig_2023_datos_originales.geojson\"\npeligro = gpd.read_file(peligro_path)\npeligro = peligro.to_crs(USE_CRS)\n\npeligro_bounds = peligro.total_bounds\npeligro_bbox = box(*peligro_bounds)\n\npartidos_file_path = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/pba_partidos.geojson\"\n\nif os.path.exists(partidos_file_path):\n    partidos = gpd.read_file(partidos_file_path)\nelse:\n    partidos = wfs_to_gdf(\n        wfs_url=\"https://geo.arba.gov.ar/geoserver/idera/wfs\",\n        layer_name=\"idera:Departamento\",\n        srs=\"EPSG:5347\",\n    )\n\n    partidos.to_file(partidos_file_path, driver=\"GeoJSON\")\n\npartidos = partidos.to_crs(USE_CRS)\nla_plata = partidos[partidos[\"fna\"] == \"Partido de La Plata\"]\n\n# Obtener la geometría principal\nmain_geom = la_plata.geometry.iloc[0]\n\n# Si es un MultiPolygon, mantener solo el polígono más grande (el partido principal)\n# Esto elimina la pequeña isla que aparece en los datos\nif main_geom.geom_type == \"MultiPolygon\":\n    # Obtener todos los polígonos y mantener el que tenga mayor área\n    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)\n    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning\n    la_plata.loc[la_plata.index[0], \"geometry\"] = largest_polygon\n\nla_plata_bbox = la_plata.geometry.iloc[0]\n\nrenabap_pba_intersect = renabap_pba[\n    renabap_pba.geometry.intersects(la_plata_bbox)\n].copy()\n\n\ncuencas_file_path = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/cuencas_buenos_aires.geojson\"\n\nif os.path.exists(cuencas_file_path):\n    cuencas = gpd.read_file(cuencas_file_path)\nelse:\n    cuencas_url = \"https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query\"\n    params = {\"where\": \"1=1\", \"outFields\": \"*\", \"f\": \"geojson\"}\n\n    cuencas_response = requests.get(cuencas_url, params=params)\n    with open(cuencas_file_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(cuencas_response.text)\n\n    cuencas = gpd.read_file(StringIO(cuencas_response.text))\n\ncuencas = cuencas.to_crs(USE_CRS)\ncuencas = cuencas.clip(la_plata)\n\neje_mapping = {\n    \"noreste\": [\"Area de Bañados\", \"Cuenca Arroyo Rodriguez-Don Carlos\"],\n    \"noroeste\": [\"Cuenca Arroyo Martín-Carnaval\", \"Cuenca Arroyo Pereyra\"],\n    \"central\": [\"Cuenca Arroyo del Gato\"],\n    \"sudoeste\": [\"Cuenca A° Maldonado\", \"Cuenca Río Samborombón\"],\n    \"sudeste\": [\"Cuenca Arroyo El Pescado\"],\n}\n\n# Map watershed names to axes based on the eje_mapping\ncuencas[\"eje\"] = (\n    cuencas[\"Cuenca\"]\n    .map(\n        {\n            cuenca: eje\n            for eje, cuencas_list in eje_mapping.items()\n            for cuenca in cuencas_list\n        }\n    )\n    .fillna(\"otro\")\n)\n\n# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)\nrenabap_total_area_ha = (\n    renabap_pba_intersect.geometry.area.sum() / 10000\n)  # Convert m² to hectares\nla_plata_area_ha = la_plata.geometry.iloc[0].area / 10000\npercentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100\n\n# Get common bounds for all maps\ncommon_bounds = la_plata.total_bounds\n\n# Intersect settlements with hazard zones\nsettlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n\nsettle_hazard_cuencas = gpd.overlay(\n    settlement_hazard, cuencas, how=\"intersection\", keep_geom_type=True\n)\n\n\nHay un total de 166 barrios populares en el Partido de La Plata, que representan np.int64(33888) familias. Estos barrios ocupan np.float64(1760.927308165013) hectáreas del Partido de La Plata, o np.float64(1.9638325015304627) por ciento del partido.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RENABAP</span>"
    ]
  }
]