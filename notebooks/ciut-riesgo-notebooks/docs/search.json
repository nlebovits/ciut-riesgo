[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CIUT Riesgo Análisis",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "renabap.html",
    "href": "renabap.html",
    "title": "3  Riesgo hídrico en barrios populares",
    "section": "",
    "text": "3.1 Resumen Ejecutivo",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Riesgo hídrico en barrios populares</span>"
    ]
  },
  {
    "objectID": "renabap.html#motivos-y-objetivos",
    "href": "renabap.html#motivos-y-objetivos",
    "title": "3  Riesgo hídrico en barrios populares",
    "section": "3.2 Motivos y Objetivos",
    "text": "3.2 Motivos y Objetivos",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Riesgo hídrico en barrios populares</span>"
    ]
  },
  {
    "objectID": "renabap.html#datos-metodología-y-limitaciones",
    "href": "renabap.html#datos-metodología-y-limitaciones",
    "title": "3  Riesgo hídrico en barrios populares",
    "section": "3.3 Datos, Metodología y Limitaciones",
    "text": "3.3 Datos, Metodología y Limitaciones",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Riesgo hídrico en barrios populares</span>"
    ]
  },
  {
    "objectID": "renabap.html#resultados",
    "href": "renabap.html#resultados",
    "title": "3  Riesgo hídrico en barrios populares",
    "section": "3.4 Resultados",
    "text": "3.4 Resultados\n\n\nMostrar el código\nimport pandas as pd\nimport geopandas as gpd\nimport requests\nfrom io import StringIO\n\nimport boto3\nimport duckdb\n\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport s2sphere\nfrom botocore.config import Config\nfrom rasterstats import zonal_stats\n\n\nfrom shapely.geometry import box\n\nUSE_CRS = \"EPSG:5349\"\n\n\n\n\nMostrar el código\nresponse = requests.get(\n    \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\n)\nrenabap = gpd.read_file(StringIO(response.text))\nrenabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\nrenabap_pba = renabap_pba.to_crs(USE_CRS)\n\n\npeligro_path = \"/home/nissim/Documents/dev/ciut-inundaciones/data/la_plata_pelig_2023_datos_originales.geojson\"\npeligro = gpd.read_file(peligro_path)\npeligro = peligro.to_crs(USE_CRS)\n\n# Get the bounds of the peligro layer\npeligro_bounds = peligro.total_bounds\npeligro_bbox = box(*peligro_bounds)\n\n# Filter renabap_pba to only include geometries that intersect with the peligro bounds\nrenabap_pba_intersect = renabap_pba[\n    renabap_pba.geometry.intersects(peligro_bbox)\n].copy()\n\n# make sure all geometries are valid\nrenabap_pba_intersect = renabap_pba_intersect[renabap_pba_intersect.geometry.is_valid]\n\n\n\n3.4.1 Interpolación areal\n\n\nMostrar el código\nimport geopandas as gpd\nfrom tobler.area_weighted import area_interpolate\n\n# Ensure both GeoDataFrames have the same CRS\nif renabap_pba_intersect.crs != peligro.crs:\n    peligro = peligro.to_crs(renabap_pba_intersect.crs)\n\n# Get unique hazard levels\nhazard_levels = peligro[\"PELIGROSID\"].unique()\n\n# Initialize output columns in renabap_pba_intersect\nfor level in hazard_levels:\n    renabap_pba_intersect[f\"porcion_{level}\"] = 0.0\n\n# For each hazard level, calculate the portion of each barrio that falls within it\nfor level in hazard_levels:\n    # Filter hazard polygons for this level\n    hazard_subset = peligro[peligro[\"PELIGROSID\"] == level].copy()\n\n    if not hazard_subset.empty:\n        # Add dummy variable with value 1 for each hazard polygon\n        hazard_subset[\"hazard_area\"] = 1\n\n        # Interpolate hazard area to barrios (this gives us the proportion)\n        results = area_interpolate(\n            source_df=hazard_subset,\n            target_df=renabap_pba_intersect,\n            extensive_variables=[\"hazard_area\"],\n        )\n\n        # This gives us the portion of each barrio that overlaps with this hazard level\n        renabap_pba_intersect[f\"porcion_{level}\"] = results[\"hazard_area\"]\n\n# Calculate families exposed to each hazard level\nfor level in hazard_levels:\n    renabap_pba_intersect[f\"familias_expuestas_{level}\"] = (\n        renabap_pba_intersect[f\"porcion_{level}\"]\n        * renabap_pba_intersect[\"familias_aproximadas\"]\n    )\n\n# Create tidy dataframe with the three required columns\nrenabap_tidy = renabap_pba_intersect[[\"nombre_barrio\"]].copy()\n\n# Calculate total familias_expuestas\nrenabap_tidy[\"fam_expuestas_areal\"] = (\n    renabap_pba_intersect[\"familias_expuestas_alta\"]\n    + renabap_pba_intersect[\"familias_expuestas_baja\"]\n    + renabap_pba_intersect[\"familias_expuestas_media\"]\n)\n\n# Determine highest hazard level (peligrosidad)\ndef get_highest_hazard(row):\n    exposures = [\n        row[\"familias_expuestas_alta\"],\n        row[\"familias_expuestas_baja\"],\n        row[\"familias_expuestas_media\"],\n    ]\n    hazard_levels = [\"alta\", \"baja\", \"media\"]\n    return hazard_levels[exposures.index(max(exposures))]\n\nrenabap_tidy[\"peligrosidad\"] = renabap_pba_intersect.apply(get_highest_hazard, axis=1)\n\n# Round fam_expuestas_areal\nrenabap_tidy[\"fam_expuestas_areal\"] = renabap_tidy[\"fam_expuestas_areal\"].round(2)\n\n\n\n\n3.4.2 Mapeo dasymetrico con datos GHSL\n\n\nMostrar el código\nimport rasterstats\nimport rioxarray\nfrom shapely.geometry import box\n\n# Load GHSL data with dask chunking for memory efficiency\nghsl = rioxarray.open_rasterio(\n    \"/home/nissim/Downloads/spatial/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13.tif\",\n    chunks={\"x\": 1024, \"y\": 1024},  # Adjust chunk size based on your memory constraints\n)\n\n# Reproject to your target CRS with streaming\nghsl = ghsl.rio.reproject(dst_crs=USE_CRS)\n\n# Clip to renabap_pba_intersect bounding box using streaming\nbounding_box = box(\n    *renabap_pba_intersect.total_bounds\n)  # Create a box from the bounding box coordinates\n\nghsl_clipped = ghsl.rio.clip(\n    [bounding_box],  # Use the bounding box as a geometry (wrapped in a list)\n    from_disk=True,  # Process from disk to avoid loading entire dataset into memory\n)\n\n\n# Convert to the format expected by rasterstats\ngeometries = [geom for geom in renabap_pba_intersect.geometry]\n\n# Use rasterstats for vectorized zonal statistics\nstats = rasterstats.zonal_stats(\n    geometries,\n    ghsl_clipped.values[0],  # rasterstats expects 2D array\n    affine=ghsl_clipped.rio.transform(),\n    stats=[\"sum\"],\n    nodata=ghsl_clipped.rio.nodata,\n)\n\n# Extract the sum values\nghsl_totals = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n\n# Add the GHSL population estimates as a new column\nrenabap_pba_intersect[\"ghsl_pop_est\"] = ghsl_totals\n\n\nfrom rasterio.features import rasterize\nimport numpy as np\n\n# Get the reference raster properties from GHSL data\nreference_raster = ghsl_clipped\nreference_transform = reference_raster.rio.transform()\nreference_crs = reference_raster.rio.crs\nreference_shape = reference_raster.shape[1:]  # Get 2D shape (height, width)\n\n# Prepare geometries and values for rasterization\ngeometries_ghsl = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"ghsl_pop_est\"]\n    )\n]\ngeometries_familias = [\n    (geom, value)\n    for geom, value in zip(\n        renabap_pba_intersect.geometry, renabap_pba_intersect[\"familias_aproximadas\"]\n    )\n]\n\n# Create GHSL population raster\nghsl_pop_raster = rasterize(\n    geometries_ghsl,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Create familias aproximadas raster\nfamilias_raster = rasterize(\n    geometries_familias,\n    out_shape=reference_shape,\n    transform=reference_transform,\n    fill=0,\n    dtype=np.float32,\n    all_touched=False,\n)\n\n# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n# Handle division by zero and nodata values properly\nmask = (ghsl_clipped.values[0] &gt; 0) & (ghsl_pop_raster &gt; 0.1)\nghsl_fractional = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n\n# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\nmask2 = (ghsl_fractional &gt; 0) & (familias_raster &gt; 0)\nfamilias_downscaled = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nfamilias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n\n\n# Check that the sum of downscaled familias equals the original familias aproximadas\ntotal_original_familias = renabap_pba_intersect[\"familias_aproximadas\"].sum()\nvalid_downscaled = familias_downscaled[familias_downscaled != -200]\ntotal_downscaled_familias = np.sum(valid_downscaled)\n\n\n# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n# Use masking to avoid division on invalid cells\nmask = (ghsl_clipped.values[0] != -200) & (ghsl_pop_raster &gt; 0.1)\nghsl_fractional = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n\n# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\nmask2 = (ghsl_fractional != -200) & (familias_raster &gt; 0)\nfamilias_downscaled = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\nfamilias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n\n# Verify the results - exclude -200 from range calculations\nghsl_valid = ghsl_clipped.values[0] != -200\nfractional_valid = ghsl_fractional != -200\ndownscaled_valid = familias_downscaled != -200\n\n# Check that the sum of downscaled familias equals the original familias aproximadas\ntotal_original_familias = renabap_pba_intersect[\"familias_aproximadas\"].sum()\ntotal_downscaled_familias = np.sum(familias_downscaled[downscaled_valid])\nprint(f\"\\nTotal original familias: {total_original_familias:,.0f}\")\nprint(f\"Total downscaled familias: {total_downscaled_familias:,.0f}\")\nprint(f\"Difference: {abs(total_original_familias - total_downscaled_familias):,.2f}\")\n\n# Intersect settlements with hazard zones\nsettlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n\n# Create GHSL tidy dataframe with matching structure\nghsl_tidy = []\n\nfor idx, row in settlement_hazard.iterrows():\n    stats = zonal_stats(\n        [row.geometry],\n        familias_downscaled,  # your numpy array\n        affine=reference_transform,  # get transform from your xarray\n        stats=[\"sum\"],\n        nodata=-200,  # use your actual nodata value\n    )[0]\n\n    ghsl_tidy.append(\n        {\n            \"nombre_barrio\": row[\"nombre_barrio\"],\n            \"peligrosidad\": row[\"PELIGROSID\"],\n            \"fam_expuestas_ghsl\": stats[\"sum\"] if stats[\"sum\"] is not None else 0,\n        }\n    )\n\nghsl_tidy = pd.DataFrame(ghsl_tidy)\n\n\n\nTotal original familias: 88,856\nTotal downscaled familias: 88,680\nDifference: 176.00\n\n\n\n\n3.4.3 Estimaciones según cantidad de edificios\n\n\nMostrar el código\ndef fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n\n    # Get S2 cell and bounds\n    center = geodataframe.to_crs(\"epsg:3857\").union_all().centroid\n    center_wgs84 = (\n        gpd.GeoDataFrame(geometry=[center], crs=\"EPSG:3857\")\n        .to_crs(epsg=4326)\n        .geometry.iloc[0]\n    )\n    cell = s2sphere.CellId.from_lat_lng(\n        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n    ).parent(10)\n    bounds = geodataframe.to_crs(\"epsg:4326\").total_bounds\n\n    # Find matching S2 partition\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=\"https://data.source.coop\",\n        aws_access_key_id=\"\",\n        aws_secret_access_key=\"\",\n        config=Config(s3={\"addressing_style\": \"path\"}),\n    )\n\n    partitions = {\n        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n        for obj in s3.list_objects_v2(\n            Bucket=\"vida\",\n            Prefix=\"google-microsoft-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n        ).get(\"Contents\", [])\n    }\n\n    parent_id = next(\n        str(cell.parent(level).id())\n        for level in range(10, 0, -1)\n        if str(cell.parent(level).id()) in partitions\n    )\n\n    # Setup DuckDB and query\n    con = duckdb.connect()\n    for cmd in [\n        \"INSTALL spatial\",\n        \"LOAD spatial\",\n        \"INSTALL httpfs\",\n        \"LOAD httpfs\",\n        \"SET s3_region='us-east-1'\",\n        \"SET s3_endpoint='data.source.coop'\",\n        \"SET s3_use_ssl=true\",\n        \"SET s3_url_style='path'\",\n    ]:\n        con.execute(cmd)\n\n    # Export and read back\n    query = f\"\"\"\n    COPY (SELECT * FROM 's3://vida/google-microsoft-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n          WHERE bbox.xmax &gt;= {bounds[0]} AND bbox.xmin &lt;= {bounds[2]} AND\n                bbox.ymax &gt;= {bounds[1]} AND bbox.ymin &lt;= {bounds[3]}\n    ) TO '{temp_file}' (FORMAT PARQUET);\n    \"\"\"\n\n    con.execute(query)\n    df = pd.read_parquet(temp_file)\n    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n\n    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n\n\n# Usage:\nbuildings = fetch_buildings(renabap_pba_intersect)\n\n# Reproject buildings to match the analysis CRS\nbuildings_proj = buildings.to_crs(USE_CRS)\n\n# Step 1: Calculate buildings per settlement-hazard intersection\nbuildings_hazard = gpd.overlay(buildings_proj, settlement_hazard, how=\"intersection\")\n\n# Count buildings per settlement-hazard combination\nbuildings_per_hazard = (\n    buildings_hazard.groupby([\"nombre_barrio\", \"PELIGROSID\"])\n    .size()\n    .reset_index(name=\"buildings_count\")\n)\n\n# Step 2: Calculate total buildings per settlement (barrio popular)\nbuildings_settlement = gpd.overlay(\n    buildings_proj, renabap_pba_intersect, how=\"intersection\"\n)\ntotal_buildings_per_settlement = (\n    buildings_settlement.groupby(\"nombre_barrio\")\n    .size()\n    .reset_index(name=\"total_buildings\")\n)\n\n# Step 3: Merge and calculate ratios\nhazard_ratios = buildings_per_hazard.merge(\n    total_buildings_per_settlement, on=\"nombre_barrio\", how=\"left\"\n)\nhazard_ratios[\"building_ratio\"] = (\n    hazard_ratios[\"buildings_count\"] / hazard_ratios[\"total_buildings\"]\n)\n\n# Step 4: Get total population per settlement and apply ratios\nsettlement_population = renabap_pba_intersect[\n    [\"nombre_barrio\", \"familias_aproximadas\"]\n].copy()\n\n# Merge with ratios and calculate population estimates\npopulation_estimates = hazard_ratios.merge(\n    settlement_population, on=\"nombre_barrio\", how=\"left\"\n)\npopulation_estimates[\"estimated_population_hazard\"] = (\n    population_estimates[\"building_ratio\"]\n    * population_estimates[\"familias_aproximadas\"]\n)\n\n# Step 5: Create final results with totals\nfinal_results = population_estimates[\n    [\"nombre_barrio\", \"PELIGROSID\", \"estimated_population_hazard\"]\n].copy()\n\n# Add total population rows (no hazard breakdown)\ntotal_pop_rows = settlement_population.copy()\ntotal_pop_rows[\"PELIGROSID\"] = \"total\"\ntotal_pop_rows[\"estimated_population_hazard\"] = total_pop_rows[\"familias_aproximadas\"]\n\n# Combine\nfinal_results = pd.concat(\n    [\n        final_results,\n        total_pop_rows[[\"nombre_barrio\", \"PELIGROSID\", \"estimated_population_hazard\"]],\n    ],\n    ignore_index=True,\n)\n\n# Create buildings tidy dataframe with matching structure\nbuildings_tidy = final_results[\n    [\"nombre_barrio\", \"PELIGROSID\", \"estimated_population_hazard\"]\n].copy()\n\n# Rename columns to match the structure\nbuildings_tidy = buildings_tidy.rename(\n    columns={\n        \"PELIGROSID\": \"peligrosidad\",\n        \"estimated_population_hazard\": \"fam_expuestas_edificios\",\n    }\n)\n\n# Filter out the 'total' rows since we only want hazard-specific data\nbuildings_tidy = buildings_tidy[buildings_tidy[\"peligrosidad\"] != \"total\"].copy()\n\n\n\n\n\n\n\n3.4.4 Comparación de resultados\n\n\nMostrar el código\n# Join all three dataframes by nombre_barrio and peligrosidad\nfinal_df = renabap_tidy.merge(\n    ghsl_tidy, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\nfinal_df = final_df.merge(\n    buildings_tidy, on=[\"nombre_barrio\", \"peligrosidad\"], how=\"outer\"\n)\n\n# Impute 0s for NA values in fam_expuestas columns\nfam_expuestas_columns = [col for col in final_df.columns if 'fam_expuestas' in col]\nfinal_df[fam_expuestas_columns] = final_df[fam_expuestas_columns].fillna(0)\n\n# Create long format dataframe with aggregation\nfinal_tidy = []\n\n# Add renabap data\nfor _, row in renabap_tidy.iterrows():\n    final_tidy.append(\n        {\n            \"nombre_barrio\": row[\"nombre_barrio\"],\n            \"peligrosidad\": row[\"peligrosidad\"],\n            \"metodo\": \"area\",\n            \"fam_expuestas\": row[\"fam_expuestas_areal\"],\n        }\n    )\n\n# Add ghsl data\nfor _, row in ghsl_tidy.iterrows():\n    final_tidy.append(\n        {\n            \"nombre_barrio\": row[\"nombre_barrio\"],\n            \"peligrosidad\": row[\"peligrosidad\"],\n            \"metodo\": \"ghsl\",\n            \"fam_expuestas\": row[\"fam_expuestas_ghsl\"],\n        }\n    )\n\n# Add buildings data\nfor _, row in buildings_tidy.iterrows():\n    final_tidy.append(\n        {\n            \"nombre_barrio\": row[\"nombre_barrio\"],\n            \"peligrosidad\": row[\"peligrosidad\"],\n            \"metodo\": \"edificios\",\n            \"fam_expuestas\": row[\"fam_expuestas_edificios\"],\n        }\n    )\n\nfinal_tidy = pd.DataFrame(final_tidy)\n\n# Aggregate to get one observation per barrio per hazard level per method\nfinal_tidy = (\n    final_tidy.groupby([\"nombre_barrio\", \"peligrosidad\", \"metodo\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n)\n\n# Create complete combination of all barrios, hazard levels, and methods\nall_barrios = final_tidy[\"nombre_barrio\"].unique()\nall_hazard_levels = [\"alta\", \"baja\", \"media\"]\nall_methods = [\"area\", \"ghsl\", \"edificios\"]\n\ncomplete_combinations = pd.DataFrame([\n    {\"nombre_barrio\": barrio, \"peligrosidad\": hazard, \"metodo\": method}\n    for barrio in all_barrios\n    for hazard in all_hazard_levels\n    for method in all_methods\n])\n\n# Merge with actual data and fill missing values with 0\nfinal_tidy = complete_combinations.merge(\n    final_tidy, on=[\"nombre_barrio\", \"peligrosidad\", \"metodo\"], how=\"left\"\n)\nfinal_tidy[\"fam_expuestas\"] = final_tidy[\"fam_expuestas\"].fillna(0)\n\n# Calculate total exposure per hazard level per method\nsummary = (\n    final_tidy.groupby([\"peligrosidad\", \"metodo\"])[\"fam_expuestas\"]\n    .sum()\n    .reset_index()\n    .pivot(index=\"peligrosidad\", columns=\"metodo\", values=\"fam_expuestas\")\n)\n\nprint(\"Total Familias Expuestas por Peligrosidad y Método:\")\nprint(\"=\" * 50)\nprint(summary.round(2))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter for high exposure (alta peligrosidad)\nalta_data = final_tidy[final_tidy[\"peligrosidad\"] == \"alta\"].copy()\n\n# Calculate total exposure per barrio across all methods\ntotal_exposure = (\n    alta_data.groupby(\"nombre_barrio\")[\"fam_expuestas\"]\n    .sum()\n    .sort_values(ascending=False)\n)\ntop_25_barrios = total_exposure.head(25).index\n\n# Filter data for top 25 barrios\ntop_25_data = alta_data[\n    alta_data[\"nombre_barrio\"].isin(top_25_barrios)\n].copy()\n\n# Create range plot showing min, max, and individual points\nplt.figure(figsize=(15, 10))\n\n# Define colors for methods\nmethod_colors = {\"area\": \"blue\", \"ghsl\": \"red\", \"edificios\": \"green\"}\n\nfor i, barrio in enumerate(top_25_barrios):\n    barrio_data = top_25_data[top_25_data[\"nombre_barrio\"] == barrio]\n    if len(barrio_data) &gt; 0:\n        values = barrio_data[\"fam_expuestas\"].values\n        min_val = values.min()\n        max_val = values.max()\n\n        # Plot range line\n        plt.plot([min_val, max_val], [i, i], \"k-\", alpha=0.5, linewidth=2)\n\n        # Plot individual points colored by method\n        for _, row in barrio_data.iterrows():\n            color = method_colors[row[\"metodo\"]]\n            plt.plot(row[\"fam_expuestas\"], i, \"o\", color=color, markersize=6, alpha=0.8)\n\nplt.yticks(range(len(top_25_barrios)), top_25_barrios)\nplt.xlabel(\"Familias Expuestas\")\nplt.ylabel(\"Barrio\")\nplt.title(\"Range of High Exposure Estimates for Top 25 Barrios\", fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# Add legend\nlegend_elements = [\n    plt.Line2D(\n        [0],\n        [0],\n        marker=\"o\",\n        color=\"w\",\n        markerfacecolor=color,\n        markersize=8,\n        label=method,\n    )\n    for method, color in method_colors.items()\n]\nplt.legend(handles=legend_elements, title=\"Método\")\n\nplt.tight_layout()\nplt.show()\n\n\nTotal Familias Expuestas por Peligrosidad y Método:\n==================================================\nmetodo           area  edificios     ghsl\npeligrosidad                             \nalta          1909.76    3606.85  2831.97\nbaja          5315.18    9852.58  7726.58\nmedia         3599.65    9717.37  8400.36",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Riesgo hídrico en barrios populares</span>"
    ]
  },
  {
    "objectID": "renabap.html#conclusiones-y-recomendaciones",
    "href": "renabap.html#conclusiones-y-recomendaciones",
    "title": "3  Riesgo hídrico en barrios populares",
    "section": "3.5 Conclusiones y Recomendaciones",
    "text": "3.5 Conclusiones y Recomendaciones",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Riesgo hídrico en barrios populares</span>"
    ]
  },
  {
    "objectID": "renabap.html#referencias",
    "href": "renabap.html#referencias",
    "title": "3  Riesgo hídrico en barrios populares",
    "section": "3.6 Referencias",
    "text": "3.6 Referencias",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Riesgo hídrico en barrios populares</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]