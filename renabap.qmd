---
title: "RENABAP"
subtitle: "Análisis de la exposición poblacional a peligros de inundación en el Partido de La Plata"
---

## Resumen ejecutivo

Este análisis utiliza datos globales abiertos de huellas de edificios para lograr una estimación más precisa de la exposición a peligros de inundación en asentamientos informales en La Plata. Este método mejora significativamente las estimaciones previas utilizando datos del RENABAP y revela una subestimación dramática en los datos oficiales. Encontramos que los datos del RENABAP subestiman el número de edificios en un promedio del 41%, lo que equivale a aproximadamente 41,000 viviendas faltantes que no están contabilizadas en las estadísticas oficiales. Tomando un promedio razonable de 3 a 5 personas por vivienda, esto representa entre 120,000 y 205,000 personas que podrían estar no contabilizadas en los asentamientos informales. El conjunto de datos globales de huellas de edificios representa, por tanto, una herramienta crítica para comprender la verdadera magnitud de la exposición a peligros de inundación en La Plata.

Encontramos que Villa Montoro tiene el mayor número de edificios expuestos a peligro alto bajo la precipitación máxima probable, con 555 edificios. La Cuenca Arroyo del Gato presenta el mayor número total de edificios expuestos con 2,662, seguida por la Cuenca Maldonado con 1,000. Además, un análisis comparativo de exposición bajo diferentes períodos de retorno para la Cuenca Maldonado revela diferencias significativas en la exposición estimada dependiendo del período de retorno considerado. Mientras que la precipitación máxima probable estima un total de 1,000 edificios expuestos para la cuenca, el período de retorno de 25 años estima 77 edificios expuestos y el período de retorno de 100 años estima 141 edificios expuestos a peligro alto, planteando así interrogantes sobre cuál de estos es más útil para iniciar el proceso de reubicación de viviendas en áreas de alto peligro en asentamientos informales.

## Objetivos

Este proyecto tiene como objetivo principal mejorar el mapeo de la exposición a peligros de inundación en asentamientos informales del Partido de La Plata. El análisis se realiza específicamente con el propósito de preparar un plan para la reubicación gradual de las estructuras, viviendas o familias en mayor riesgo dentro de estos asentamientos informales hacia lugares más seguros.

El trabajo busca cuantificar la exposición a peligros de inundación en asentamientos informales como herramienta para la toma de decisiones a nivel municipal, desarrollando metodologías de análisis espacial que permitan identificar las áreas y poblaciones de mayor riesgo. Asimismo, se propone proporcionar información técnica que ayude a mitigar el riesgo de inundación en asentamientos informales y obtener estimaciones más precisas de la población expuesta utilizando datos de huellas de edificios, complementando las limitaciones conocidas de los datos del RENABAP.

Un objetivo adicional de este análisis es obtener estimaciones más precisas de exposición utilizando datos abiertos de huellas de edificios en lugar de depender únicamente de los datos del RENABAP. Los últimos datos del RENABAP fueron publicados en 2023 y están basados en proyecciones derivadas del censo de 2010, por lo que no se espera que sean especialmente precisos para las condiciones actuales.

```{python}
import matplotlib.pyplot as plt
import contextily as ctx


from io import BytesIO, StringIO
from owslib.wfs import WebFeatureService
from shapely.geometry import box
import geopandas as gpd
import requests
import pandas as pd
import os

import boto3
import duckdb


import numpy as np
import s2sphere
from botocore.config import Config
import itables
from itables import show
from IPython.display import HTML, display

# For scale bars and north arrows
from matplotlib_map_utils import north_arrow, scale_bar, ScaleBar


# =============================================================================
# ITABLES SPANISH CONFIGURATION
# =============================================================================

# Configure Argentine Spanish for itables
try:
    spanish_url = "https://cdn.datatables.net/plug-ins/2.3.3/i18n/es-AR.json"
    response = requests.get(spanish_url)
    response.raise_for_status()
    spanish_config = response.json()
    itables.options.language = spanish_config
except Exception:
    pass  # Fall back to English if configuration fails

# Configure smaller font size for all itables
css = """
.dt-container {
  font-size: small;
}
"""
display(HTML(f"<style>{css}</style>"))


# Helper function to round numeric columns for display
def round_numeric_columns(df, decimals=0):
    """Round all numeric columns in a DataFrame to specified decimal places."""
    df_display = df.copy()
    numeric_columns = df_display.select_dtypes(include=[np.number]).columns
    df_display[numeric_columns] = df_display[numeric_columns].round(decimals)
    return df_display


# =============================================================================
# CONSTANTS AND CONFIGURATION
# =============================================================================

# Coordinate Reference Systems
USE_CRS = "EPSG:5349"  # POSGAR 2007 / Argentina 4
WEB_MERCATOR_CRS = "EPSG:3857"  # Web Mercator for visualization
WGS84_CRS = "EPSG:4326"  # WGS84 for API calls

# File paths
BASE_PATH = "/home/nissim/Documents/dev/fulbright/ciut-riesgo"
DATA_PATH = f"{BASE_PATH}/notebooks/data"
PELIGRO_PATH = f"{DATA_PATH}/la_plata_pelig_2023_datos_originales.geojson"
PARTIDOS_PATH = f"{DATA_PATH}/pba_partidos.geojson"
CUENCAS_PATH = f"{BASE_PATH}/notebooks/cuencas_buenos_aires.geojson"
BUILDINGS_PATH = f"{BASE_PATH}/notebooks/buildings_filtered.parquet"

# Data URLs
RENABAP_URL = (
    "https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson"
)
PARTIDOS_WFS_URL = "https://geo.arba.gov.ar/geoserver/idera/wfs"
CUENCAS_API_URL = "https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query"

# Data processing constants
HAZARD_LEVELS = ["baja", "media", "alta"]
METHOD_NAMES = ["edificios", "ghsl", "areal"]
EXPOSURE_COLUMNS = [
    "fam_exp_edificios",
    "fam_exp_ghsl",
    "fam_exp_areal",
]
NON_HAZARD_VALUE = "none"
NODATA_VALUE = -200

# Column mappings and renaming
COLUMN_MAPPINGS = {
    "buildings_to_edificios": {"fam_expuestas_buildings": "fam_expuestas_edificios"},
    "method_cleanup_prefix": "fam_expuestas_",
}

# Basic visualization settings (only for repeated values)
DEFAULT_FIGSIZE = (12, 10)
MAP_PADDING = 500
PLASMA_CMAP = plt.cm.plasma

# Color schemes for visualization
PELIGROSIDAD_COLORS = {
    "alta": PLASMA_CMAP(0.8),
    "media": PLASMA_CMAP(0.5),
    "baja": PLASMA_CMAP(0.2),
}

METHOD_COLORS = {
    "fam_exp_areal": PLASMA_CMAP(0.8),
    "fam_exp_ghsl": PLASMA_CMAP(0.5),
    "fam_exp_edificios": PLASMA_CMAP(0.2),
}

# Eje mapping for watershed analysis
EJE_MAPPING = {
    "noreste": ["Area de Bañados", "Cuenca Arroyo Rodriguez-Don Carlos"],
    "noroeste": ["Cuenca Arroyo Martín-Carnaval", "Cuenca Arroyo Pereyra"],
    "central": ["Cuenca Arroyo del Gato"],
    "sudoeste": ["Cuenca A° Maldonado", "Cuenca Río Samborombón"],
    "sudeste": ["Cuenca Arroyo El Pescado"],
}


def setup_base_map(
    figsize=None, bounds=None, boundary_gdf=None, padding_x=None, padding_y=None
):
    """Create figure and set up basic map boundaries with padding."""
    if figsize is None:
        figsize = DEFAULT_FIGSIZE
    if padding_x is None:
        padding_x = MAP_PADDING
    if padding_y is None:
        padding_y = MAP_PADDING

    if bounds is None and boundary_gdf is not None:
        bounds = boundary_gdf.total_bounds
    elif bounds is None:
        bounds = renabap_pba_intersect.total_bounds

    # Convert bounds to Web Mercator for basemap compatibility
    if bounds is not None:
        # Create a temporary GeoDataFrame with the bounds to reproject
        temp_bounds = gpd.GeoDataFrame(
            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS
        )
        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds
    else:
        bounds_3857 = bounds

    fig, ax = plt.subplots(figsize=figsize)
    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)
    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)
    return fig, ax


def add_basemap(ax, zoom=13):
    """Add CartoDB basemap to the axes."""

    ctx.add_basemap(
        ax,
        source=ctx.providers.CartoDB.PositronNoLabels,
        zorder=0,
        zoom=zoom,
    )

    return ax


ScaleBar.set_size("xs")

def add_scale_bar_and_north_arrow(ax, location="upper right", scale_color="black", arrow_color="black"):
    """Add a scale bar and north arrow to the map using matplotlib_map_utils."""
    # Add scale bar using matplotlib_map_utils ScaleBar class with ticks style
    scalebar = ScaleBar(
        location="upper left",
        style="ticks",
        bar={
            "projection": "EPSG:3857",
            "tickcolors": scale_color,
            "basecolors": scale_color,
            "minor_type": "none"
        },
        labels={"style": "first_last"}
    )
    ax.add_artist(scalebar)
    
    # Add north arrow using matplotlib_map_utils
    north_arrow(
        ax,
        location=location,
        scale=0.3,  # Small size
        rotation={"degrees": 0},
        base={"facecolor": "none", "edgecolor": arrow_color, "linewidth": 1},
        fancy=True,
        shadow=True,
        label=False  # Hide the "N" text
    )


def add_la_plata_outline(ax, color="black"):
    """Add the outline of Partido de La Plata to a map as the top layer."""
    la_plata_3857 = la_plata.to_crs(WEB_MERCATOR_CRS)
    la_plata_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor=color,
        linewidth=0.5,
        linestyle="--",
        legend=False,
        zorder=100,  # Ensure it's always on top
    )


def add_boundary_outline(ax, boundary_gdf, crs="EPSG:3857"):
    """Add the outline of a boundary geodataframe to a map."""
    boundary_3857 = boundary_gdf.to_crs(crs)
    boundary_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor="black",
        linewidth=0.5,
        linestyle="--",
        legend=False,
        zorder=5,
    )


def create_consistent_map(title, boundary_gdf=None, bounds=None):
    """Create a map with consistent styling and basemap."""
    fig, ax = setup_base_map(bounds=bounds, boundary_gdf=boundary_gdf)

    add_basemap(ax)

    add_scale_bar_and_north_arrow(ax)

    if boundary_gdf is not None:
        add_boundary_outline(ax, boundary_gdf)
    else:
        add_la_plata_outline(ax)

    ax.set_title(title, fontsize=16, fontweight="bold", pad=20)

    ax.set_axis_off()

    return fig, ax


def wfs_to_gdf(
    wfs_url: str, layer_name: str, srs: str = "EPSG:4326"
) -> gpd.GeoDataFrame:
    """
    Descarga una capa WFS y la devuelve como GeoDataFrame.

    Args:
        wfs_url (str): URL del servicio WFS.
        layer_name (str): Nombre de la capa (typename).
        srs (str): Código EPSG del sistema de referencia de coordenadas.

    Returns:
        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.
    """
    wfs = WebFeatureService(url=wfs_url, version="2.0.0")
    response = wfs.getfeature(typename=layer_name, srsname=srs)
    gdf = gpd.read_file(BytesIO(response.read()))
    return gdf


def create_exposure_tidy_data(
    data,
    id_column,
    peligrosidad_column,
    method_suffix,
    exposure_values,
    exclude_zero=True,
):
    """
    Create tidy exposure dataset in a standardized format.

    Args:
        data: DataFrame containing the base data
        id_column: Column name for the identifier (e.g., 'id_renabap', 'Cuenca', 'eje')
        peligrosidad_column: Column name for hazard level
        method_suffix: Suffix for the exposure column (e.g., 'areal', 'ghsl', 'edificios')
        exposure_values: Series or array of exposure values matching data rows
        exclude_zero: Whether to exclude zero exposure values

    Returns:
        pd.DataFrame: Tidy format dataframe with id, peligrosidad, and exposure columns
    """
    tidy_data = []
    for idx, (_, row) in enumerate(data.iterrows()):
        exposure_value = (
            exposure_values.iloc[idx]
            if hasattr(exposure_values, "iloc")
            else exposure_values[idx]
        )

        if exclude_zero and exposure_value <= 0:
            continue

        tidy_data.append(
            {
                id_column: row[id_column],
                "peligrosidad": row[peligrosidad_column],
                f"fam_expuestas_{method_suffix}": exposure_value,
            }
        )

    return pd.DataFrame(tidy_data)


def create_wide_exposure_dataframe(
    areal_data, ghsl_data, buildings_data, id_columns, exclude_hazard_value="none"
):
    """
    Create wide format exposure dataframe by merging tidy datasets.

    Args:
        areal_data: Tidy dataframe with areal interpolation results
        ghsl_data: Tidy dataframe with GHSL dasymetric results
        buildings_data: Tidy dataframe with buildings dasymetric results
        id_columns: List of columns to merge on (e.g., ['id_renabap', 'peligrosidad'])
        exclude_hazard_value: Hazard value to exclude from results

    Returns:
        pd.DataFrame: Wide format dataframe with all exposure methods
    """
    # Filter out non-hazard values
    areal_filtered = areal_data[areal_data["peligrosidad"] != exclude_hazard_value]
    ghsl_filtered = ghsl_data[ghsl_data["peligrosidad"] != exclude_hazard_value]
    buildings_filtered = buildings_data[
        buildings_data["peligrosidad"] != exclude_hazard_value
    ]

    # Apply column mapping for buildings if needed
    if "fam_expuestas_buildings" in buildings_filtered.columns:
        buildings_filtered = buildings_filtered.rename(
            columns={"fam_expuestas_buildings": "fam_expuestas_edificios"}
        )

    # Merge all datasets
    wide_data = areal_filtered.merge(ghsl_filtered, on=id_columns, how="outer").merge(
        buildings_filtered, on=id_columns, how="outer"
    )

    # Fill NaN values with 0
    wide_data = wide_data.fillna(0)

    # Rename columns to shorter format
    column_mapping = {
        "fam_expuestas_areal": "fam_exp_areal",
        "fam_expuestas_ghsl": "fam_exp_ghsl",
        "fam_expuestas_edificios": "fam_exp_edificios",
    }
    wide_data = wide_data.rename(columns=column_mapping)

    return wide_data


response = requests.get(RENABAP_URL)
renabap = gpd.read_file(StringIO(response.text))
renabap_pba = renabap[renabap["provincia"] == "Buenos Aires"]
renabap_pba = renabap_pba.to_crs(USE_CRS)

peligro = gpd.read_file(PELIGRO_PATH)
peligro = peligro.to_crs(USE_CRS)

peligro_bounds = peligro.total_bounds
peligro_bbox = box(*peligro_bounds)

if os.path.exists(PARTIDOS_PATH):
    partidos = gpd.read_file(PARTIDOS_PATH)
else:
    partidos = wfs_to_gdf(
        wfs_url=PARTIDOS_WFS_URL,
        layer_name="idera:Departamento",
        srs="EPSG:5347",
    )

    partidos.to_file(PARTIDOS_PATH, driver="GeoJSON")

partidos = partidos.to_crs(USE_CRS)
la_plata = partidos[partidos["fna"] == "Partido de La Plata"]

# Obtener la geometría principal
main_geom = la_plata.geometry.iloc[0]

# Si es un MultiPolygon, mantener solo el polígono más grande (el partido principal)
# Esto elimina la pequeña isla que aparece en los datos
if main_geom.geom_type == "MultiPolygon":
    # Obtener todos los polígonos y mantener el que tenga mayor área
    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)
    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning
    la_plata.loc[la_plata.index[0], "geometry"] = largest_polygon

la_plata_bbox = la_plata.geometry.iloc[0]

renabap_pba_intersect = renabap_pba[
    renabap_pba.geometry.intersects(la_plata_bbox)
].copy()


if os.path.exists(CUENCAS_PATH):
    cuencas = gpd.read_file(CUENCAS_PATH)
else:
    params = {"where": "1=1", "outFields": "*", "f": "geojson"}

    cuencas_response = requests.get(CUENCAS_API_URL, params=params)
    with open(CUENCAS_PATH, "w", encoding="utf-8") as f:
        f.write(cuencas_response.text)

    cuencas = gpd.read_file(StringIO(cuencas_response.text))

cuencas = cuencas.to_crs(USE_CRS)
cuencas = cuencas.clip(la_plata)

# Map watershed names to axes based on the EJE_MAPPING
cuencas["eje"] = (
    cuencas["Cuenca"]
    .map(
        {
            cuenca: eje
            for eje, cuencas_list in EJE_MAPPING.items()
            for cuenca in cuencas_list
        }
    )
    .fillna("otro")
)

# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)
renabap_total_area_ha = (
    renabap_pba_intersect.geometry.area.sum() / 10000
)  # Convert m² to hectares
la_plata_area_ha = la_plata.geometry.iloc[0].area / 10000
percentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100

# Get common bounds for all maps
common_bounds = la_plata.total_bounds

# Intersect settlements with hazard zones
settlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how="intersection")

settle_hazard_cuencas = gpd.overlay(
    settlement_hazard, cuencas, how="intersection", keep_geom_type=True
)
```

## Fuentes de datos

### RENABAP
El Registro Nacional de Barrios Populares (RENABAP) es producido por la Subsecretaría de Integración Socio Urbana y proporciona información sobre asentamientos informales en Argentina, incluyendo estimaciones de población y delimitaciones geográficas de estos barrios. Más información sobre el RENABAP está disponible en el [Observatorio de Barrios Populares](https://www.argentina.gob.ar/obras-publicas/sisu/renabap/observatorio-de-barrios-populares). Los datos fueron obtenidos a través del [Mapa de Barrios Populares](https://www.argentina.gob.ar/obras-publicas/sisu/renabap/mapa) y están disponibles para [descarga como GeoJSON](https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson).

```{python}

```

### Peligro de inundación

Los datos de peligro de inundación utilizados en este análisis fueron desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata [@romanazzi2019]. Estos datos fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que permitió simular la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. El modelo calcula las principales variables hidráulicas (altura del agua, velocidad y caudal) a lo largo del tiempo, y a partir de estos resultados se generaron los mapas de peligrosidad que combinan el efecto de la profundidad con la velocidad de la corriente, ofreciendo un indicador más completo que los mapas tradicionales de máximas profundidades.

```{python}

```

### Google-Microsoft-OSM Open Buildings

Los datos de [Google-Microsoft-OSM Open Buildings - combined by VIDA](https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access) [@google_microsoft_osm_buildings] representan una forma más precisa de evaluar dónde se ubican los asentamientos humanos. Este conjunto de datos combina Google's V3 Open Buildings, Microsoft's GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo más de 2.7 mil millones de huellas de edificios. Estos datos han sido [exitosamente aplicados a evaluaciones de riesgo de inundación por empresas globales de riesgo financiero como ICE](https://www.ice.com/insights/sustainable-finance/ice-climates-exposure-datasets-understanding-how-climate-risks-impact-infrastructure-and-communities), demostrando su utilidad para mapear la exposición climática a nivel de huella de edificio individual. Sin embargo, en ausencia de información sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el número total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de dónde se ubican las personas, sin tener una comprensión precisa de quién vive realmente allí y cuántas personas.

```{python}
def fetch_buildings(geodataframe, temp_file="buildings_filtered.parquet"):
    """Fetch building data for a given GeoDataFrame region"""

    # Get S2 cell and bounds
    center = geodataframe.to_crs(WEB_MERCATOR_CRS).union_all().centroid
    center_wgs84 = (
        gpd.GeoDataFrame(geometry=[center], crs=WEB_MERCATOR_CRS)
        .to_crs(WGS84_CRS)
        .geometry.iloc[0]
    )
    cell = s2sphere.CellId.from_lat_lng(
        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)
    ).parent(10)
    bounds = geodataframe.to_crs(WGS84_CRS).total_bounds

    # Find matching S2 partition
    s3 = boto3.client(
        "s3",
        endpoint_url="https://data.source.coop",
        aws_access_key_id="",
        aws_secret_access_key="",
        config=Config(s3={"addressing_style": "path"}),
    )

    partitions = {
        obj["Key"].split("/")[-1].replace(".parquet", "")
        for obj in s3.list_objects_v2(
            Bucket="vida",
            Prefix="google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/",
        ).get("Contents", [])
    }

    parent_id = next(
        str(cell.parent(level).id())
        for level in range(10, 0, -1)
        if str(cell.parent(level).id()) in partitions
    )

    # Setup DuckDB and query
    con = duckdb.connect()
    for cmd in [
        "INSTALL spatial",
        "LOAD spatial",
        "INSTALL httpfs",
        "LOAD httpfs",
        "SET s3_region='us-east-1'",
        "SET s3_endpoint='data.source.coop'",
        "SET s3_use_ssl=true",
        "SET s3_url_style='path'",
    ]:
        con.execute(cmd)

    # Export and read back
    query = f"""
    COPY (SELECT * FROM 's3://vida/google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'
          WHERE bbox.xmax >= {bounds[0]} AND bbox.xmin <= {bounds[2]} AND
                bbox.ymax >= {bounds[1]} AND bbox.ymin <= {bounds[3]}
    ) TO '{temp_file}' (FORMAT PARQUET);
    """

    con.execute(query)
    df = pd.read_parquet(temp_file)
    df["geometry"] = gpd.GeoSeries.from_wkb(df["geometry"])

    return gpd.GeoDataFrame(df, geometry="geometry", crs=WGS84_CRS)


if os.path.exists(BUILDINGS_PATH):
    buildings = gpd.read_parquet(BUILDINGS_PATH)
else:
    buildings = fetch_buildings(renabap_pba_intersect)


buildings_proj = buildings.to_crs(USE_CRS)

buildings_proj = buildings_proj.clip(la_plata)

```

## Contexto

```{python}
# Calcular variables para el contexto
total_barrios = int(len(renabap_pba_intersect))
total_familias = int(renabap_pba_intersect['familias_aproximadas'].sum())
area_barrios_ha = int(renabap_total_area_ha)
porcentaje_cobertura = float(round(percentage_coverage, 1))

# Obtener total de edificaciones en La Plata
total_buildings_la_plata = len(buildings_proj)

# Obtener todas las edificaciones que intersectan con los barrios (corregir warning de deprecación)
buildings_in_barrios = buildings_proj[
    buildings_proj.geometry.intersects(renabap_pba_intersect.union_all())
]
total_buildings_in_barrios = len(buildings_in_barrios)

# Calcular porcentaje de edificaciones en barrios
buildings_percentage = float(round((total_buildings_in_barrios / total_buildings_la_plata) * 100, 1))

# Helper function to format numbers with commas
def format_number(num):
    return f"{num:,}"

# Recortar peligro por la plata
peligro_la_plata = peligro.clip(la_plata)

# Calcular área para cada tipo de peligro en hectáreas
peligro_areas = (
    peligro_la_plata.groupby("PELIGROSID")["geometry"]
    .apply(
        lambda x: x.area.sum() / 10000  # Convertir m² a hectáreas
    )
    .reset_index()
)
peligro_areas.columns = ["tipo_peligro", "area_ha"]

# Calcular porcentajes
peligro_areas["porcentaje"] = (peligro_areas["area_ha"] / la_plata_area_ha) * 100

# Variables para cada nivel de peligro (convertir a float Python nativo)
peligro_alta_ha = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "alta"]["area_ha"].iloc[0], 1))
peligro_alta_pct = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "alta"]["porcentaje"].iloc[0], 1))
peligro_media_ha = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "media"]["area_ha"].iloc[0], 1))
peligro_media_pct = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "media"]["porcentaje"].iloc[0], 1))
peligro_baja_ha = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "baja"]["area_ha"].iloc[0], 1))
peligro_baja_pct = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "baja"]["porcentaje"].iloc[0], 1))

# Área total cubierta por zonas de peligro (convertir a float Python nativo)
area_total_peligro_ha = float(round(peligro_areas['area_ha'].sum(), 1))
porcentaje_total_peligro = float(round(peligro_areas['porcentaje'].sum(), 1))
```

Hay un total de `{python} format_number(total_barrios)` [barrios populares en el Partido de La Plata](https://lookerstudio.google.com/u/0/reporting/0a127285-4dd0-43b2-b7b2-98390bfd567f/page/klATC), que representan `{python} format_number(total_familias)` familias y 30,753 edificios. Estos barrios ocupan `{python} format_number(area_barrios_ha)` hectáreas del Partido de La Plata, o `{python} porcentaje_cobertura` por ciento del partido. El análisis de edificios revela un total de `{python} format_number(total_buildings_la_plata)` edificios en La Plata, de los cuales `{python} format_number(total_buildings_in_barrios)` se encuentran en barrios populares (`{python} buildings_percentage`% del total). En cuanto a las zonas de peligro de inundación, el territorio incluye `{python} format_number(int(peligro_alta_ha))` hectáreas de peligro alto (`{python} peligro_alta_pct`% del partido), `{python} format_number(int(peligro_media_ha))` hectáreas de peligro medio (`{python} peligro_media_pct`% del partido), y `{python} format_number(int(peligro_baja_ha))` hectáreas de peligro bajo (`{python} peligro_baja_pct`% del partido). El área total cubierta por zonas de peligro es de `{python} format_number(int(area_total_peligro_ha))` hectáreas, representando `{python} porcentaje_total_peligro`% del partido.

```{python}
# | cache: true
# | layout-ncol: 3
# | label: fig-fuentes-datos
# | fig-cap: "Fuentes de datos para análisis de exposición"
# | fig-subcap:
# |   - "Asentamientos RENABAP en La Plata"
# |   - "Zonas de Peligro en La Plata"
# |   - "Huellas de edificios"
# | lightbox:
# |   group: fuentes-datos

fig1, ax1 = create_consistent_map("Asentamientos RENABAP en La Plata", boundary_gdf=la_plata, bounds=common_bounds)

renabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(WEB_MERCATOR_CRS)

renabap_pba_intersect_3857.plot(
    ax=ax1, facecolor="none", edgecolor="black", linewidth=0.5, legend=False, zorder=10
)

plt.tight_layout()
plt.show()

peligro_clipped = gpd.clip(peligro, la_plata)

peligro_clipped_3857 = peligro_clipped.to_crs(WEB_MERCATOR_CRS)

# Reorder the categories so they map correctly to plasma colormap
peligro_clipped_3857["PELIGROSID_ordered"] = pd.Categorical(
    peligro_clipped_3857["PELIGROSID"],
    categories=["baja", "media", "alta"],
    ordered=True,
)


fig2, ax2 = create_consistent_map("Zonas de Peligro en La Plata", boundary_gdf=la_plata, bounds=common_bounds)


peligro_clipped_3857.plot(
    ax=ax2,
    column="PELIGROSID_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    legend_kwds={"loc": "lower right"},
    zorder=5,
)

plt.tight_layout()
plt.show()


fig3, ax3 = create_consistent_map("Huellas de edificios", boundary_gdf=la_plata, bounds=common_bounds)

buildings_3857 = buildings_proj.to_crs(WEB_MERCATOR_CRS)

buildings_3857.plot(ax=ax3, facecolor="grey", edgecolor="none", alpha=0.7)

plt.tight_layout()
plt.show()
```



## Metodología

En versiones anteriores de este análisis, el trabajo se realizó mediante una interpolación areal simple del porcentaje de superposición de cada área de peligro de inundación con los asentamientos informales. Este enfoque presenta dos problemas fundamentales que este estudio busca abordar.

El primer problema es que la interpolación areal es inherentemente imprecisa, ya que asume lo que se conoce como el [problema de la unidad areal modificable](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/modifiable-areal-unit-problem) y presupone que la población se distribuye uniformemente en el espacio. Sin embargo, estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución [@smith2019]. La población, de hecho, no se distribuye uniformemente en el espacio; frecuentemente los edificios se agrupan ya sea alejándose de las zonas de peligro de inundación o concentrándose en zonas de alto peligro de inundación. Por tanto, es fundamental comprender con estimaciones más precisas dónde vive realmente la gente.

El segundo problema radica en que los propios datos del RENABAP, según nuestro análisis aquí presentado, parecen contar dramáticamente de forma incorrecta, frecuentemente por un factor de dos o más, el número de familias que aparentemente viven en un asentamiento informal basándose en el número de edificaciones. Esto probablemente se debe a errores de proyección acumulados a lo largo del tiempo y a la dificultad de mantener actualizados los datos de asentamientos informales.

Esta es una de las grandes ventajas de las huellas de edificios globales derivadas de satélite que han surgido en los últimos años de Google-Microsoft-OSM, entre otros. Uno de los objetivos principales de este análisis es demostrar que estos datos de huellas de edificios pueden utilizarse para estimar la exposición de manera más precisa, tanto en términos de precisión metodológica como en términos de mejora sobre conjuntos de datos nacionales existentes como el RENABAP.

Por tanto, en este estudio utilizamos el número de edificios que intersectan con las diferentes zonas de peligro de inundación como medida de exposición. Hemos encontrado que los datos del RENABAP presentan limitaciones significativas, como se demuestra en nuestro análisis. Los datos del RENABAP para los asentamientos informales de La Plata estiman aproximadamente 1.1 familias por edificio. Para quienes estén interesados en entender el número de familias que probablemente estén expuestas, pueden multiplicar el número de edificios por 1.1 y obtener una estimación razonable.

Sin embargo, dado que no conocemos exactamente cuántas familias viven en cada edificio y que los edificios pueden variar en tamaño, no realizamos esta conversión. En su lugar, medimos la exposición puramente en términos del número comparativo de edificios, lo cual es suficiente para demostrar que los datos del RENABAP están considerablemente desactualizados, pero también para proporcionarnos estimaciones razonablemente buenas de exposición.

Además, basándonos en conversaciones con planificadores tanto del ámbito académico como del gobierno municipal, nos sentimos razonablemente seguros al asumir que la mayoría o la totalidad de los edificios dentro de los límites de un asentamiento informal son probablemente edificios residenciales de uno a dos pisos como máximo. Por tanto, existe una correspondencia muy estrecha entre el número de edificios observados y el número de familias que viven en un asentamiento informal. Esto no será el caso en todos los asentamientos informales y ciertamente no es el caso en asentamientos formales densos. En este contexto particular, nos sentimos cómodos haciendo esta suposición por las razones expuestas.

```{python}
## Análisis de exposición: edificios por barrio y cuenca por zona de peligro
# Versión concisa con spatial joins (sin warnings)

import geopandas as gpd

# Definir orden de prioridad de peligro y simplificar
hazard_priority = {"alta": 3, "media": 2, "baja": 1}
peligro_simple = peligro_la_plata.dissolve(by="PELIGROSID").reset_index()

# === ANÁLISIS POR BARRIO ===
# Spatial joins
buildings_with_barrios = gpd.sjoin(
    buildings_proj,
    renabap_pba_intersect[
        ["id_renabap", "nombre_barrio", "familias_aproximadas", "geometry"]
    ],
    how="inner",
    predicate="within",
)
buildings_with_barrios = buildings_with_barrios.drop(columns=["index_right"]).copy()

buildings_with_peligro_barrio = gpd.sjoin(
    buildings_with_barrios,
    peligro_simple[["PELIGROSID", "geometry"]],
    how="left",
    predicate="within",
)

# Resolver duplicados y contar
buildings_barrio_final = buildings_with_peligro_barrio.dropna(
    subset=["PELIGROSID"]
).copy()
buildings_barrio_final.loc[:, "prioridad"] = buildings_barrio_final["PELIGROSID"].map(
    hazard_priority
)
buildings_barrio_unique = buildings_barrio_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_barrio_final.geometry.name, keep="first")

# Calcular exposición por barrio
edificios_por_barrio_peligro = (
    buildings_barrio_unique.groupby(["id_renabap", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_barrio = (
    buildings_with_barrios.groupby("id_renabap")
    .size()
    .reset_index(name="total_edificios")
)

exposure_barrio = edificios_por_barrio_peligro.merge(
    total_edificios_barrio, on="id_renabap"
)
exposure_barrio["proporcion"] = (
    exposure_barrio["edificios_expuestos"] / exposure_barrio["total_edificios"]
)

familias_barrio = renabap_pba_intersect[
    ["id_renabap", "nombre_barrio", "familias_aproximadas"]
].drop_duplicates()
final_exposure_barrio = exposure_barrio.merge(familias_barrio, on="id_renabap")
final_exposure_barrio["fam_expuestas"] = (
    final_exposure_barrio["proporcion"] * final_exposure_barrio["familias_aproximadas"]
)

resultado_exposicion_barrio = final_exposure_barrio[
    [
        "id_renabap",
        "nombre_barrio",
        "PELIGROSID",
        "edificios_expuestos",
    ]
].rename(columns={"PELIGROSID": "peligrosidad"})

# === ANÁLISIS POR CUENCA ===
# Usar edificios ya en barrios para análisis de cuenca
buildings_in_settlements = buildings_with_barrios.copy()

# Spatial joins para cuenca
buildings_with_cuenca = gpd.sjoin(
    buildings_in_settlements,
    cuencas[["Cuenca", "eje", "geometry"]],
    how="left",
    predicate="within",
)
buildings_with_cuenca = buildings_with_cuenca.drop(columns=["index_right"]).copy()

buildings_with_peligro_cuenca = gpd.sjoin(
    buildings_in_settlements,
    peligro_simple[["PELIGROSID", "geometry"]],
    how="left",
    predicate="within",
)

# Combinar y filtrar
buildings_cuenca_final = buildings_in_settlements.copy()
buildings_cuenca_final.loc[:, "Cuenca"] = buildings_with_cuenca["Cuenca"]
buildings_cuenca_final.loc[:, "eje"] = buildings_with_cuenca["eje"]
buildings_cuenca_final.loc[:, "PELIGROSID"] = buildings_with_peligro_cuenca[
    "PELIGROSID"
]
buildings_cuenca_final = buildings_cuenca_final.dropna(
    subset=["Cuenca", "PELIGROSID"]
).copy()

# Resolver duplicados y calcular exposición por cuenca
buildings_cuenca_final.loc[:, "prioridad"] = buildings_cuenca_final["PELIGROSID"].map(
    hazard_priority
)
buildings_cuenca_unique = buildings_cuenca_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_cuenca_final.geometry.name, keep="first")

edificios_por_cuenca_peligro = (
    buildings_cuenca_unique.groupby(["Cuenca", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_cuenca = (
    buildings_with_cuenca.dropna(subset=["Cuenca"])
    .groupby("Cuenca")
    .size()
    .reset_index(name="total_edificios")
)

exposure_cuenca = edificios_por_cuenca_peligro.merge(
    total_edificios_cuenca, on="Cuenca"
)
exposure_cuenca["proporcion"] = (
    exposure_cuenca["edificios_expuestos"] / exposure_cuenca["total_edificios"]
)

familias_cuenca = (
    settle_hazard_cuencas.drop_duplicates("id_renabap")
    .groupby("Cuenca")["familias_aproximadas"]
    .sum()
    .reset_index()
)

final_exposure_cuenca = exposure_cuenca.merge(familias_cuenca, on="Cuenca")
final_exposure_cuenca["fam_expuestas"] = (
    final_exposure_cuenca["proporcion"] * final_exposure_cuenca["familias_aproximadas"]
)

resultado_exposicion_cuenca = final_exposure_cuenca[
    ["Cuenca", "PELIGROSID", "edificios_expuestos"]
].rename(columns={"PELIGROSID": "peligrosidad"})

# === ANÁLISIS POR EJE ===
# Usar los edificios ya procesados con cuenca y peligro
buildings_eje_final = buildings_cuenca_final.dropna(subset=["eje"]).copy()

# Resolver duplicados por prioridad de peligro
buildings_eje_final.loc[:, "prioridad"] = buildings_eje_final["PELIGROSID"].map(
    hazard_priority
)
buildings_eje_unique = buildings_eje_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_eje_final.geometry.name, keep="first")

# Calcular exposición por eje y peligrosidad
edificios_por_eje_peligro = (
    buildings_eje_unique.groupby(["eje", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_eje = (
    buildings_with_cuenca.dropna(subset=["eje"])
    .groupby("eje")
    .size()
    .reset_index(name="total_edificios")
)

exposure_eje = edificios_por_eje_peligro.merge(total_edificios_eje, on="eje")
exposure_eje["proporcion"] = (
    exposure_eje["edificios_expuestos"] / exposure_eje["total_edificios"]
)

familias_por_eje = (
    settle_hazard_cuencas.drop_duplicates("id_renabap")
    .groupby("eje")["familias_aproximadas"]
    .sum()
    .reset_index()
)

final_exposure_eje = exposure_eje.merge(familias_por_eje, on="eje")
final_exposure_eje["fam_expuestas"] = (
    final_exposure_eje["proporcion"] * final_exposure_eje["familias_aproximadas"]
)

resultado_exposicion_eje = final_exposure_eje[
    ["eje", "PELIGROSID", "edificios_expuestos"]
].rename(columns={"PELIGROSID": "peligrosidad"})
```

### Limitaciones de los datos del RENABAP

Los datos del RENABAP presentan limitaciones importantes que justifican el uso de huellas de edificios como alternativa más precisa. Los datos más recientes del RENABAP de 2023 subestiman significativamente el número total de familias por asentamiento informal. Estos datos se basan en proyecciones derivadas del censo de 2010, lo que ha resultado en estimaciones considerablemente desactualizadas.

Nuestro análisis comparativo entre los datos del RENABAP y el conteo de huellas de edificios revela que el RENABAP subestima el número de estructuras habitacionales en un promedio del 41%. A nivel agregado, esto se traduce en aproximadamente 41,000 viviendas faltantes que no están contabilizadas en las estadísticas oficiales del RENABAP. Considerando un rango razonable de 3 a 5 personas por vivienda, esta subestimación representa entre 120,000 y 205,000 personas que podrían estar no contabilizadas en los asentamientos informales. Esta discrepancia masiva demuestra claramente las limitaciones críticas del RENABAP para la evaluación precisa de la exposición a riesgos de inundación y la planificación de políticas públicas.

```{python}
# | label: fig-error-renabap
# | fig-cap: "Distribución del error porcentual en las estimaciones del RENABAP comparado con estimaciones basadas en edificios"

import matplotlib.pyplot as plt

# Calcular familias estimadas basadas en edificios (1.1 familias por edificio)
ratio_fam_edif = (
    buildings_with_barrios.groupby(["id_renabap", "familias_aproximadas"])
    .size()
    .reset_index(name="total_edificios")
)

ratio_fam_edif["familias_estimadas_edificios"] = ratio_fam_edif["total_edificios"] * 1.1
# Calcular el error porcentual: (RENABAP - Edificios) / Edificios * 100
ratio_fam_edif["error_porcentual"] = (
    (
        ratio_fam_edif["familias_aproximadas"]
        - ratio_fam_edif["familias_estimadas_edificios"]
    )
    / ratio_fam_edif["familias_estimadas_edificios"]
) * 100

# Crear histograma
plt.figure(figsize=(12, 6))
plt.hist(
    ratio_fam_edif["error_porcentual"],
    bins=30,
    edgecolor="none",
    color=PELIGROSIDAD_COLORS["alta"],
)

# Personalizar el gráfico
plt.title(
    "Error de Estimación de RENABAP vs Estimación por Edificios",
    fontsize=16,
    fontweight="bold",
)
plt.xlabel("Error Porcentual (%)", fontsize=12)
plt.ylabel("Frecuencia (Número de Barrios)", fontsize=12)

# Agregar líneas de referencia
mean_error = ratio_fam_edif["error_porcentual"].mean()
median_error = ratio_fam_edif["error_porcentual"].median()

plt.axvline(
    mean_error,
    color="black",
    linestyle="--",
    linewidth=2,
    label=f"Error promedio: {mean_error:.1f}%",
)
plt.axvline(
    median_error,
    color="black",
    linestyle="dotted",
    linewidth=2,
    label=f"Error mediano: {median_error:.1f}%",
)


plt.legend()
plt.tight_layout()
plt.show()
```

También podemos examinar imágenes satelitales de un asentamiento informal de muestra con las huellas de edificios superpuestas para tener una idea de la veracidad de los datos. Aquí está un barrio llamado Los Pinos, en el cual mapeamos la extensión del RENABAP del barrio y las huellas de los edificios dentro de él. Las estimaciones del RENABAP dicen que este asentamiento informal tiene solo 72 familias. Nuestros datos cuentan 519 edificios. Si usamos la estimación del RENABAP de aproximadamente 1.1 familias por edificio, que es lo que calculan en sus datos originales, estamos hablando de un total de 570 familias, que es casi ocho veces más de lo que los datos del RENABAP contabilizan.


```{python}
# | label: fig-ejemplo-barrio
# | fig-cap: "Ejemplo de discrepancia en los datos del RENABAP: el barrio Los Pinos con límites oficiales y edificaciones detectadas"

import matplotlib.pyplot as plt
import geopandas as gpd
import contextily as cx
from matplotlib_map_utils.core.scale_bar import ScaleBar, scale_bar
from matplotlib_map_utils.core.north_arrow import north_arrow

# Filtrar para obtener solo el barrio con id_renabap 5688
barrio_5688 = renabap_pba_intersect[renabap_pba_intersect["id_renabap"] == 5688].copy()
if len(barrio_5688) == 0:
    print("No se encontró el barrio con id_renabap 5688")
else:
    # Obtener edificios en este barrio
    buildings_5688 = buildings_with_barrios[
        buildings_with_barrios["id_renabap"] == 5688
    ].copy()
    # Convertir a Web Mercator
    barrio_5688_3857 = barrio_5688.to_crs(WEB_MERCATOR_CRS)
    buildings_5688_3857 = buildings_5688.to_crs(WEB_MERCATOR_CRS)
    # Crear el mapa
    fig, ax = plt.subplots(figsize=(12, 10))
    # Configurar límites basados en el barrio
    bounds = barrio_5688_3857.total_bounds
    margin = 50  # metros
    ax.set_xlim(bounds[0] - margin, bounds[2] + margin)
    ax.set_ylim(bounds[1] - margin, bounds[3] + margin)
    # Agregar basemap de contextily
    cx.add_basemap(ax, crs="EPSG:3857", source=cx.providers.Esri.WorldImagery)
    # Plot de edificios con contorno naranja (sin fill)
    buildings_5688_3857.plot(
        ax=ax, facecolor="none", edgecolor=PLASMA_CMAP(1), linewidth=1
    )
    # Plot del límite del barrio con estilo consistente
    barrio_5688_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor="white",  # White for satellite imagery visibility
        linewidth=3,
        linestyle="--",
        zorder=10,
    )
    
    ScaleBar.set_size("md")
    
    scale_bar(ax=ax, 
    location="upper left", 
    style="ticks", 
    bar={"projection":"axis",
    "minor_type":"none",
    "tickcolors": "white",
    "basecolors": "white"}, 
    labels={"style":"first_last",
    "textcolors":["white"],
    "stroke_width":0},
    units={"label":"m",
    "textcolor":"white",
    "stroke_width":0}
    )
    
    north_arrow(
        ax,
        location="upper right",
        scale=0.3,  # Small size
        rotation={"degrees": 0},
        base={"facecolor": "none", "edgecolor": "white", "linewidth": 1},
        fancy=True,
        shadow=True,
        label=False  # Hide the "N" text
    )
    
    # Limpiar el mapa
    barrio_nombre = barrio_5688["nombre_barrio"].iloc[0]
    ax.set_title(
        f"Barrio {barrio_nombre} - Límites y Edificaciones",
        fontsize=14,
        fontweight="bold",
        pad=20,
    )
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xlabel("")
    ax.set_ylabel("")
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)
    ax.spines["left"].set_visible(False)
    # Agregar leyenda simple
    legend_elements = [
        plt.Line2D([0], [0], color="white", linewidth=3, label="Límite del barrio"),
        plt.Line2D([0], [0], color=PLASMA_CMAP(1), linewidth=1, label="Edificaciones"),
    ]
    ax.legend(handles=legend_elements, loc="lower right", bbox_to_anchor=(1.0, 0.02))
    plt.tight_layout()
    plt.show()
```

## Procesamiento y resultados

La exposición en asentamientos informales se concentra principalmente en los alrededores del casco urbano de La Plata. El análisis revela una distribución característica donde un número pequeño de barrios presenta exposición muy alta, seguido por un grupo de exposición media, y luego una disminución gradual. Villa Montoro lidera con 555 edificaciones expuestas a peligro alto, seguida por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. Otros barrios con exposición significativa incluyen Aeropuerto (258), 48 y 144 (225), San Luis (206), y El Uido (132).

A nivel de cuencas hidrográficas, la Cuenca Arroyo del Gato concentra la mayor exposición con 2,662 edificaciones expuestas a peligro alto, principalmente debido a la presencia de Villa Montoro y otros asentamientos importantes. Le sigue la Cuenca A° Maldonado con 1,000 edificaciones y la Cuenca Arroyo Martín-Carnaval con 368. Esta concentración en la Cuenca Arroyo del Gato refleja tanto la densidad de asentamientos informales como su ubicación en zonas de alto riesgo hidrológico.

### Exposición por barrio

```{python}
# | label: fig-exposicion-barrios
# | fig-cap: "Mapa de exposición de barrios populares por nivel de peligrosidad de inundación"

import matplotlib.pyplot as plt
import geopandas as gpd
import contextily as cx

# Colores para peligrosidad
PELIGROSIDAD_COLORS = {
    "alta": PLASMA_CMAP(0.8),
    "media": PLASMA_CMAP(0.5),
    "baja": PLASMA_CMAP(0.2),
}


# Preparar datos - solo alta y media
exposure_data = resultado_exposicion_barrio[
    resultado_exposicion_barrio["peligrosidad"].isin(["alta", "media"])
].copy()

# Merge con geometrías para obtener centroides
exposure_gdf = exposure_data.merge(
    renabap_pba_intersect[["id_renabap", "geometry"]], on="id_renabap"
)
exposure_gdf = gpd.GeoDataFrame(exposure_gdf, geometry="geometry", crs=USE_CRS)

# Convertir a Web Mercator para el plotting
exposure_gdf_3857 = exposure_gdf.to_crs("EPSG:3857")
la_plata_3857 = la_plata.to_crs("EPSG:3857")

# Crear el mapa
fig, ax = plt.subplots(figsize=(12, 10))

# Configurar límites
bounds = la_plata_3857.total_bounds
margin = 2000  # metros
ax.set_xlim(bounds[0] - margin, bounds[2] + margin)
ax.set_ylim(bounds[1] - margin, bounds[3] + margin)

# Agregar basemap de contextily
cx.add_basemap(
    ax, crs="EPSG:3857", source=cx.providers.CartoDB.PositronNoLabels, alpha=0.7
)

# Plot de puntos con jitter
np.random.seed(42)
plotting_order = ["media", "alta"]

for peligrosidad in plotting_order:
    level_data = exposure_gdf_3857[exposure_gdf_3857["peligrosidad"] == peligrosidad]
    for _, row in level_data.iterrows():
        centroid = row["geometry"].centroid
        jitter_x = np.random.uniform(-200, 200)
        jitter_y = np.random.uniform(-200, 200)
        x_pos = centroid.x + jitter_x
        y_pos = centroid.y + jitter_y
        color = PELIGROSIDAD_COLORS[row["peligrosidad"]]
        size = max(10, row["edificios_expuestos"] * 0.5 + 15)
        ax.scatter(
            x_pos,
            y_pos,
            s=size,
            color=color,
            alpha=0.9,
            edgecolors="white",
            linewidth=1.0,
        )

# Leyenda de peligrosidad
legend_elements_peligro = [
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor=PELIGROSIDAD_COLORS["alta"],
        markersize=8,
        label="Alta",
    ),
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor=PELIGROSIDAD_COLORS["media"],
        markersize=8,
        label="Media",
    ),
]

# Leyenda de tamaño
building_values = [100, 500, 1000]
legend_elements_size = []
for val in building_values:
    size = max(10, val * 0.5 + 15)
    legend_elements_size.append(
        plt.Line2D(
            [0],
            [0],
            marker="o",
            color="w",
            markerfacecolor="gray",
            markersize=np.sqrt(size / 10),
            label=f"{val} edificios",
        )
    )

# Crear leyendas lado a lado en bottom right
legend1 = ax.legend(
    handles=legend_elements_peligro,
    title="Nivel de peligrosidad",
    loc="lower right",
    bbox_to_anchor=(0.85, 0),
)
ax.add_artist(legend1)

legend2 = ax.legend(
    handles=legend_elements_size,
    title="Edificios expuestos",
    loc="lower right",
    bbox_to_anchor=(1.0, 0),
)

# Agregar el contorno de La Plata como capa superior
add_la_plata_outline(ax)

# Agregar escala y flecha norte para consistencia
add_scale_bar_and_north_arrow(ax)

# Limpiar el mapa - quitar bordes, ticks, etc.
ax.set_title(
    "Exposición de Barrios Populares por Nivel de Peligrosidad",
    fontsize=14,
    fontweight="bold",
    pad=20,
)
ax.set_axis_off()

plt.tight_layout()
plt.show()

# | label: fig-top-barrios-exposicion
# | fig-cap: "Los 10 barrios con mayor número de edificaciones expuestas a peligros de inundación"

# Filtrar exposición alta y media por nombre de barrio (excluyendo "Sin Nombre")
barrios_alta_data = (
    resultado_exposicion_barrio[
        (resultado_exposicion_barrio["peligrosidad"] == "alta")
        & (resultado_exposicion_barrio["nombre_barrio"] != "Sin Nombre")
    ]
    .groupby("nombre_barrio")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
    .head(10)
)

barrios_media_data = (
    resultado_exposicion_barrio[
        (resultado_exposicion_barrio["peligrosidad"] == "media")
        & (resultado_exposicion_barrio["nombre_barrio"] != "Sin Nombre")
    ]
    .groupby("nombre_barrio")["edificios_expuestos"]
    .sum()
    .reset_index()
)

# Merge para tener ambos niveles
barrios_combined = barrios_alta_data.merge(barrios_media_data, on="nombre_barrio", how="left", suffixes=("_alta", "_media"))
barrios_combined["edificios_expuestos_media"] = barrios_combined["edificios_expuestos_media"].fillna(0)

# Crear el gráfico de barras
fig, ax = plt.subplots(figsize=(12, 8))
x = np.arange(len(barrios_combined))
width = 0.35

bars1 = ax.bar(x - width/2, barrios_combined["edificios_expuestos_alta"], width,
               label="Peligro Alto", color=PELIGROSIDAD_COLORS["alta"])
bars2 = ax.bar(x + width/2, barrios_combined["edificios_expuestos_media"], width,
               label="Peligro Medio", color=PELIGROSIDAD_COLORS["media"])

ax.set_xlabel("Barrios", fontsize=12)
ax.set_ylabel("Edificios Expuestos", fontsize=12)
ax.set_title("Top 10 Barrios por Edificios Expuestos", fontsize=14, fontweight="bold")
ax.set_xticks(x)
ax.set_xticklabels(barrios_combined["nombre_barrio"], rotation=45, ha="right")
ax.legend(loc="upper right")

# Agregar valores en las barras
for bar in bars1:
    height = bar.get_height()
    if height > 0:
        ax.text(bar.get_x() + bar.get_width()/2., height + 5, f'{int(height)}',
                ha='center', va='bottom', fontsize=10)

for bar in bars2:
    height = bar.get_height()
    if height > 0:
        ax.text(bar.get_x() + bar.get_width()/2., height + 5, f'{int(height)}',
                ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

show(resultado_exposicion_barrio)
```

### Exposición por cuenca y eje

```{python}
# | layout-ncol: 2
# | label: fig-exposicion-cuencas-ejes
# | fig-cap: "Exposición por cuencas hidrográficas y ejes territoriales"
# | fig-subcap:
# |   - "Cuencas por edificaciones expuestas"
# |   - "Ejes por edificaciones expuestas"

# === GRÁFICO DE CUENCAS ===
# Filtrar exposición alta y media por cuenca
cuenca_alta_data = (
    resultado_exposicion_cuenca[resultado_exposicion_cuenca["peligrosidad"] == "alta"]
    .groupby("Cuenca")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
)

cuenca_media_data = (
    resultado_exposicion_cuenca[resultado_exposicion_cuenca["peligrosidad"] == "media"]
    .groupby("Cuenca")["edificios_expuestos"]
    .sum()
    .reset_index()
)

# Merge para tener ambos niveles
cuenca_combined = cuenca_alta_data.merge(cuenca_media_data, on="Cuenca", how="left", suffixes=("_alta", "_media"))
cuenca_combined["edificios_expuestos_media"] = cuenca_combined["edificios_expuestos_media"].fillna(0)

# Crear gráfico de cuencas
fig1, ax1 = plt.subplots(figsize=(10, 8))
x = np.arange(len(cuenca_combined))
width = 0.35

bars1 = ax1.bar(x - width/2, cuenca_combined["edificios_expuestos_alta"], width, 
                label="Peligro Alto", color=PELIGROSIDAD_COLORS["alta"])
bars2 = ax1.bar(x + width/2, cuenca_combined["edificios_expuestos_media"], width,
                label="Peligro Medio", color=PELIGROSIDAD_COLORS["media"])

ax1.set_xlabel("Cuencas", fontsize=12)
ax1.set_ylabel("Edificios Expuestos", fontsize=12)
ax1.set_title("Cuencas por Edificaciones Expuestas", fontsize=14, fontweight="bold")
ax1.set_xticks(x)
ax1.set_xticklabels(cuenca_combined["Cuenca"], rotation=45, ha="right")
ax1.legend(loc="upper right")

# Agregar valores en las barras
for bar in bars1:
    height = bar.get_height()
    if height > 0:
        ax1.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}',
                ha='center', va='bottom', fontsize=10)

for bar in bars2:
    height = bar.get_height()
    if height > 0:
        ax1.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}',
                ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

# === GRÁFICO DE EJES ===
# Filtrar exposición alta y media por eje
eje_alta_data = (
    resultado_exposicion_eje[resultado_exposicion_eje["peligrosidad"] == "alta"]
    .groupby("eje")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
)

eje_media_data = (
    resultado_exposicion_eje[resultado_exposicion_eje["peligrosidad"] == "media"]
    .groupby("eje")["edificios_expuestos"]
    .sum()
    .reset_index()
)

# Merge para tener ambos niveles
eje_combined = eje_alta_data.merge(eje_media_data, on="eje", how="left", suffixes=("_alta", "_media"))
eje_combined["edificios_expuestos_media"] = eje_combined["edificios_expuestos_media"].fillna(0)

# Crear gráfico de ejes
fig2, ax2 = plt.subplots(figsize=(10, 8))
x = np.arange(len(eje_combined))
width = 0.35

bars1 = ax2.bar(x - width/2, eje_combined["edificios_expuestos_alta"], width,
                label="Peligro Alto", color=PELIGROSIDAD_COLORS["alta"])
bars2 = ax2.bar(x + width/2, eje_combined["edificios_expuestos_media"], width,
                label="Peligro Medio", color=PELIGROSIDAD_COLORS["media"])

ax2.set_xlabel("Ejes", fontsize=12)
ax2.set_ylabel("Edificios Expuestos", fontsize=12)
ax2.set_title("Ejes por Edificaciones Expuestas", fontsize=14, fontweight="bold")
ax2.set_xticks(x)
ax2.set_xticklabels(eje_combined["eje"], rotation=45, ha="right")
ax2.legend(loc="upper right")

# Agregar valores en las barras
for bar in bars1:
    height = bar.get_height()
    if height > 0:
        ax2.text(bar.get_x() + bar.get_width()/2., height + 10, f'{int(height)}',
                ha='center', va='bottom', fontsize=10)

for bar in bars2:
    height = bar.get_height()
    if height > 0:
        ax2.text(bar.get_x() + bar.get_width()/2., height + 10, f'{int(height)}',
                ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()
```

## Comparativa de periodos de retorno

```{python}
# | cache: true
# | layout-ncol: 3
# | label: fig-escenarios-maldonado
# | fig-cap: "Escenarios de peligrosidad en Cuenca Maldonado"
# | fig-subcap:
# |   - "PMP (Precipitación Máxima Probable)"
# |   - "R100 (Período de retorno 100 años)"
# |   - "R25 (Período de retorno 25 años)"
# | lightbox:
# |   group: escenarios-maldonado

# Preparar datos de cuenca Maldonado para clipping
cuenca_maldonado = cuencas[cuencas["Cuenca"] == "Cuenca A° Maldonado"].copy()

# === MAPA PMP ===
# Clipear peligro PMP a cuenca Maldonado
peligro_pmp_maldonado = gpd.clip(peligro_la_plata, cuenca_maldonado)
peligro_pmp_maldonado_3857 = peligro_pmp_maldonado.to_crs(WEB_MERCATOR_CRS)

# Ordenar categorías para mapeo correcto
peligro_pmp_maldonado_3857["PELIGROSID_ordered"] = pd.Categorical(
    peligro_pmp_maldonado_3857["PELIGROSID"],
    categories=["baja", "media", "alta"],
    ordered=True,
)

fig1, ax1 = create_consistent_map("PMP (Precipitación Máxima Probable)", boundary_gdf=cuenca_maldonado)
peligro_pmp_maldonado_3857.plot(
    ax=ax1,
    column="PELIGROSID_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    legend_kwds={"loc": "lower right"},
    zorder=5,
)
plt.tight_layout()
plt.show()

# === MAPA R100 ===
pelig_100_maldonado = gpd.read_file("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp")
pelig_100_maldonado = pelig_100_maldonado.to_crs(USE_CRS)

# Clipear a cuenca Maldonado
pelig_100_maldonado_clipped = gpd.clip(pelig_100_maldonado, cuenca_maldonado)
pelig_100_maldonado_clipped_3857 = pelig_100_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)

# Ordenar categorías
pelig_100_maldonado_clipped_3857["peli_ordered"] = pd.Categorical(
    pelig_100_maldonado_clipped_3857["peli"],
    categories=["Bajo", "Medio", "Alto"],
    ordered=True,
)

fig2, ax2 = create_consistent_map("R100 (Período de retorno 100 años)", boundary_gdf=cuenca_maldonado)
pelig_100_maldonado_clipped_3857.plot(
    ax=ax2,
    column="peli_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    legend_kwds={"loc": "lower right"},
    zorder=5,
)
plt.tight_layout()
plt.show()

# === MAPA R25 ===
pelig_25_maldonado = gpd.read_file("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp")
pelig_25_maldonado = pelig_25_maldonado.to_crs(USE_CRS)

# Clipear a cuenca Maldonado
pelig_25_maldonado_clipped = gpd.clip(pelig_25_maldonado, cuenca_maldonado)
pelig_25_maldonado_clipped_3857 = pelig_25_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)

# Ordenar categorías
pelig_25_maldonado_clipped_3857["peli_ordered"] = pd.Categorical(
    pelig_25_maldonado_clipped_3857["peli"],
    categories=["Bajo", "Medio", "Alto"],
    ordered=True,
)

fig3, ax3 = create_consistent_map("R25 (Período de retorno 25 años)", boundary_gdf=cuenca_maldonado)
pelig_25_maldonado_clipped_3857.plot(
    ax=ax3,
    column="peli_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    legend_kwds={"loc": "lower right"},
    zorder=5,
)
plt.tight_layout()
plt.show()
```

```{python}
# Comparación de escenarios de precipitación para Cuenca Maldonado
import matplotlib.pyplot as plt
import numpy as np

# Helper function para procesar datos de peligro
def process_hazard_data(file_path, buildings):
    pelig_data = gpd.read_file(file_path).to_crs(USE_CRS)
    pelig_filtered = pelig_data[pelig_data["peli"].isin(["Alto", "Medio"])].copy()
    pelig_simple = pelig_filtered.dissolve(by="peli").reset_index()
    
    buildings_with_peligro = gpd.sjoin(buildings, pelig_simple[["peli", "geometry"]], how="left", predicate="within")
    buildings_exposed = buildings_with_peligro.dropna(subset=["peli"]).copy()
    
    hazard_priority = {"Alto": 3, "Medio": 2}
    buildings_exposed.loc[:, "prioridad"] = buildings_exposed["peli"].map(hazard_priority)
    buildings_unique = buildings_exposed.sort_values("prioridad", ascending=False).drop_duplicates(subset=buildings_exposed.geometry.name, keep="first")
    
    exposicion = buildings_unique.groupby("peli").size().reset_index(name="edificios_expuestos")
    result = {}
    for _, row in exposicion.iterrows():
        peligro_name = "alta" if row['peli'] == "Alto" else "media"
        result[peligro_name] = row['edificios_expuestos']
    return result

buildings_maldonado = buildings_with_barrios.copy()

# === DATOS DE LOS TRES ESCENARIOS ===
# PMP
maldonado_pmp = resultado_exposicion_cuenca[resultado_exposicion_cuenca["Cuenca"] == "Cuenca A° Maldonado"].copy()
pmp_data = {row['peligrosidad']: int(row['edificios_expuestos']) for _, row in maldonado_pmp.iterrows()} if len(maldonado_pmp) > 0 else {}

# R25 y R100
r25_data = process_hazard_data("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp", buildings_maldonado)
r100_data = process_hazard_data("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp", buildings_maldonado)

# === VISUALIZACIÓN COMPARATIVA ===
escenarios = ['PMP', 'R100', 'R25']
alta_values = [pmp_data.get('alta', 0), r100_data.get('alta', 0), r25_data.get('alta', 0)]
media_values = [pmp_data.get('media', 0), r100_data.get('media', 0), r25_data.get('media', 0)]

x = np.arange(len(escenarios))
width = 0.35

fig, ax = plt.subplots(figsize=(10, 6))
bars1 = ax.bar(x - width/2, alta_values, width, label="Peligro Alto", color=PELIGROSIDAD_COLORS["alta"])
bars2 = ax.bar(x + width/2, media_values, width, label="Peligro Medio", color=PELIGROSIDAD_COLORS["media"])

ax.set_xlabel("Escenario de Precipitación", fontsize=12)
ax.set_ylabel("Edificios Expuestos", fontsize=12)
ax.set_title("Exposición en Cuenca Maldonado por Escenario de Precipitación", fontsize=14, fontweight="bold")
ax.set_xticks(x)
ax.set_xticklabels(escenarios)
ax.legend(loc="upper right")

def add_value_labels(bars):
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}', ha='center', va='bottom', fontsize=10)

add_value_labels(bars1)
add_value_labels(bars2)
plt.tight_layout()
plt.show()
```

## Conclusiones

Los datos de huellas de edificios nos permiten realizar evaluaciones significativamente más precisas de la exposición en asentamientos informales en todo el partido y revelan una subestimación crítica en los datos oficiales. Este análisis identifica aproximadamente 41,000 viviendas faltantes que no están contabilizadas en los datos del RENABAP, lo que representa potencialmente entre 120,000 y 205,000 personas no contabilizadas en los asentamientos informales (usando un rango razonable de 3 a 5 personas por vivienda). Esta discrepancia tiene implicaciones profundas para la planificación de gestión de riesgo y la asignación de recursos.

Nuestros resultados muestran que Villa Montoro presenta el mayor número de edificios expuestos a peligro alto con 555 edificios, seguido por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. A nivel de cuencas hidrográficas, la Cuenca Arroyo del Gato concentra la mayor exposición con 2,662 edificios expuestos a peligro alto, seguida por la Cuenca A° Maldonado con 1,000. En términos de ejes territoriales, el central presenta 2,662 edificios expuestos y el sudoeste 1,000.

Este enfoque basado en edificios no solo proporciona estimaciones más precisas y actualizadas que los métodos tradicionales de interpolación areal, sino que también demuestra la necesidad urgente de actualizar los registros oficiales de asentamientos informales. Los datos globales de huellas de edificios representan una herramienta esencial para comprender la verdadera magnitud de la población en riesgo y para la planificación efectiva de políticas de reducción de riesgo de inundación.