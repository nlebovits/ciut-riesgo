---
title: "RENABAP"
subtitle: "Análisis de la exposición poblacional a peligros de inundación en el Partido de La Plata"
---

## Resumen ejecutivo

Este análisis utiliza datos globales abiertos de huellas de edificios para lograr una estimación más precisa de la exposición a peligros de inundación en asentamientos informales en La Plata. Este método mejora significativamente las estimaciones previas utilizando datos del RENABAP y sugiere que los niveles de exposición son hasta 1.7 veces más altos de lo que se pensaba anteriormente, alcanzando potencialmente a aproximadamente 23,000 familias. Encontramos que los datos del RENABAP subestiman el número de familias en un promedio del 41%, y que el conjunto de datos globales de huellas de edificios representa, por tanto, una herramienta significativa para comprender mejor la exposición a peligros de inundación en La Plata.

Encontramos que Villa Montoro tiene el mayor número de edificios estimados expuestos a peligro alto bajo la precipitación máxima probable, con 555 edificaciones. La Cuenca Arroyo del Gato presenta el mayor número total de edificios estimados expuestos con 2,662, seguida por la Cuenca Maldonado con 1,000. Además, un análisis comparativo de exposición bajo diferentes períodos de retorno para la Cuenca Maldonado revela diferencias significativas en la exposición estimada dependiendo del período de retorno considerado. Mientras que la precipitación máxima probable estima un total de 1,000 edificios expuestos para la cuenca, el período de retorno de 25 años estima 77 edificios expuestos y el período de retorno de 100 años estima 141 edificios expuestos a peligro alto, planteando así interrogantes sobre cuál de estos es más útil para iniciar el proceso de reubicación de viviendas en áreas de alto peligro en asentamientos informales.

## Objetivos

Este proyecto tiene como objetivo principal mejorar el mapeo de la exposición a peligros de inundación en asentamientos informales del Partido de La Plata. El análisis se realiza específicamente con el propósito de preparar un plan para la reubicación gradual de las estructuras, viviendas o familias en mayor riesgo dentro de estos asentamientos informales hacia lugares más seguros.

El trabajo busca cuantificar la exposición a peligros de inundación en asentamientos informales como herramienta para la toma de decisiones a nivel municipal, desarrollando metodologías de análisis espacial que permitan identificar las áreas y poblaciones de mayor riesgo. Asimismo, se propone proporcionar información técnica que ayude a mitigar el riesgo de inundación en asentamientos informales y obtener estimaciones más precisas de la población expuesta utilizando datos de huellas de edificios, complementando las limitaciones conocidas de los datos del RENABAP.

Un objetivo adicional de este análisis es intentar obtener una estimación más precisa utilizando datos abiertos de huellas de edificios que los datos del RENABAP nos proporcionan. Los últimos datos del RENABAP fueron publicados en 2023 y están basados en proyecciones derivadas del censo de 2010, por lo que no se espera que sean especialmente precisos para las condiciones actuales.

```{python}
import matplotlib.pyplot as plt
import contextily as ctx


from io import BytesIO, StringIO
from owslib.wfs import WebFeatureService
from shapely.geometry import box
import geopandas as gpd
import requests
import pandas as pd
import os

import boto3
import duckdb


import numpy as np
import s2sphere
from botocore.config import Config
import itables
from itables import show
from IPython.display import HTML, display


# =============================================================================
# ITABLES SPANISH CONFIGURATION
# =============================================================================

# Configure Argentine Spanish for itables
try:
    spanish_url = "https://cdn.datatables.net/plug-ins/2.3.3/i18n/es-AR.json"
    response = requests.get(spanish_url)
    response.raise_for_status()
    spanish_config = response.json()
    itables.options.language = spanish_config
except Exception:
    pass  # Fall back to English if configuration fails

# Configure smaller font size for all itables
css = """
.dt-container {
  font-size: small;
}
"""
display(HTML(f"<style>{css}</style>"))


# Helper function to round numeric columns for display
def round_numeric_columns(df, decimals=0):
    """Round all numeric columns in a DataFrame to specified decimal places."""
    df_display = df.copy()
    numeric_columns = df_display.select_dtypes(include=[np.number]).columns
    df_display[numeric_columns] = df_display[numeric_columns].round(decimals)
    return df_display


# =============================================================================
# CONSTANTS AND CONFIGURATION
# =============================================================================

# Coordinate Reference Systems
USE_CRS = "EPSG:5349"  # POSGAR 2007 / Argentina 4
WEB_MERCATOR_CRS = "EPSG:3857"  # Web Mercator for visualization
WGS84_CRS = "EPSG:4326"  # WGS84 for API calls

# File paths
BASE_PATH = "/home/nissim/Documents/dev/fulbright/ciut-riesgo"
DATA_PATH = f"{BASE_PATH}/notebooks/data"
PELIGRO_PATH = f"{DATA_PATH}/la_plata_pelig_2023_datos_originales.geojson"
PARTIDOS_PATH = f"{DATA_PATH}/pba_partidos.geojson"
CUENCAS_PATH = f"{BASE_PATH}/notebooks/cuencas_buenos_aires.geojson"
BUILDINGS_PATH = f"{BASE_PATH}/notebooks/buildings_filtered.parquet"

# Data URLs
RENABAP_URL = (
    "https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson"
)
PARTIDOS_WFS_URL = "https://geo.arba.gov.ar/geoserver/idera/wfs"
CUENCAS_API_URL = "https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query"

# Data processing constants
HAZARD_LEVELS = ["baja", "media", "alta"]
METHOD_NAMES = ["edificios", "ghsl", "areal"]
EXPOSURE_COLUMNS = [
    "fam_exp_edificios",
    "fam_exp_ghsl",
    "fam_exp_areal",
]
NON_HAZARD_VALUE = "none"
NODATA_VALUE = -200

# Column mappings and renaming
COLUMN_MAPPINGS = {
    "buildings_to_edificios": {"fam_expuestas_buildings": "fam_expuestas_edificios"},
    "method_cleanup_prefix": "fam_expuestas_",
}

# Basic visualization settings (only for repeated values)
DEFAULT_FIGSIZE = (12, 10)
MAP_PADDING = 500
PLASMA_CMAP = plt.cm.plasma

# Color schemes for visualization
PELIGROSIDAD_COLORS = {
    "alta": PLASMA_CMAP(0.8),
    "media": PLASMA_CMAP(0.5),
    "baja": PLASMA_CMAP(0.2),
}

METHOD_COLORS = {
    "fam_exp_areal": PLASMA_CMAP(0.8),
    "fam_exp_ghsl": PLASMA_CMAP(0.5),
    "fam_exp_edificios": PLASMA_CMAP(0.2),
}

# Eje mapping for watershed analysis
EJE_MAPPING = {
    "noreste": ["Area de Bañados", "Cuenca Arroyo Rodriguez-Don Carlos"],
    "noroeste": ["Cuenca Arroyo Martín-Carnaval", "Cuenca Arroyo Pereyra"],
    "central": ["Cuenca Arroyo del Gato"],
    "sudoeste": ["Cuenca A° Maldonado", "Cuenca Río Samborombón"],
    "sudeste": ["Cuenca Arroyo El Pescado"],
}


def setup_base_map(
    figsize=None, bounds=None, boundary_gdf=None, padding_x=None, padding_y=None
):
    """Create figure and set up basic map boundaries with padding."""
    if figsize is None:
        figsize = DEFAULT_FIGSIZE
    if padding_x is None:
        padding_x = MAP_PADDING
    if padding_y is None:
        padding_y = MAP_PADDING

    if bounds is None and boundary_gdf is not None:
        bounds = boundary_gdf.total_bounds
    elif bounds is None:
        bounds = renabap_pba_intersect.total_bounds

    # Convert bounds to Web Mercator for basemap compatibility
    if bounds is not None:
        # Create a temporary GeoDataFrame with the bounds to reproject
        temp_bounds = gpd.GeoDataFrame(
            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=USE_CRS
        )
        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds
    else:
        bounds_3857 = bounds

    fig, ax = plt.subplots(figsize=figsize)
    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)
    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)
    return fig, ax


def add_basemap(ax, zoom=13):
    """Add CartoDB basemap to the axes."""

    ctx.add_basemap(
        ax,
        source=ctx.providers.CartoDB.PositronNoLabels,
        zorder=0,
        zoom=zoom,
    )

    return ax


def add_north_arrow(ax, x=0.95, y=0.05, arrow_length=0.04):
    """Add a north arrow to the map."""
    # Add north arrow, https://stackoverflow.com/a/58110049/604456
    ax.annotate(
        "N",
        xy=(x, y),
        xytext=(x, y - arrow_length),
        arrowprops=dict(facecolor="black", width=3, headwidth=10),
        ha="center",
        va="center",
        fontsize=14,
        xycoords=ax.transAxes,
    )


def add_la_plata_outline(ax, color="black"):
    """Add the outline of Partido de La Plata to a map as the top layer."""
    la_plata_3857 = la_plata.to_crs(WEB_MERCATOR_CRS)
    la_plata_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor=color,
        linewidth=0.5,
        linestyle="--",
        legend=False,
        zorder=100,  # Ensure it's always on top
    )


def add_boundary_outline(ax, boundary_gdf, crs="EPSG:3857"):
    """Add the outline of a boundary geodataframe to a map."""
    boundary_3857 = boundary_gdf.to_crs(crs)
    boundary_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor="black",
        linewidth=0.5,
        linestyle="--",
        legend=False,
        zorder=5,
    )


def create_consistent_map(title, boundary_gdf=None, bounds=None):
    """Create a map with consistent styling and basemap."""
    fig, ax = setup_base_map(bounds=bounds, boundary_gdf=boundary_gdf)

    add_basemap(ax)

    add_north_arrow(ax)

    if boundary_gdf is not None:
        add_boundary_outline(ax, boundary_gdf)
    else:
        add_la_plata_outline(ax)

    ax.set_title(title, fontsize=16, fontweight="bold", pad=20)

    ax.set_axis_off()

    return fig, ax


def wfs_to_gdf(
    wfs_url: str, layer_name: str, srs: str = "EPSG:4326"
) -> gpd.GeoDataFrame:
    """
    Descarga una capa WFS y la devuelve como GeoDataFrame.

    Args:
        wfs_url (str): URL del servicio WFS.
        layer_name (str): Nombre de la capa (typename).
        srs (str): Código EPSG del sistema de referencia de coordenadas.

    Returns:
        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.
    """
    wfs = WebFeatureService(url=wfs_url, version="2.0.0")
    response = wfs.getfeature(typename=layer_name, srsname=srs)
    gdf = gpd.read_file(BytesIO(response.read()))
    return gdf


def create_exposure_tidy_data(
    data,
    id_column,
    peligrosidad_column,
    method_suffix,
    exposure_values,
    exclude_zero=True,
):
    """
    Create tidy exposure dataset in a standardized format.

    Args:
        data: DataFrame containing the base data
        id_column: Column name for the identifier (e.g., 'id_renabap', 'Cuenca', 'eje')
        peligrosidad_column: Column name for hazard level
        method_suffix: Suffix for the exposure column (e.g., 'areal', 'ghsl', 'edificios')
        exposure_values: Series or array of exposure values matching data rows
        exclude_zero: Whether to exclude zero exposure values

    Returns:
        pd.DataFrame: Tidy format dataframe with id, peligrosidad, and exposure columns
    """
    tidy_data = []
    for idx, (_, row) in enumerate(data.iterrows()):
        exposure_value = (
            exposure_values.iloc[idx]
            if hasattr(exposure_values, "iloc")
            else exposure_values[idx]
        )

        if exclude_zero and exposure_value <= 0:
            continue

        tidy_data.append(
            {
                id_column: row[id_column],
                "peligrosidad": row[peligrosidad_column],
                f"fam_expuestas_{method_suffix}": exposure_value,
            }
        )

    return pd.DataFrame(tidy_data)


def create_wide_exposure_dataframe(
    areal_data, ghsl_data, buildings_data, id_columns, exclude_hazard_value="none"
):
    """
    Create wide format exposure dataframe by merging tidy datasets.

    Args:
        areal_data: Tidy dataframe with areal interpolation results
        ghsl_data: Tidy dataframe with GHSL dasymetric results
        buildings_data: Tidy dataframe with buildings dasymetric results
        id_columns: List of columns to merge on (e.g., ['id_renabap', 'peligrosidad'])
        exclude_hazard_value: Hazard value to exclude from results

    Returns:
        pd.DataFrame: Wide format dataframe with all exposure methods
    """
    # Filter out non-hazard values
    areal_filtered = areal_data[areal_data["peligrosidad"] != exclude_hazard_value]
    ghsl_filtered = ghsl_data[ghsl_data["peligrosidad"] != exclude_hazard_value]
    buildings_filtered = buildings_data[
        buildings_data["peligrosidad"] != exclude_hazard_value
    ]

    # Apply column mapping for buildings if needed
    if "fam_expuestas_buildings" in buildings_filtered.columns:
        buildings_filtered = buildings_filtered.rename(
            columns={"fam_expuestas_buildings": "fam_expuestas_edificios"}
        )

    # Merge all datasets
    wide_data = areal_filtered.merge(ghsl_filtered, on=id_columns, how="outer").merge(
        buildings_filtered, on=id_columns, how="outer"
    )

    # Fill NaN values with 0
    wide_data = wide_data.fillna(0)

    # Rename columns to shorter format
    column_mapping = {
        "fam_expuestas_areal": "fam_exp_areal",
        "fam_expuestas_ghsl": "fam_exp_ghsl",
        "fam_expuestas_edificios": "fam_exp_edificios",
    }
    wide_data = wide_data.rename(columns=column_mapping)

    return wide_data


response = requests.get(RENABAP_URL)
renabap = gpd.read_file(StringIO(response.text))
renabap_pba = renabap[renabap["provincia"] == "Buenos Aires"]
renabap_pba = renabap_pba.to_crs(USE_CRS)

peligro = gpd.read_file(PELIGRO_PATH)
peligro = peligro.to_crs(USE_CRS)

peligro_bounds = peligro.total_bounds
peligro_bbox = box(*peligro_bounds)

if os.path.exists(PARTIDOS_PATH):
    partidos = gpd.read_file(PARTIDOS_PATH)
else:
    partidos = wfs_to_gdf(
        wfs_url=PARTIDOS_WFS_URL,
        layer_name="idera:Departamento",
        srs="EPSG:5347",
    )

    partidos.to_file(PARTIDOS_PATH, driver="GeoJSON")

partidos = partidos.to_crs(USE_CRS)
la_plata = partidos[partidos["fna"] == "Partido de La Plata"]

# Obtener la geometría principal
main_geom = la_plata.geometry.iloc[0]

# Si es un MultiPolygon, mantener solo el polígono más grande (el partido principal)
# Esto elimina la pequeña isla que aparece en los datos
if main_geom.geom_type == "MultiPolygon":
    # Obtener todos los polígonos y mantener el que tenga mayor área
    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)
    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning
    la_plata.loc[la_plata.index[0], "geometry"] = largest_polygon

la_plata_bbox = la_plata.geometry.iloc[0]

renabap_pba_intersect = renabap_pba[
    renabap_pba.geometry.intersects(la_plata_bbox)
].copy()


if os.path.exists(CUENCAS_PATH):
    cuencas = gpd.read_file(CUENCAS_PATH)
else:
    params = {"where": "1=1", "outFields": "*", "f": "geojson"}

    cuencas_response = requests.get(CUENCAS_API_URL, params=params)
    with open(CUENCAS_PATH, "w", encoding="utf-8") as f:
        f.write(cuencas_response.text)

    cuencas = gpd.read_file(StringIO(cuencas_response.text))

cuencas = cuencas.to_crs(USE_CRS)
cuencas = cuencas.clip(la_plata)

# Map watershed names to axes based on the EJE_MAPPING
cuencas["eje"] = (
    cuencas["Cuenca"]
    .map(
        {
            cuenca: eje
            for eje, cuencas_list in EJE_MAPPING.items()
            for cuenca in cuencas_list
        }
    )
    .fillna("otro")
)

# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)
renabap_total_area_ha = (
    renabap_pba_intersect.geometry.area.sum() / 10000
)  # Convert m² to hectares
la_plata_area_ha = la_plata.geometry.iloc[0].area / 10000
percentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100

# Get common bounds for all maps
common_bounds = la_plata.total_bounds

# Intersect settlements with hazard zones
settlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how="intersection")

settle_hazard_cuencas = gpd.overlay(
    settlement_hazard, cuencas, how="intersection", keep_geom_type=True
)
```

## Fuentes de datos

### RENABAP
El Registro Nacional de Barrios Populares (RENABAP) es producido por la Subsecretaría de Integración Socio Urbana y proporciona información sobre asentamientos informales en Argentina, incluyendo estimaciones de población y delimitaciones geográficas de estos barrios. Más información sobre el RENABAP está disponible en el [Observatorio de Barrios Populares](https://www.argentina.gob.ar/obras-publicas/sisu/renabap/observatorio-de-barrios-populares). Los datos fueron obtenidos a través del [Mapa de Barrios Populares](https://www.argentina.gob.ar/obras-publicas/sisu/renabap/mapa) y están disponibles para [descarga como GeoJSON](https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson).

```{python}

```

### Peligro de inundación

Los datos de peligro de inundación utilizados en este análisis fueron desarrollados por la Facultad de Ingeniería de la Universidad Nacional de La Plata como parte del Plan de Reducción del Riesgo por Inundaciones en la Región de La Plata [@romanazzi2019]. Estos datos fueron generados mediante la aplicación del modelo hidrológico-hidráulico bidimensional FLO-2D, que permitió simular la dinámica de inundación de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviométricos extremos. El modelo calcula las principales variables hidráulicas (altura del agua, velocidad y caudal) a lo largo del tiempo, y a partir de estos resultados se generaron los mapas de peligrosidad que combinan el efecto de la profundidad con la velocidad de la corriente, ofreciendo un indicador más completo que los mapas tradicionales de máximas profundidades.

```{python}

```

### Google-Microsoft-OSM Open Buildings

Los datos de [Google-Microsoft-OSM Open Buildings - combined by VIDA](https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access) [@google_microsoft_osm_buildings] representan una forma más precisa de evaluar dónde se ubican los asentamientos humanos. Este conjunto de datos combina Google's V3 Open Buildings, Microsoft's GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo más de 2.7 mil millones de huellas de edificios. Estos datos han sido [exitosamente aplicados a evaluaciones de riesgo de inundación por empresas globales de riesgo financiero como ICE](https://www.ice.com/insights/sustainable-finance/ice-climates-exposure-datasets-understanding-how-climate-risks-impact-infrastructure-and-communities), demostrando su utilidad para mapear la exposición climática a nivel de huella de edificio individual. Sin embargo, en ausencia de información sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el número total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de dónde se ubican las personas, sin tener una comprensión precisa de quién vive realmente allí y cuántas personas.

```{python}
def fetch_buildings(geodataframe, temp_file="buildings_filtered.parquet"):
    """Fetch building data for a given GeoDataFrame region"""

    # Get S2 cell and bounds
    center = geodataframe.to_crs(WEB_MERCATOR_CRS).union_all().centroid
    center_wgs84 = (
        gpd.GeoDataFrame(geometry=[center], crs=WEB_MERCATOR_CRS)
        .to_crs(WGS84_CRS)
        .geometry.iloc[0]
    )
    cell = s2sphere.CellId.from_lat_lng(
        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)
    ).parent(10)
    bounds = geodataframe.to_crs(WGS84_CRS).total_bounds

    # Find matching S2 partition
    s3 = boto3.client(
        "s3",
        endpoint_url="https://data.source.coop",
        aws_access_key_id="",
        aws_secret_access_key="",
        config=Config(s3={"addressing_style": "path"}),
    )

    partitions = {
        obj["Key"].split("/")[-1].replace(".parquet", "")
        for obj in s3.list_objects_v2(
            Bucket="vida",
            Prefix="google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/",
        ).get("Contents", [])
    }

    parent_id = next(
        str(cell.parent(level).id())
        for level in range(10, 0, -1)
        if str(cell.parent(level).id()) in partitions
    )

    # Setup DuckDB and query
    con = duckdb.connect()
    for cmd in [
        "INSTALL spatial",
        "LOAD spatial",
        "INSTALL httpfs",
        "LOAD httpfs",
        "SET s3_region='us-east-1'",
        "SET s3_endpoint='data.source.coop'",
        "SET s3_use_ssl=true",
        "SET s3_url_style='path'",
    ]:
        con.execute(cmd)

    # Export and read back
    query = f"""
    COPY (SELECT * FROM 's3://vida/google-microsoft-osm-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'
          WHERE bbox.xmax >= {bounds[0]} AND bbox.xmin <= {bounds[2]} AND
                bbox.ymax >= {bounds[1]} AND bbox.ymin <= {bounds[3]}
    ) TO '{temp_file}' (FORMAT PARQUET);
    """

    con.execute(query)
    df = pd.read_parquet(temp_file)
    df["geometry"] = gpd.GeoSeries.from_wkb(df["geometry"])

    return gpd.GeoDataFrame(df, geometry="geometry", crs=WGS84_CRS)


if os.path.exists(BUILDINGS_PATH):
    buildings = gpd.read_parquet(BUILDINGS_PATH)
else:
    buildings = fetch_buildings(renabap_pba_intersect)


buildings_proj = buildings.to_crs(USE_CRS)

buildings_proj = buildings_proj.clip(la_plata)

```

## Contexto

```{python}
# Calcular variables para el contexto
total_barrios = int(len(renabap_pba_intersect))
total_familias = int(renabap_pba_intersect['familias_aproximadas'].sum())
area_barrios_ha = int(renabap_total_area_ha)
porcentaje_cobertura = float(round(percentage_coverage, 1))

# Obtener total de edificaciones en La Plata
total_buildings_la_plata = len(buildings_proj)

# Obtener todas las edificaciones que intersectan con los barrios (corregir warning de deprecación)
buildings_in_barrios = buildings_proj[
    buildings_proj.geometry.intersects(renabap_pba_intersect.union_all())
]
total_buildings_in_barrios = len(buildings_in_barrios)

# Calcular porcentaje de edificaciones en barrios
buildings_percentage = float(round((total_buildings_in_barrios / total_buildings_la_plata) * 100, 1))

# Helper function to format numbers with commas
def format_number(num):
    return f"{num:,}"

# Recortar peligro por la plata
peligro_la_plata = peligro.clip(la_plata)

# Calcular área para cada tipo de peligro en hectáreas
peligro_areas = (
    peligro_la_plata.groupby("PELIGROSID")["geometry"]
    .apply(
        lambda x: x.area.sum() / 10000  # Convertir m² a hectáreas
    )
    .reset_index()
)
peligro_areas.columns = ["tipo_peligro", "area_ha"]

# Calcular porcentajes
peligro_areas["porcentaje"] = (peligro_areas["area_ha"] / la_plata_area_ha) * 100

# Variables para cada nivel de peligro (convertir a float Python nativo)
peligro_alta_ha = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "alta"]["area_ha"].iloc[0], 1))
peligro_alta_pct = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "alta"]["porcentaje"].iloc[0], 1))
peligro_media_ha = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "media"]["area_ha"].iloc[0], 1))
peligro_media_pct = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "media"]["porcentaje"].iloc[0], 1))
peligro_baja_ha = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "baja"]["area_ha"].iloc[0], 1))
peligro_baja_pct = float(round(peligro_areas[peligro_areas["tipo_peligro"] == "baja"]["porcentaje"].iloc[0], 1))

# Área total cubierta por zonas de peligro (convertir a float Python nativo)
area_total_peligro_ha = float(round(peligro_areas['area_ha'].sum(), 1))
porcentaje_total_peligro = float(round(peligro_areas['porcentaje'].sum(), 1))
```

Hay un total de `{python} format_number(total_barrios)` barrios populares en el Partido de La Plata, que representan `{python} format_number(total_familias)` familias. Estos barrios ocupan `{python} format_number(area_barrios_ha)` hectáreas del Partido de La Plata, o `{python} porcentaje_cobertura` por ciento del partido. El análisis de edificaciones revela un total de `{python} format_number(total_buildings_la_plata)` edificaciones en La Plata, de las cuales `{python} format_number(total_buildings_in_barrios)` se encuentran en barrios populares (`{python} buildings_percentage`% del total). En cuanto a las zonas de peligro de inundación, el territorio incluye `{python} format_number(int(peligro_alta_ha))` hectáreas de peligro alto (`{python} peligro_alta_pct`% del partido), `{python} format_number(int(peligro_media_ha))` hectáreas de peligro medio (`{python} peligro_media_pct`% del partido), y `{python} format_number(int(peligro_baja_ha))` hectáreas de peligro bajo (`{python} peligro_baja_pct`% del partido). El área total cubierta por zonas de peligro es de `{python} format_number(int(area_total_peligro_ha))` hectáreas, representando `{python} porcentaje_total_peligro`% del partido.

```{python}
# | cache: true
# | layout-ncol: 3
# | label: fig-fuentes-datos
# | fig-cap: "Fuentes de datos para análisis de exposición"
# | fig-subcap:
# |   - "Asentamientos RENABAP en La Plata"
# |   - "Zonas de Peligro en La Plata"
# |   - "Huellas de edificios"
# | lightbox:
# |   group: fuentes-datos

fig1, ax1 = create_consistent_map("Asentamientos RENABAP en La Plata", boundary_gdf=la_plata, bounds=common_bounds)

renabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(WEB_MERCATOR_CRS)

renabap_pba_intersect_3857.plot(
    ax=ax1, facecolor="none", edgecolor="black", linewidth=0.5, legend=False, zorder=10
)

plt.tight_layout()
plt.show()

peligro_clipped = gpd.clip(peligro, la_plata)

peligro_clipped_3857 = peligro_clipped.to_crs(WEB_MERCATOR_CRS)

# Reorder the categories so they map correctly to plasma colormap
peligro_clipped_3857["PELIGROSID_ordered"] = pd.Categorical(
    peligro_clipped_3857["PELIGROSID"],
    categories=["baja", "media", "alta"],
    ordered=True,
)


fig2, ax2 = create_consistent_map("Zonas de Peligro en La Plata", boundary_gdf=la_plata, bounds=common_bounds)


peligro_clipped_3857.plot(
    ax=ax2,
    column="PELIGROSID_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    zorder=5,
)

plt.tight_layout()
plt.show()


fig3, ax3 = create_consistent_map("Huellas de edificios", boundary_gdf=la_plata, bounds=common_bounds)

buildings_3857 = buildings_proj.to_crs(WEB_MERCATOR_CRS)

buildings_3857.plot(ax=ax3, facecolor="grey", edgecolor="none", alpha=0.7)

plt.tight_layout()
plt.show()
```



## Metodología

En versiones anteriores de este análisis, el trabajo se realizó mediante una interpolación areal simple del porcentaje de superposición de cada área de peligro de inundación con los asentamientos informales. Este enfoque presenta dos problemas fundamentales que este estudio busca abordar.

El primer problema es que la interpolación areal es inherentemente imprecisa, ya que asume lo que se conoce como el [problema de la unidad areal modificable](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/modifiable-areal-unit-problem) y presupone que la población se distribuye uniformemente en el espacio. Sin embargo, estudios sobre modelado de riesgo de inundación con conjuntos de datos globales han demostrado que evaluar la exposición a esta escala de resolución puede llevar a sobreestimaciones de la exposición poblacional en zonas de peligro de inundación en comparación con datos de mayor resolución [@smith2019]. La población, de hecho, no se distribuye uniformemente en el espacio; frecuentemente los edificios se agrupan ya sea alejándose de las zonas de peligro de inundación o concentrándose en zonas de alto peligro de inundación. Por tanto, es fundamental comprender con estimaciones más precisas dónde vive realmente la gente.

El segundo problema radica en que los propios datos del RENABAP, según nuestro análisis aquí presentado, parecen contar dramáticamente de forma incorrecta, frecuentemente por un factor de dos o más, el número de familias que aparentemente viven en un asentamiento informal basándose en el número de edificaciones. Esto probablemente se debe a errores de proyección acumulados a lo largo del tiempo y a la dificultad de mantener actualizados los datos de asentamientos informales.

Esta es una de las grandes ventajas de las huellas de edificios globales derivadas de satélite que han surgido en los últimos años de Google-Microsoft-OSM, entre otros. Uno de los objetivos principales de este análisis es demostrar que estos datos de huellas de edificios pueden utilizarse para estimar la exposición de manera más precisa, tanto en términos de precisión metodológica como en términos de mejora sobre conjuntos de datos nacionales existentes como el RENABAP.

Por tanto, en este estudio utilizamos el número de edificios que intersectan con las diferentes zonas de peligro de inundación como indicador de exposición, asumiendo que un edificio equivale aproximadamente a una familia, supuesto que el propio RENABAP asume en sus datos.

```{python}
## Análisis de exposición: edificios por barrio y cuenca por zona de peligro
# Versión concisa con spatial joins (sin warnings)

import geopandas as gpd

# Definir orden de prioridad de peligro y simplificar
hazard_priority = {"alta": 3, "media": 2, "baja": 1}
peligro_simple = peligro_la_plata.dissolve(by="PELIGROSID").reset_index()

# === ANÁLISIS POR BARRIO ===
# Spatial joins
buildings_with_barrios = gpd.sjoin(
    buildings_proj,
    renabap_pba_intersect[
        ["id_renabap", "nombre_barrio", "familias_aproximadas", "geometry"]
    ],
    how="inner",
    predicate="within",
)
buildings_with_barrios = buildings_with_barrios.drop(columns=["index_right"]).copy()

buildings_with_peligro_barrio = gpd.sjoin(
    buildings_with_barrios,
    peligro_simple[["PELIGROSID", "geometry"]],
    how="left",
    predicate="within",
)

# Resolver duplicados y contar
buildings_barrio_final = buildings_with_peligro_barrio.dropna(
    subset=["PELIGROSID"]
).copy()
buildings_barrio_final.loc[:, "prioridad"] = buildings_barrio_final["PELIGROSID"].map(
    hazard_priority
)
buildings_barrio_unique = buildings_barrio_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_barrio_final.geometry.name, keep="first")

# Calcular exposición por barrio
edificios_por_barrio_peligro = (
    buildings_barrio_unique.groupby(["id_renabap", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_barrio = (
    buildings_with_barrios.groupby("id_renabap")
    .size()
    .reset_index(name="total_edificios")
)

exposure_barrio = edificios_por_barrio_peligro.merge(
    total_edificios_barrio, on="id_renabap"
)
exposure_barrio["proporcion"] = (
    exposure_barrio["edificios_expuestos"] / exposure_barrio["total_edificios"]
)

familias_barrio = renabap_pba_intersect[
    ["id_renabap", "nombre_barrio", "familias_aproximadas"]
].drop_duplicates()
final_exposure_barrio = exposure_barrio.merge(familias_barrio, on="id_renabap")
final_exposure_barrio["fam_expuestas"] = (
    final_exposure_barrio["proporcion"] * final_exposure_barrio["familias_aproximadas"]
)

resultado_exposicion_barrio = final_exposure_barrio[
    [
        "id_renabap",
        "nombre_barrio",
        "PELIGROSID",
        "fam_expuestas",
        "edificios_expuestos",
    ]
].rename(columns={"PELIGROSID": "peligrosidad"})

# === ANÁLISIS POR CUENCA ===
# Usar edificios ya en barrios para análisis de cuenca
buildings_in_settlements = buildings_with_barrios.copy()

# Spatial joins para cuenca
buildings_with_cuenca = gpd.sjoin(
    buildings_in_settlements,
    cuencas[["Cuenca", "eje", "geometry"]],
    how="left",
    predicate="within",
)
buildings_with_cuenca = buildings_with_cuenca.drop(columns=["index_right"]).copy()

buildings_with_peligro_cuenca = gpd.sjoin(
    buildings_in_settlements,
    peligro_simple[["PELIGROSID", "geometry"]],
    how="left",
    predicate="within",
)

# Combinar y filtrar
buildings_cuenca_final = buildings_in_settlements.copy()
buildings_cuenca_final.loc[:, "Cuenca"] = buildings_with_cuenca["Cuenca"]
buildings_cuenca_final.loc[:, "eje"] = buildings_with_cuenca["eje"]
buildings_cuenca_final.loc[:, "PELIGROSID"] = buildings_with_peligro_cuenca[
    "PELIGROSID"
]
buildings_cuenca_final = buildings_cuenca_final.dropna(
    subset=["Cuenca", "PELIGROSID"]
).copy()

# Resolver duplicados y calcular exposición por cuenca
buildings_cuenca_final.loc[:, "prioridad"] = buildings_cuenca_final["PELIGROSID"].map(
    hazard_priority
)
buildings_cuenca_unique = buildings_cuenca_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_cuenca_final.geometry.name, keep="first")

edificios_por_cuenca_peligro = (
    buildings_cuenca_unique.groupby(["Cuenca", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_cuenca = (
    buildings_with_cuenca.dropna(subset=["Cuenca"])
    .groupby("Cuenca")
    .size()
    .reset_index(name="total_edificios")
)

exposure_cuenca = edificios_por_cuenca_peligro.merge(
    total_edificios_cuenca, on="Cuenca"
)
exposure_cuenca["proporcion"] = (
    exposure_cuenca["edificios_expuestos"] / exposure_cuenca["total_edificios"]
)

familias_cuenca = (
    settle_hazard_cuencas.drop_duplicates("id_renabap")
    .groupby("Cuenca")["familias_aproximadas"]
    .sum()
    .reset_index()
)

final_exposure_cuenca = exposure_cuenca.merge(familias_cuenca, on="Cuenca")
final_exposure_cuenca["fam_expuestas"] = (
    final_exposure_cuenca["proporcion"] * final_exposure_cuenca["familias_aproximadas"]
)

resultado_exposicion_cuenca = final_exposure_cuenca[
    ["Cuenca", "PELIGROSID", "fam_expuestas", "edificios_expuestos"]
].rename(columns={"PELIGROSID": "peligrosidad"})

# === ANÁLISIS POR EJE ===
# Usar los edificios ya procesados con cuenca y peligro
buildings_eje_final = buildings_cuenca_final.dropna(subset=["eje"]).copy()

# Resolver duplicados por prioridad de peligro
buildings_eje_final.loc[:, "prioridad"] = buildings_eje_final["PELIGROSID"].map(
    hazard_priority
)
buildings_eje_unique = buildings_eje_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_eje_final.geometry.name, keep="first")

# Calcular exposición por eje y peligrosidad
edificios_por_eje_peligro = (
    buildings_eje_unique.groupby(["eje", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_eje = (
    buildings_with_cuenca.dropna(subset=["eje"])
    .groupby("eje")
    .size()
    .reset_index(name="total_edificios")
)

exposure_eje = edificios_por_eje_peligro.merge(total_edificios_eje, on="eje")
exposure_eje["proporcion"] = (
    exposure_eje["edificios_expuestos"] / exposure_eje["total_edificios"]
)

familias_por_eje = (
    settle_hazard_cuencas.drop_duplicates("id_renabap")
    .groupby("eje")["familias_aproximadas"]
    .sum()
    .reset_index()
)

final_exposure_eje = exposure_eje.merge(familias_por_eje, on="eje")
final_exposure_eje["fam_expuestas"] = (
    final_exposure_eje["proporcion"] * final_exposure_eje["familias_aproximadas"]
)

resultado_exposicion_eje = final_exposure_eje[
    ["eje", "PELIGROSID", "fam_expuestas", "edificios_expuestos"]
].rename(columns={"PELIGROSID": "peligrosidad"})
```

### Análisis de las limitaciones de los datos del RENABAP

Observamos que los datos más recientes del RENABAP de 2023 frecuentemente y significativamente subestiman el número total de familias por asentamiento informal. Los datos de 2023 fueron basados en proyecciones derivadas del censo de 2010. Aquí comparamos estos datos con el número de huellas de edificios por asentamiento informal. Podemos asumir razonablemente que hay mínimamente una correspondencia uno a uno entre unidades de vivienda y familias, que es lo que los propios datos del RENABAP asumen. Encontramos que usando este método, los datos del RENABAP frecuentemente están desactualizados por una cantidad significativa. En promedio, subestiman el número de estructuras habitacionales por 41%, lo que equivale a aproximadamente 1.7 veces más familias por asentamiento de lo que aparecen en los datos del RENABAP.

```{python}
# | label: fig-error-renabap
# | fig-cap: "Distribución del error porcentual en las estimaciones del RENABAP comparado con estimaciones basadas en edificios"

import matplotlib.pyplot as plt

# Calcular familias estimadas basadas en edificios (1.1 familias por edificio)
ratio_fam_edif = (
    buildings_with_barrios.groupby(["id_renabap", "familias_aproximadas"])
    .size()
    .reset_index(name="total_edificios")
)

ratio_fam_edif["familias_estimadas_edificios"] = ratio_fam_edif["total_edificios"] * 1.1
# Calcular el error porcentual: (RENABAP - Edificios) / Edificios * 100
ratio_fam_edif["error_porcentual"] = (
    (
        ratio_fam_edif["familias_aproximadas"]
        - ratio_fam_edif["familias_estimadas_edificios"]
    )
    / ratio_fam_edif["familias_estimadas_edificios"]
) * 100

# Crear histograma
plt.figure(figsize=(12, 6))
plt.hist(
    ratio_fam_edif["error_porcentual"],
    bins=30,
    edgecolor="none",
    color=PELIGROSIDAD_COLORS["alta"],
)

# Personalizar el gráfico
plt.title(
    "Error de Estimación de RENABAP vs Estimación por Edificios",
    fontsize=16,
    fontweight="bold",
)
plt.xlabel("Error Porcentual (%)", fontsize=12)
plt.ylabel("Frecuencia (Número de Barrios)", fontsize=12)

# Agregar líneas de referencia
mean_error = ratio_fam_edif["error_porcentual"].mean()
median_error = ratio_fam_edif["error_porcentual"].median()

plt.axvline(
    mean_error,
    color="black",
    linestyle="--",
    linewidth=2,
    label=f"Error promedio: {mean_error:.1f}%",
)
plt.axvline(
    median_error,
    color="black",
    linestyle="dotted",
    linewidth=2,
    label=f"Error mediano: {median_error:.1f}%",
)


plt.legend()
plt.tight_layout()
plt.show()
```

También podemos examinar imágenes satelitales de un asentamiento informal de muestra con las huellas de edificios superpuestas para tener una idea de la veracidad de los datos. Aquí está un barrio llamado Los Pinos, en el cual mapeamos la extensión del RENABAP del barrio y las huellas de los edificios dentro de él. Las estimaciones del RENABAP dicen que este asentamiento informal tiene solo 72 familias. Nuestros datos cuentan 519 edificios. Si usamos la estimación del RENABAP de aproximadamente 1.1 familias por edificio, que es lo que calculan en sus datos originales, estamos hablando de un total de 570 familias, que es casi ocho veces más de lo que los datos del RENABAP contabilizan.


```{python}
# | label: fig-ejemplo-barrio
# | fig-cap: "Ejemplo de discrepancia en los datos del RENABAP: el barrio Los Pinos con límites oficiales y edificaciones detectadas"

import matplotlib.pyplot as plt
import geopandas as gpd
import contextily as cx

# Filtrar para obtener solo el barrio con id_renabap 5688
barrio_5688 = renabap_pba_intersect[renabap_pba_intersect["id_renabap"] == 5688].copy()

if len(barrio_5688) == 0:
    print("No se encontró el barrio con id_renabap 5688")
else:
    # Obtener edificios en este barrio
    buildings_5688 = buildings_with_barrios[
        buildings_with_barrios["id_renabap"] == 5688
    ].copy()

    # Convertir a Web Mercator
    barrio_5688_3857 = barrio_5688.to_crs(WEB_MERCATOR_CRS)
    buildings_5688_3857 = buildings_5688.to_crs(WEB_MERCATOR_CRS)

    # Crear el mapa
    fig, ax = plt.subplots(figsize=(12, 10))

    # Configurar límites basados en el barrio
    bounds = barrio_5688_3857.total_bounds
    margin = 50  # metros
    ax.set_xlim(bounds[0] - margin, bounds[2] + margin)
    ax.set_ylim(bounds[1] - margin, bounds[3] + margin)

    # Agregar basemap de contextily
    cx.add_basemap(ax, crs="EPSG:3857", source=cx.providers.Esri.WorldImagery)

    # Plot de edificios con contorno naranja (sin fill)
    buildings_5688_3857.plot(
        ax=ax, facecolor="none", edgecolor=PLASMA_CMAP(1), linewidth=1
    )

    # Plot del límite del barrio con estilo consistente
    barrio_5688_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor="white",  # White for satellite imagery visibility
        linewidth=3,
        linestyle="--",
        zorder=10,
    )

    # Limpiar el mapa
    barrio_nombre = barrio_5688["nombre_barrio"].iloc[0]
    ax.set_title(
        f"Barrio {barrio_nombre} - Límites y Edificaciones",
        fontsize=14,
        fontweight="bold",
        pad=20,
    )
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xlabel("")
    ax.set_ylabel("")
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)
    ax.spines["left"].set_visible(False)

    # Agregar leyenda simple
    legend_elements = [
        plt.Line2D([0], [0], color="white", linewidth=3, label="Límite del barrio"),
        plt.Line2D([0], [0], color=PLASMA_CMAP(1), linewidth=1, label="Edificaciones"),
    ]
    ax.legend(handles=legend_elements, loc="upper right")

    plt.tight_layout()
    plt.show()
```

## Procesamiento y resultados

La exposición en asentamientos informales se concentra principalmente en los alrededores del casco urbano de La Plata. El análisis revela una distribución característica donde un número pequeño de barrios presenta exposición muy alta, seguido por un grupo de exposición media, y luego una disminución gradual. Villa Montoro lidera con 555 edificaciones expuestas a peligro alto, seguida por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. Otros barrios con exposición significativa incluyen Aeropuerto (258), 48 y 144 (225), San Luis (206), y El Uido (132).

A nivel de cuencas hidrográficas, la Cuenca Arroyo del Gato concentra la mayor exposición con 2,662 edificaciones expuestas a peligro alto, principalmente debido a la presencia de Villa Montoro y otros asentamientos importantes. Le sigue la Cuenca A° Maldonado con 1,000 edificaciones y la Cuenca Arroyo Martín-Carnaval con 368. Esta concentración en la Cuenca Arroyo del Gato refleja tanto la densidad de asentamientos informales como su ubicación en zonas de alto riesgo hidrológico.

### Exposición por barrio

```{python}
# | label: fig-exposicion-barrios
# | fig-cap: "Mapa de exposición de barrios populares por nivel de peligrosidad de inundación"

import matplotlib.pyplot as plt
import geopandas as gpd
import contextily as cx

# Colores para peligrosidad
PELIGROSIDAD_COLORS = {
    "alta": PLASMA_CMAP(0.8),
    "media": PLASMA_CMAP(0.5),
    "baja": PLASMA_CMAP(0.2),
}


# Preparar datos - solo alta y media
exposure_data = resultado_exposicion_barrio[
    resultado_exposicion_barrio["peligrosidad"].isin(["alta", "media"])
].copy()

# Merge con geometrías para obtener centroides
exposure_gdf = exposure_data.merge(
    renabap_pba_intersect[["id_renabap", "geometry"]], on="id_renabap"
)
exposure_gdf = gpd.GeoDataFrame(exposure_gdf, geometry="geometry", crs=USE_CRS)

# Convertir a Web Mercator para el plotting
exposure_gdf_3857 = exposure_gdf.to_crs("EPSG:3857")
la_plata_3857 = la_plata.to_crs("EPSG:3857")

# Crear el mapa
fig, ax = plt.subplots(figsize=(12, 10))

# Configurar límites
bounds = la_plata_3857.total_bounds
margin = 2000  # metros
ax.set_xlim(bounds[0] - margin, bounds[2] + margin)
ax.set_ylim(bounds[1] - margin, bounds[3] + margin)

# Agregar basemap de contextily
cx.add_basemap(
    ax, crs="EPSG:3857", source=cx.providers.CartoDB.PositronNoLabels, alpha=0.7
)

# Plot de puntos con jitter
np.random.seed(42)
plotting_order = ["media", "alta"]

for peligrosidad in plotting_order:
    level_data = exposure_gdf_3857[exposure_gdf_3857["peligrosidad"] == peligrosidad]
    for _, row in level_data.iterrows():
        centroid = row["geometry"].centroid
        jitter_x = np.random.uniform(-200, 200)
        jitter_y = np.random.uniform(-200, 200)
        x_pos = centroid.x + jitter_x
        y_pos = centroid.y + jitter_y
        color = PELIGROSIDAD_COLORS[row["peligrosidad"]]
        size = max(10, row["edificios_expuestos"] * 0.5 + 15)
        ax.scatter(
            x_pos,
            y_pos,
            s=size,
            color=color,
            alpha=0.9,
            edgecolors="white",
            linewidth=1.0,
        )

# Leyenda de peligrosidad
legend_elements_peligro = [
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor=PELIGROSIDAD_COLORS["alta"],
        markersize=8,
        label="Alta",
    ),
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor=PELIGROSIDAD_COLORS["media"],
        markersize=8,
        label="Media",
    ),
]

# Leyenda de tamaño
building_values = [100, 500, 1000]
legend_elements_size = []
for val in building_values:
    size = max(10, val * 0.5 + 15)
    legend_elements_size.append(
        plt.Line2D(
            [0],
            [0],
            marker="o",
            color="w",
            markerfacecolor="gray",
            markersize=np.sqrt(size / 10),
            label=f"{val} edificios",
        )
    )

# Crear leyendas lado a lado en bottom right
legend1 = ax.legend(
    handles=legend_elements_peligro,
    title="Nivel de peligrosidad",
    loc="lower right",
    bbox_to_anchor=(0.85, 0),
)
ax.add_artist(legend1)

legend2 = ax.legend(
    handles=legend_elements_size,
    title="Edificios expuestos",
    loc="lower right",
    bbox_to_anchor=(1.0, 0),
)

# Agregar el contorno de La Plata como capa superior
add_la_plata_outline(ax)

# Agregar flecha norte para consistencia
add_north_arrow(ax)

# Limpiar el mapa - quitar bordes, ticks, etc.
ax.set_title(
    "Exposición de Barrios Populares por Nivel de Peligrosidad",
    fontsize=14,
    fontweight="bold",
    pad=20,
)
ax.set_axis_off()

plt.tight_layout()
plt.show()

# | label: fig-top-barrios-peligro-alto
# | fig-cap: "Los 25 barrios con mayor número de edificaciones expuestas a peligro alto de inundación"

import matplotlib.pyplot as plt

# Filtrar solo exposición alta y agregar por nombre de barrio (excluyendo "Sin Nombre")
edificios_alta_por_nombre = (
    resultado_exposicion_barrio[
        (resultado_exposicion_barrio["peligrosidad"] == "alta")
        & (resultado_exposicion_barrio["nombre_barrio"] != "Sin Nombre")
    ]
    .groupby("nombre_barrio")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
    .head(25)
)

# Crear el gráfico de barras
plt.figure(figsize=(12, 8))
bars = plt.bar(
    range(len(edificios_alta_por_nombre)),
    edificios_alta_por_nombre["edificios_expuestos"],
    color=PELIGROSIDAD_COLORS["alta"],
    edgecolor="none",
)

# Personalizar el gráfico
plt.title(
    "Top 25 Barrios por Edificaciones Expuestas a Peligro Alto",
    fontsize=16,
    fontweight="bold",
)
plt.xlabel("Barrios", fontsize=12)
plt.ylabel("Edificaciones Expuestas (Peligro Alto)", fontsize=12)
plt.xticks(
    range(len(edificios_alta_por_nombre)),
    edificios_alta_por_nombre["nombre_barrio"],
    rotation=45,
    ha="right",
)

# Agregar valores en las barras
for i, bar in enumerate(bars):
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2.0,
        height + 5,
        f"{int(height)}",
        ha="center",
        va="bottom",
        fontsize=9,
    )

plt.tight_layout()
plt.show()

show(resultado_exposicion_barrio)
```

### Exposición por cuenca
```{python}
# | label: fig-exposicion-cuencas
# | fig-cap: "Cuencas hidrográficas ordenadas por número de edificaciones expuestas a peligro alto de inundación"

import matplotlib.pyplot as plt

# Filtrar solo exposición alta y agregar por cuenca
edificios_alta_por_cuenca = (
    resultado_exposicion_cuenca[resultado_exposicion_cuenca["peligrosidad"] == "alta"]
    .groupby("Cuenca")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
)

# Crear el gráfico de barras
plt.figure(figsize=(12, 6))
bars = plt.bar(
    range(len(edificios_alta_por_cuenca)),
    edificios_alta_por_cuenca["edificios_expuestos"],
    color=PELIGROSIDAD_COLORS["alta"],
    edgecolor="none",
)

# Personalizar el gráfico
plt.title(
    "Top Cuencas por Edificaciones Expuestas a Peligro Alto",
    fontsize=16,
    fontweight="bold",
)
plt.xlabel("Cuencas", fontsize=12)
plt.ylabel("Edificaciones Expuestas (Peligro Alto)", fontsize=12)
plt.xticks(
    range(len(edificios_alta_por_cuenca)),
    edificios_alta_por_cuenca["Cuenca"],
    rotation=45,
    ha="right",
)

# Agregar valores en las barras
for i, bar in enumerate(bars):
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2.0,
        height + 10,
        f"{int(height)}",
        ha="center",
        va="bottom",
        fontsize=10,
    )

plt.tight_layout()
plt.show()


show(resultado_exposicion_cuenca)

```

### Exposición por eje

```{python}
# | label: fig-exposicion-ejes
# | fig-cap: "Ejes territoriales ordenados por número de edificaciones expuestas a peligro alto de inundación"

import matplotlib.pyplot as plt

# Filtrar solo exposición alta y agregar por eje
edificios_alta_por_eje = (
    resultado_exposicion_eje[resultado_exposicion_eje["peligrosidad"] == "alta"]
    .groupby("eje")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
)

# Crear el gráfico de barras
plt.figure(figsize=(10, 6))
bars = plt.bar(
    range(len(edificios_alta_por_eje)),
    edificios_alta_por_eje["edificios_expuestos"],
    color=PELIGROSIDAD_COLORS["alta"],
    edgecolor="none",
)

# Personalizar el gráfico
plt.title(
    "Ejes por Edificaciones Expuestas a Peligro Alto",
    fontsize=16,
    fontweight="bold",
)
plt.xlabel("Ejes", fontsize=12)
plt.ylabel("Edificaciones Expuestas (Peligro Alto)", fontsize=12)
plt.xticks(
    range(len(edificios_alta_por_eje)),
    edificios_alta_por_eje["eje"],
    rotation=45,
    ha="right",
)

# Agregar valores en las barras
for i, bar in enumerate(bars):
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2.0,
        height + 10,
        f"{int(height)}",
        ha="center",
        va="bottom",
        fontsize=10,
    )

plt.tight_layout()
plt.show()

show(resultado_exposicion_eje)
```

## Comparativa de periodos de retorno

```{python}
# | cache: true
# | layout-ncol: 3
# | label: fig-escenarios-maldonado
# | fig-cap: "Escenarios de peligrosidad en Cuenca Maldonado"
# | fig-subcap:
# |   - "PMP (Precipitación Máxima Probable)"
# |   - "R100 (Período de retorno 100 años)"
# |   - "R25 (Período de retorno 25 años)"
# | lightbox:
# |   group: escenarios-maldonado

# Preparar datos de cuenca Maldonado para clipping
cuenca_maldonado = cuencas[cuencas["Cuenca"] == "Cuenca A° Maldonado"].copy()

# === MAPA PMP ===
# Clipear peligro PMP a cuenca Maldonado
peligro_pmp_maldonado = gpd.clip(peligro_la_plata, cuenca_maldonado)
peligro_pmp_maldonado_3857 = peligro_pmp_maldonado.to_crs(WEB_MERCATOR_CRS)

# Ordenar categorías para mapeo correcto
peligro_pmp_maldonado_3857["PELIGROSID_ordered"] = pd.Categorical(
    peligro_pmp_maldonado_3857["PELIGROSID"],
    categories=["baja", "media", "alta"],
    ordered=True,
)

fig1, ax1 = create_consistent_map("PMP (Precipitación Máxima Probable)", boundary_gdf=cuenca_maldonado)
peligro_pmp_maldonado_3857.plot(
    ax=ax1,
    column="PELIGROSID_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    zorder=5,
)
plt.tight_layout()
plt.show()

# === MAPA R100 ===
pelig_100_maldonado = gpd.read_file("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp")
pelig_100_maldonado = pelig_100_maldonado.to_crs(USE_CRS)

# Clipear a cuenca Maldonado
pelig_100_maldonado_clipped = gpd.clip(pelig_100_maldonado, cuenca_maldonado)
pelig_100_maldonado_clipped_3857 = pelig_100_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)

# Ordenar categorías
pelig_100_maldonado_clipped_3857["peli_ordered"] = pd.Categorical(
    pelig_100_maldonado_clipped_3857["peli"],
    categories=["Bajo", "Medio", "Alto"],
    ordered=True,
)

fig2, ax2 = create_consistent_map("R100 (Período de retorno 100 años)", boundary_gdf=cuenca_maldonado)
pelig_100_maldonado_clipped_3857.plot(
    ax=ax2,
    column="peli_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    zorder=5,
)
plt.tight_layout()
plt.show()

# === MAPA R25 ===
pelig_25_maldonado = gpd.read_file("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp")
pelig_25_maldonado = pelig_25_maldonado.to_crs(USE_CRS)

# Clipear a cuenca Maldonado
pelig_25_maldonado_clipped = gpd.clip(pelig_25_maldonado, cuenca_maldonado)
pelig_25_maldonado_clipped_3857 = pelig_25_maldonado_clipped.to_crs(WEB_MERCATOR_CRS)

# Ordenar categorías
pelig_25_maldonado_clipped_3857["peli_ordered"] = pd.Categorical(
    pelig_25_maldonado_clipped_3857["peli"],
    categories=["Bajo", "Medio", "Alto"],
    ordered=True,
)

fig3, ax3 = create_consistent_map("R25 (Período de retorno 25 años)", boundary_gdf=cuenca_maldonado)
pelig_25_maldonado_clipped_3857.plot(
    ax=ax3,
    column="peli_ordered",
    cmap="plasma",
    alpha=0.75,
    legend=True,
    zorder=5,
)
plt.tight_layout()
plt.show()
```

```{python}
# Comparación de escenarios de precipitación para Cuenca Maldonado
import matplotlib.pyplot as plt
import numpy as np

# Helper function para procesar datos de peligro
def process_hazard_data(file_path, buildings):
    pelig_data = gpd.read_file(file_path).to_crs(USE_CRS)
    pelig_filtered = pelig_data[pelig_data["peli"].isin(["Alto", "Medio"])].copy()
    pelig_simple = pelig_filtered.dissolve(by="peli").reset_index()
    
    buildings_with_peligro = gpd.sjoin(buildings, pelig_simple[["peli", "geometry"]], how="left", predicate="within")
    buildings_exposed = buildings_with_peligro.dropna(subset=["peli"]).copy()
    
    hazard_priority = {"Alto": 3, "Medio": 2}
    buildings_exposed.loc[:, "prioridad"] = buildings_exposed["peli"].map(hazard_priority)
    buildings_unique = buildings_exposed.sort_values("prioridad", ascending=False).drop_duplicates(subset=buildings_exposed.geometry.name, keep="first")
    
    exposicion = buildings_unique.groupby("peli").size().reset_index(name="edificios_expuestos")
    result = {}
    for _, row in exposicion.iterrows():
        peligro_name = "alta" if row['peli'] == "Alto" else "media"
        result[peligro_name] = row['edificios_expuestos']
    return result

buildings_maldonado = buildings_with_barrios.copy()

# === DATOS DE LOS TRES ESCENARIOS ===
# PMP
maldonado_pmp = resultado_exposicion_cuenca[resultado_exposicion_cuenca["Cuenca"] == "Cuenca A° Maldonado"].copy()
pmp_data = {row['peligrosidad']: int(row['edificios_expuestos']) for _, row in maldonado_pmp.iterrows()} if len(maldonado_pmp) > 0 else {}

# R25 y R100
r25_data = process_hazard_data("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp", buildings_maldonado)
r100_data = process_hazard_data("/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp", buildings_maldonado)

# === VISUALIZACIÓN COMPARATIVA ===
escenarios = ['PMP', 'R100', 'R25']
alta_values = [pmp_data.get('alta', 0), r100_data.get('alta', 0), r25_data.get('alta', 0)]
media_values = [pmp_data.get('media', 0), r100_data.get('media', 0), r25_data.get('media', 0)]

x = np.arange(len(escenarios))
width = 0.35

fig, ax = plt.subplots(figsize=(10, 6))
bars1 = ax.bar(x - width/2, alta_values, width, label='Peligro Alto', color=PELIGROSIDAD_COLORS["alta"], alpha=0.8)
bars2 = ax.bar(x + width/2, media_values, width, label='Peligro Medio', color=PELIGROSIDAD_COLORS["media"], alpha=0.8)

ax.set_xlabel('Escenario de Precipitación', fontsize=12)
ax.set_ylabel('Edificios Expuestos', fontsize=12)
ax.set_title('Exposición en Cuenca Maldonado por Escenario de Precipitación', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(escenarios)
ax.legend()

def add_value_labels(bars):
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax.text(bar.get_x() + bar.get_width()/2., height + 20, f'{int(height)}', ha='center', va='bottom', fontsize=10, fontweight='bold')

add_value_labels(bars1)
add_value_labels(bars2)

ax.grid(True, axis='y', alpha=0.3)
ax.set_axisbelow(True)
plt.tight_layout()
plt.show()
```

## Conclusiones

Los datos de huellas de edificios nos permiten realizar evaluaciones significativamente más precisas de la exposición poblacional en asentamientos informales en todo el partido. Este análisis identifica aproximadamente 23,000 edificaciones adicionales que creemos están presentes, equivalentes a potencialmente alrededor de 100,000 personas adicionales que no han sido mapeadas en los datos del RENABAP. Por tanto, representan un recurso realmente importante para la planificación de gestión de riesgo.

Encontramos que Villa Montoro contiene el mayor número de edificaciones y, por tanto, población expuesta a peligro alto con 555 edificaciones, seguido por La Palmeira con 341, La Esperanza con 324, La Isla con 304, y Toba con 299. La Cuenca Arroyo del Gato presenta el mayor número de población expuesta con 2,662 edificaciones, seguida por la Cuenca A° Maldonado con 1,000. Lo mismo es cierto para los ejes, donde el central tiene 2,662 y el sudoeste tiene 1,000, correspondiendo exactamente a estas cifras.