---
title: "RENABAP"
subtitle: "An치lisis de la exposici칩n poblacional a peligros de inundaci칩n en el Partido de La Plata"
authors: "Mgstr. Nissim Lebovits, Dr. Arq. Juan Carlos Etula칤n y Est. Celeste Duarte"
---

## Resumen ejecutivo

Este an치lisis utiliza el conjunto de datos global de huellas de edificios para mejorar las estimaciones de exposici칩n a peligros de inundaci칩n en asentamientos informales en La Plata.

丘멆잺 **Los datos del RENABAP subestiman dram치ticamente la poblaci칩n en asentamientos informales**, con aproximadamente **41,575 viviendas faltantes** no contabilizadas en las estad칤sticas oficiales. Esto representa entre 125,000 y 208,000 personas no contabilizadas, lo cual es fundamental para comprender la verdadera magnitud de la exposici칩n a inundaciones en La Plata.

游늵 Encontramos que **17,014 edificios est치n expuestas a peligros de inundaci칩n (23.9% del total) bajo el escenario de Precipitaci칩n M치xima Probable (PMP)**, con 6,112 en zonas de peligro alto y 10,902 en peligro medio. Villa Montoro presenta la mayor exposici칩n con 669 edificios en peligro alto (21.7% del barrio), seguido por La Esperanza con 440 edificios (16.3%), Las Palmeras con 417 (33.7%), Toba con 335 (67.7%), y La Isla con 320 edificios (96.4%). A nivel de cuencas, la Cuenca Arroyo del Gato concentra la mayor exposici칩n con 7,943 edificios expuestos.

游댃 El an치lisis de diferentes per칤odos de retorno para la Cuenca Maldonado revela que **la elecci칩n del per칤odo genera diferencias significativas en las estimaciones de exposici칩n**, siendo crucial para determinar qu칠 치reas priorizar para la reubicaci칩n de residentes en asentamientos informales.

- [游닌 Descargar los datos de exposici칩n de edificios a nivel de barrio](https://arg-fulbright-data.s3.us-east-2.amazonaws.com/renabap/exposicion-barrio-la-plata-03-09-2025.csv)
- [游닌 Descargar los datos de exposici칩n de edificios a nivel de cuenca y eje](https://arg-fulbright-data.s3.us-east-2.amazonaws.com/renabap/exposicion-cuenca-la-plata-03-09-2025.csv)

## Objetivos

Este proyecto tiene tres objetivos principales:

1. **Encontrar metodolog칤as m치s precisas para evaluar la poblaci칩n expuesta en barrios populares** - Desarrollar y aplicar t칠cnicas de an치lisis espacial que superen las limitaciones de la interpolaci칩n areal tradicional, utilizando datos de huellas de edificios para obtener estimaciones m치s precisas de la exposici칩n a peligros de inundaci칩n en asentamientos informales, y demostrar las limitaciones significativas de los datos oficiales del RENABAP que subestiman dram치ticamente el n칰mero de viviendas y poblaci칩n.

2. **Aportar y precisar el mapeo de riesgo h칤drico en el Partido de La Plata** - Mejorar la comprensi칩n de la distribuci칩n espacial del riesgo de inundaci칩n mediante el an치lisis de la exposici칩n de edificios individuales, proporcionando informaci칩n detallada para la toma de decisiones a nivel municipal y la planificaci칩n de pol칤ticas de reducci칩n de riesgo.

3. **Poner en cuesti칩n las recurrencias utilizadas en el c치lculo de riesgo seg칰n la pol칤tica considerada y evidenciar errores u omisiones en datos oficiales** - Evaluar cr칤ticamente los per칤odos de retorno utilizados en los modelos de peligrosidad y examinar la importancia de la precisi칩n de los datos considerados, tanto en t칠rminos de la exactitud de los datos del RENABAP como de los datos de peligros de inundaci칩n, para una evaluaci칩n adecuada del riesgo.

```{python}


import matplotlib.pyplot as plt

from io import StringIO
from shapely.geometry import box
import geopandas as gpd
import requests
import os

import itables
from itables import show
from IPython.display import HTML, display

from matplotlib_map_utils import north_arrow, scale_bar, ScaleBar

from matplotlib.patches import Patch


from shapely.ops import unary_union
import contextily as cx

# Global settings for international number formatting
import locale
import pandas as pd
import numpy as np

# Set locale for international number formatting (period for thousands, comma for decimal)
try:
    locale.setlocale(locale.LC_ALL, 'es_AR.UTF-8')
except locale.Error:
    try:
        locale.setlocale(locale.LC_ALL, 'es_ES.UTF-8')
    except locale.Error:
        locale.setlocale(locale.LC_ALL, '')

# Set pandas options for international formatting
pd.set_option('display.float_format', lambda x: f'{x:,.1f}'.replace(',', '.').replace('.', ',', 1))

# Helper function to format numbers with international formatting (periods for thousands, periods for decimals)
def format_number(num, decimals=None):
    if decimals is None:
        # Integer formatting - just thousands separators
        return f"{num:,}".replace(",", ".")
    else:
        # Decimal formatting - thousands separators and decimal period
        return f"{num:,.{decimals}f}".replace(",", ".")

from utils.utils import (
    add_scale_bar_and_north_arrow,
    add_basemap,
    add_boundary_outline,
    create_consistent_map,
    wfs_to_gdf,
    fetch_buildings,
)

ScaleBar.set_size(size="md")

# Configure Argentine Spanish for itables
try:
    spanish_url = "https://cdn.datatables.net/plug-ins/2.3.3/i18n/es-AR.json"
    response = requests.get(spanish_url)
    response.raise_for_status()
    spanish_config = response.json()
    itables.options.language = spanish_config
except Exception:
    pass

# Configure smaller font size for all itables
css = """
.dt-container {
  font-size: small;
}
"""
display(HTML(f"<style>{css}</style>"))


# Helper function to round numeric columns for display
def round_numeric_columns(df, decimals=0):
    """Round all numeric columns in a DataFrame to specified decimal places."""
    df_display = df.copy()
    numeric_columns = df_display.select_dtypes(include=[np.number]).columns
    df_display[numeric_columns] = df_display[numeric_columns].round(decimals)
    return df_display

def add_scale_bar_and_north_arrow(
    ax, location="upper right", scale_color="black", arrow_color="black", length=None
):
    """Add a scale bar and north arrow to the map using matplotlib_map_utils."""
    # Add scale bar using matplotlib_map_utils ScaleBar class with ticks style
    scale_bar(
        ax=ax,
        location="upper left",
        style="ticks",
        bar={
            "projection": "EPSG:3857",
            "tickcolors": scale_color,
            "basecolors": scale_color,
            "minor_type": "none",
            "length": length,
        },
        labels={"style": "first_last"},
    )

    # Add north arrow using matplotlib_map_utils
    north_arrow(
        ax,
        location=location,
        scale=0.3,  # Small size
        rotation={"degrees": 0},
        base={"facecolor": "none", "edgecolor": arrow_color, "linewidth": 1},
        fancy=True,
        shadow=True,
        label=False,  # Hide the "N" text
    )

def setup_base_map(
    use_crs, figsize=None, bounds=None, boundary_gdf=None, padding_x=None, padding_y=None
):
    """Create figure and set up basic map boundaries with padding."""
    if figsize is None:
        figsize = DEFAULT_FIGSIZE
    if padding_x is None:
        padding_x = MAP_PADDING
    if padding_y is None:
        padding_y = MAP_PADDING

    if bounds is None and boundary_gdf is not None:
        bounds = boundary_gdf.total_bounds

    # Convert bounds to Web Mercator for basemap compatibility
    if bounds is not None:
        # Create a temporary GeoDataFrame with the bounds to reproject
        temp_bounds = gpd.GeoDataFrame(
            geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])], crs=use_crs
        )
        bounds_3857 = temp_bounds.to_crs(WEB_MERCATOR_CRS).total_bounds
    else:
        bounds_3857 = bounds

    fig, ax = plt.subplots(figsize=figsize)
    ax.set_xlim(bounds_3857[0] - padding_x, bounds_3857[2] + padding_x)
    ax.set_ylim(bounds_3857[1] - padding_y, bounds_3857[3] + padding_y)
    return fig, ax

def create_consistent_map(title, crs, boundary_gdf=None, bounds=None, attribution=None, scalebar_length=None):
    """Create a map with consistent styling and basemap."""
    fig, ax = setup_base_map(crs, bounds=bounds, boundary_gdf=boundary_gdf)

    add_basemap(ax, attribution=attribution)

    add_scale_bar_and_north_arrow(ax, length=scalebar_length)

    add_boundary_outline(ax, boundary_gdf)

    ax.set_title(title, fontsize=16, fontweight="bold", pad=20)

    ax.set_axis_off()

    return fig, ax



# =============================================================================
# CONSTANTES Y CONFIGURACI칍N
# =============================================================================

USE_CRS = "EPSG:5349"  # POSGAR 2007 / Argentina 4
WEB_MERCATOR_CRS = "EPSG:3857"  # visualization
WGS84_CRS = "EPSG:4326"  # for API calls

BASE_PATH = "/home/nissim/Documents/dev/fulbright/ciut-riesgo"
DATA_PATH = f"{BASE_PATH}/notebooks/data"
PELIGRO_PATH = f"{DATA_PATH}/la_plata_pelig_2023_datos_originales.geojson"
PARTIDOS_PATH = f"{DATA_PATH}/pba_partidos.geojson"
CUENCAS_PATH = f"{BASE_PATH}/notebooks/cuencas_buenos_aires.geojson"
BUILDINGS_PATH = f"{BASE_PATH}/notebooks/buildings_filtered.parquet"

RENABAP_URL = (
    "https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson"
)
PARTIDOS_WFS_URL = "https://geo.arba.gov.ar/geoserver/idera/wfs"
CUENCAS_API_URL = "https://services1.arcgis.com/atxllciEI8CHWvwW/ArcGIS/rest/services/Cuencas_BuenosAires_2023/FeatureServer/0/query"


# Basic visualization settings (only for repeated values)
DEFAULT_FIGSIZE = (12, 10)
MAP_PADDING = 500
PLASMA_CMAP = plt.cm.plasma

# Color schemes for visualization
PELIGROSIDAD_COLORS = {
    "alta": PLASMA_CMAP(0.5),
    "media": PLASMA_CMAP(0.8),
}


PELIGROSIDAD_LEGEND = [
    Patch(facecolor=color, label=label) for label, color in PELIGROSIDAD_COLORS.items()
]


# Eje mapping for watershed analysis
EJE_MAPPING = {
    "noreste": ["Area de Ba침ados", "Cuenca Arroyo Rodriguez-Don Carlos"],
    "noroeste": ["Cuenca Arroyo Mart칤n-Carnaval", "Cuenca Arroyo Pereyra"],
    "central": ["Cuenca Arroyo del Gato"],
    "sudoeste": ["Cuenca A춿 Maldonado", "Cuenca R칤o Samboromb칩n"],
    "sudeste": ["Cuenca Arroyo El Pescado"],
}





# =============================================================================
# DATA LOADING AND PREPROCESSING
# =============================================================================

response = requests.get(RENABAP_URL)
renabap = gpd.read_file(StringIO(response.text))
renabap_pba = renabap[renabap["provincia"] == "Buenos Aires"]
renabap_pba = renabap_pba.to_crs(USE_CRS)


if os.path.exists(PARTIDOS_PATH):
    partidos = gpd.read_file(PARTIDOS_PATH)
else:
    partidos = wfs_to_gdf(
        wfs_url=PARTIDOS_WFS_URL,
        layer_name="idera:Departamento",
        srs="EPSG:5347",
    )

    partidos.to_file(PARTIDOS_PATH, driver="GeoJSON")

partidos = partidos.to_crs(USE_CRS)
la_plata = partidos[partidos["fna"] == "Partido de La Plata"]

# Obtener la geometr칤a principal
main_geom = la_plata.geometry.iloc[0]

# Si es un MultiPolygon, mantener solo el pol칤gono m치s grande (el partido principal)
# Esto elimina la peque침a isla que aparece en los datos
if main_geom.geom_type == "MultiPolygon":
    # Obtener todos los pol칤gonos y mantener el que tenga mayor 치rea
    largest_polygon = max(main_geom.geoms, key=lambda p: p.area)
    la_plata = la_plata.copy()  # Create a copy to avoid SettingWithCopyWarning
    la_plata.loc[la_plata.index[0], "geometry"] = largest_polygon

la_plata_bbox = la_plata.geometry.iloc[0]


peligro = gpd.read_file(PELIGRO_PATH)
peligro = peligro.to_crs(USE_CRS)
peligro = peligro[peligro["PELIGROSID"] != "baja"]

peligro_bounds = peligro.total_bounds
peligro_bbox = box(*peligro_bounds)

peligro_la_plata = peligro.clip(la_plata)
peligro_clipped_3857 = peligro_la_plata.to_crs(WEB_MERCATOR_CRS)


renabap_pba_intersect = renabap_pba[
    renabap_pba.geometry.intersects(la_plata_bbox)
].copy()


if os.path.exists(CUENCAS_PATH):
    cuencas = gpd.read_file(CUENCAS_PATH)
else:
    params = {"where": "1=1", "outFields": "*", "f": "geojson"}

    cuencas_response = requests.get(CUENCAS_API_URL, params=params)
    with open(CUENCAS_PATH, "w", encoding="utf-8") as f:
        f.write(cuencas_response.text)

    cuencas = gpd.read_file(StringIO(cuencas_response.text))

cuencas = cuencas.to_crs(USE_CRS)
cuencas = cuencas.clip(la_plata)

# Map watershed names to axes based on the EJE_MAPPING
cuencas["eje"] = (
    cuencas["Cuenca"]
    .map(
        {
            cuenca: eje
            for eje, cuencas_list in EJE_MAPPING.items()
            for cuenca in cuencas_list
        }
    )
    .fillna("otro")
)

# Calculate total area of RENABAP settlements in hectares (POSGAR projection is in meters)
renabap_total_area_ha = (
    renabap_pba_intersect.geometry.area.sum() / 10000
)  # Convert m to hectares
la_plata_area_ha = la_plata.geometry.iloc[0].area / 10000
percentage_coverage = (renabap_total_area_ha / la_plata_area_ha) * 100

# Get common bounds for all maps
common_bounds = la_plata.total_bounds

# Intersect settlements with hazard zones
settlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how="intersection")

settle_hazard_cuencas = gpd.overlay(
    settlement_hazard, cuencas, how="intersection", keep_geom_type=True
)

if os.path.exists(BUILDINGS_PATH):
    buildings = gpd.read_parquet(BUILDINGS_PATH)
else:
    buildings = fetch_buildings(la_plata.buffer(500))


la_plata_buffered = la_plata_bbox.buffer(500)
buildings_proj = buildings.to_crs(USE_CRS)
buildings_proj = buildings_proj[buildings_proj.geometry.intersects(la_plata_buffered)]
```

## Fuentes de datos

### RENABAP

El Registro Nacional de Barrios Populares (RENABAP) es coordinado por la Subsecretar칤a de Integraci칩n Socio Urbana y sistematiza la informaci칩n sobre villas y asentamientos informales en Argentina. El registro incluye estimaciones de poblaci칩n, delimitaciones geogr치ficas y datos sociodemogr치ficos obtenidos a trav칠s de relevamientos territoriales realizados desde 2016 por equipos conformados por organizaciones sociales y vecinos de los barrios.

Este relevamiento de Viviendas Familiares se realiza mediante encuestas domiciliarias en los barrios populares registrados. La metodolog칤a combina trabajo territorial con herramientas digitales como aplicaciones m칩viles de geolocalizaci칩n, escaneo de DNI, grabaci칩n de encuestas y cartograf칤a editable. Cada pol칤gono barrial se subdivide en manzanas, lotes y edificios, y se releva una ficha por cada vivienda habitada. Los datos son validados con organismos oficiales (RENAPER, ANSES) y sometidos a control de calidad para garantizar su precisi칩n.
Por otro lado, las estimaciones poblacionales para la versi칩n 2023 fueron calculadas multiplicando la cantidad de viviendas registradas en el RENABAP por el promedio de personas por vivienda y el promedio de hogares por vivienda, seg칰n los datos del Censo Nacional de Hogares Poblaci칩n y Vivienda INDEC 2010 correspondiente a cada barrio. Esto limita significativamente la precisi칩n de los datos demogr치ficos en el contexto de procesos de transformaci칩n urbana, ya que los asentamientos informales han experimentado cambios sustanciales desde 2010. Las limitaciones cr칤ticas de estos datos se analizan en detalle en la secci칩n correspondiente de este estudio.

M치s informaci칩n sobre el RENABAP est치 disponible en el [Observatorio de Barrios Populares](https://www.argentina.gob.ar/obras-publicas/sisu/renabap/observatorio-de-barrios-populares). Los datos fueron obtenidos a trav칠s del [Mapa de Barrios Populares](https://www.argentina.gob.ar/obras-publicas/sisu/renabap/mapa) y est치n disponibles para [descarga como GeoJSON](https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson).

### Peligro de inundaci칩n

Los datos de peligro de inundaci칩n utilizados en este an치lisis fueron desarrollados por la Facultad de Ingenier칤a de la Universidad Nacional de La Plata como parte del Plan de Reducci칩n del Riesgo por Inundaciones en la Regi칩n de La Plata [@romanazzi2019, @romanazzi2023]. El modelo digital de elevaci칩n fue actualizado en 2023 para capturar mejor los patrones de drenaje y la topograf칤a urbana de la ciudad [@etulain2025]. La informaci칩n fue generada mediante la aplicaci칩n del modelo hidrol칩gico-hidr치ulico bidimensional FLO-2D, que permiti칩 simular la din치mica de inundaci칩n de todas las cuencas del partido de La Plata para distintos escenarios de eventos pluviom칠tricos extremos. Este an치lisis se basa espec칤ficamente en los datos de peligrosidad generados para el escenario de Precipitaci칩n M치xima Probable (PMP), en contraste con otros per칤odos de retorno como 25 a침os, 100 a침os o 500 a침os. El modelo calcula las principales variables hidr치ulicas (altura del agua, velocidad y caudal) a lo largo del tiempo, y a partir de estos resultados se generaron los mapas de peligrosidad que combinan el efecto de la profundidad con la velocidad de la corriente, ofreciendo un indicador m치s completo que los mapas tradicionales de m치ximas profundidades.

### Google-Microsoft-OSM Open Buildings

Los datos de [Google-Microsoft-OSM Open Buildings](https://source.coop/repositories/vida/google-microsoft-osm-open-buildings/access) [@google_microsoft_osm_buildings] representan una forma m치s precisa de evaluar d칩nde se ubican los asentamientos humanos. Este conjunto de datos combina Google V3 Open Buildings, Microsoft GlobalMLFootprints, y OpenStreetMap building footprints, conteniendo m치s de 2.7 mil millones de huellas de edificios. Estos datos han sido aplicados a evaluaciones de riesgo de inundaci칩n por [empresas globales de riesgo financiero como ICE](https://www.ice.com/insights/sustainable-finance/ice-climates-exposure-datasets-understanding-how-climate-risks-impact-infrastructure-and-communities), demostrando su utilidad para mapear la exposici칩n clim치tica a nivel de huella de edificio individual. Sin embargo, en ausencia de informaci칩n sobre si los edificios son residenciales o tienen otros usos, y sin datos sobre el n칰mero total de unidades en el edificio y habitantes por edificio, solo podemos obtener estimaciones proporcionales aproximadas de d칩nde se ubican las personas, sin tener una comprensi칩n precisa de qui칠n vive realmente all칤 y cu치ntas personas.

### L칤mites municipales

Los l칤mites municipales del Partido de La Plata fueron obtenidos del Instituto Geogr치fico Nacional (IGN) a trav칠s de su servidor WFS [@ign_municipios_2025]. Los datos representan la divisi칩n pol칤tico-administrativa de tercer orden que incluye comunas, juntas vecinales y dem치s formas de gobiernos.

### Cuencas hidrogr치ficas

Los datos de cuencas hidrogr치ficas fueron obtenidos de la Divisi칩n Provincial de Hidr치ulica de la Provincia de Buenos Aires a trav칠s de su servidor WFS [@dipsoh_cuencas_2025].



## Contexto

```{python}
# Calcular variables para el contexto
total_barrios = int(len(renabap_pba_intersect))
total_familias = int(renabap_pba_intersect["familias_aproximadas"].sum())
area_barrios_ha = int(renabap_total_area_ha)
porcentaje_cobertura = float(round(percentage_coverage, 1))

# Calcular barrios que intersectan con zonas de peligro
barrios_with_peligro = gpd.sjoin(
    renabap_pba_intersect, peligro_la_plata, how="inner", predicate="intersects"
)

# Contar barrios por nivel de peligro
barrios_peligro_alta = int(
    len(
        barrios_with_peligro[barrios_with_peligro["PELIGROSID"] == "alta"][
            "id_renabap"
        ].unique()
    )
)
barrios_peligro_media = int(
    len(
        barrios_with_peligro[barrios_with_peligro["PELIGROSID"] == "media"][
            "id_renabap"
        ].unique()
    )
)

# Contar barrios por tipo de peligro (sin duplicados)
barrios_peligro_summary = (
    barrios_with_peligro.groupby("id_renabap")["PELIGROSID"]
    .agg(["nunique", "unique"])
    .reset_index()
)
barrios_peligro_summary["tiene_alta"] = barrios_peligro_summary["unique"].apply(
    lambda x: "alta" in x
)
barrios_peligro_summary["tiene_media"] = barrios_peligro_summary["unique"].apply(
    lambda x: "media" in x
)

# Contar barrios por categor칤a
barrios_solo_alta = int(
    (
        barrios_peligro_summary["tiene_alta"] & ~barrios_peligro_summary["tiene_media"]
    ).sum()
)
barrios_solo_media = int(
    (
        barrios_peligro_summary["tiene_media"] & ~barrios_peligro_summary["tiene_alta"]
    ).sum()
)
barrios_ambos_peligros = int(
    (
        barrios_peligro_summary["tiene_alta"] & barrios_peligro_summary["tiene_media"]
    ).sum()
)

# Total de barrios que intersectan con cualquier nivel de peligro (sin duplicados)
barrios_total_peligro = int(len(barrios_with_peligro["id_renabap"].unique()))

# Obtener total de edificios en La Plata
total_buildings_la_plata = len(buildings_proj)

# Obtener todas las edificios que intersectan con los barrios (corregir warning de deprecaci칩n)
buildings_in_barrios = buildings_proj[
    buildings_proj.geometry.intersects(renabap_pba_intersect.union_all())
]
total_buildings_in_barrios = len(buildings_in_barrios)

viviendas_faltantes = (
    total_buildings_in_barrios - 30753
)  # 30753 es el n칰mero oficial de RENABAP

# Calcular porcentaje de edificios en barrios
buildings_percentage = float(
    round((total_buildings_in_barrios / total_buildings_la_plata) * 100, 1)
)

# Calcular 치rea total de barrios populares en hect치reas
barrios_total_area_ha = float(round(renabap_pba_intersect.geometry.area.sum() / 10000, 1))

# Calcular el 치rea real de superposici칩n entre barrios populares y zonas de peligro
# Primero, crear uniones de las zonas de peligro por tipo
peligro_alta_union = peligro_la_plata[peligro_la_plata["PELIGROSID"] == "alta"].union_all()
peligro_media_union = peligro_la_plata[peligro_la_plata["PELIGROSID"] == "media"].union_all()

# Calcular el 치rea de superposici칩n real entre barrios y zonas de peligro alto
barrios_intersect_alta = renabap_pba_intersect.copy()
barrios_intersect_alta["geometry"] = renabap_pba_intersect.geometry.intersection(peligro_alta_union)
barrios_intersect_alta = barrios_intersect_alta[~barrios_intersect_alta.geometry.is_empty]
barrios_area_peligro_alta_ha = float(round(barrios_intersect_alta.geometry.area.sum() / 10000, 1))
barrios_pct_peligro_alta = float(round((barrios_area_peligro_alta_ha / barrios_total_area_ha) * 100, 1))

# Calcular el 치rea de superposici칩n real entre barrios y zonas de peligro medio
barrios_intersect_media = renabap_pba_intersect.copy()
barrios_intersect_media["geometry"] = renabap_pba_intersect.geometry.intersection(peligro_media_union)
barrios_intersect_media = barrios_intersect_media[~barrios_intersect_media.geometry.is_empty]
barrios_area_peligro_media_ha = float(round(barrios_intersect_media.geometry.area.sum() / 10000, 1))
barrios_pct_peligro_media = float(round((barrios_area_peligro_media_ha / barrios_total_area_ha) * 100, 1))

# Calcular el 치rea total de barrios populares como porcentaje del partido
barrios_pct_del_partido = float(round((barrios_total_area_ha / la_plata_area_ha) * 100, 1))




# Calcular 치rea para cada tipo de peligro en hect치reas
peligro_areas = (
    peligro_la_plata.groupby("PELIGROSID")["geometry"]
    .apply(
        lambda x: x.area.sum() / 10000  # Convertir m a hect치reas
    )
    .reset_index()
)
peligro_areas.columns = ["tipo_peligro", "area_ha"]

# Calcular porcentajes
peligro_areas["porcentaje"] = (peligro_areas["area_ha"] / la_plata_area_ha) * 100

# Variables para cada nivel de peligro (convertir a float Python nativo)
peligro_alta_ha = float(
    round(peligro_areas[peligro_areas["tipo_peligro"] == "alta"]["area_ha"].iloc[0], 1)
)
peligro_alta_pct = float(
    round(
        peligro_areas[peligro_areas["tipo_peligro"] == "alta"]["porcentaje"].iloc[0], 1
    )
)
peligro_media_ha = float(
    round(peligro_areas[peligro_areas["tipo_peligro"] == "media"]["area_ha"].iloc[0], 1)
)
peligro_media_pct = float(
    round(
        peligro_areas[peligro_areas["tipo_peligro"] == "media"]["porcentaje"].iloc[0], 1
    )
)

# 츼rea total cubierta por zonas de peligro (convertir a float Python nativo)
area_total_peligro_ha = float(round(peligro_areas["area_ha"].sum(), 1))
porcentaje_total_peligro = float(round(peligro_areas["porcentaje"].sum(), 1))
```

Seg칰n los datos oficiales de RENABAP, hay un total de `{python} format_number(total_familias)` familias y `{python} format_number(30753)` edificios en `{python} format_number(total_barrios)` [barrios populares en el Partido de La Plata](https://lookerstudio.google.com/u/0/reporting/0a127285-4dd0-43b2-b7b2-98390bfd567f/page/klATC). Sin embargo, estos datos fueron creados bas치ndose en proyecciones del Censo Argentino de 2010 hacia 2023. Nuestro an치lisis de datos de huellas de edificios encuentra un total de `{python} format_number(total_buildings_in_barrios)` edificios en barrios populares en La Plata, representando aproximadamente `{python} format_number(viviendas_faltantes)` edificios adicionales que no est치n contabilizados en los datos oficiales.

El Partido de La Plata tiene un 치rea total de `{python} format_number(la_plata_area_ha, 1)` hect치reas, de las cuales `{python} format_number(peligro_alta_ha, 1)` hect치reas (`{python} format_number(peligro_alta_pct, 1)`%) corresponden a zonas de peligro alto y `{python} format_number(peligro_media_ha, 1)` hect치reas (`{python} format_number(peligro_media_pct, 1)`%) a zonas de peligro medio bajo el escenario de Precipitaci칩n M치xima Probable (PMP). En el Partido existen un total de `{python} format_number(total_barrios)` barrios populares que ocupan `{python} format_number(barrios_total_area_ha, 1)` hect치reas (`{python} format_number(barrios_pct_del_partido, 1)`% del territorio total), y de estos, `{python} format_number(barrios_area_peligro_alta_ha, 1)` hect치reas (`{python} format_number(barrios_pct_peligro_alta, 1)`% del 치rea total de barrios populares) se superponen con zonas de peligro alto, mientras que `{python} format_number(barrios_area_peligro_media_ha, 1)` hect치reas (`{python} format_number(barrios_pct_peligro_media, 1)`% del 치rea total de barrios populares) se superponen con zonas de peligro medio. En total, `{python} int(barrios_total_peligro)` barrios (`{python} format_number((barrios_total_peligro / total_barrios) * 100, 1)`% del total) intersectan con zonas de peligro, siendo `{python} barrios_solo_alta` barrio que intersecta 칰nicamente con zonas de peligro alto, `{python} barrios_solo_media` barrios que intersectan 칰nicamente con zonas de peligro medio, y `{python} barrios_ambos_peligros` barrios que presentan tanto peligro alto como medio dentro de sus l칤mites.

```{python}
# | layout-ncol: 3
# | label: fig-fuentes-datos
# | fig-cap: "Fuentes de datos para an치lisis de exposici칩n"
# | fig-subcap:
# |   - "Asentamientos RENABAP en La Plata"
# |   - "Zonas de Peligro en La Plata"
# |   - "Huellas de edificios"
# | lightbox:
# |   group: fuentes-datos


fig1, ax1 = create_consistent_map(
    "Asentamientos RENABAP en La Plata", crs=USE_CRS, boundary_gdf=la_plata, bounds=common_bounds, attribution="Datos: RENABAP (2023), IGN (2025) | Mapa base: Carto (2025)", scalebar_length=0.20
)

renabap_pba_intersect_3857 = renabap_pba_intersect.to_crs(WEB_MERCATOR_CRS)

renabap_pba_intersect_3857.plot(
    ax=ax1, facecolor="none", edgecolor="black", linewidth=0.5, legend=False, zorder=10
)

plt.tight_layout()
plt.show()



# Reorder the categories so they map correctly to plasma colormap
peligro_clipped_3857["PELIGROSID_ordered"] = pd.Categorical(
    peligro_clipped_3857["PELIGROSID"],
    categories=["media", "alta"],
    ordered=True,
)


fig2, ax2 = create_consistent_map(
    "Zonas de Peligro en La Plata", crs=USE_CRS, boundary_gdf=la_plata, bounds=common_bounds, attribution="Datos: Romanazzi et al. (2019), IGN (2025) | Mapa base: Carto (2025)", scalebar_length=0.20
)


color_map = peligro_clipped_3857["PELIGROSID"].map(PELIGROSIDAD_COLORS)

peligro_clipped_3857.plot(
    ax=ax2,
    color=color_map,
    alpha=0.75,
    zorder=5,
)

ax2.legend(handles=PELIGROSIDAD_LEGEND, loc="lower right")

plt.tight_layout()
plt.show()


fig3, ax3 = create_consistent_map(
    "Huellas de edificios", crs=USE_CRS, boundary_gdf=la_plata, bounds=common_bounds, attribution="Datos: VIDA (2023), IGN (2025) | Mapa base: Carto (2025)", scalebar_length=0.20
)

buildings_3857 = buildings_proj.to_crs(WEB_MERCATOR_CRS)

buildings_3857.plot(ax=ax3, facecolor="grey", edgecolor="none", alpha=0.7)

plt.tight_layout()
plt.show()

```

## Metodolog칤a

En versiones anteriores de este an치lisis, el trabajo se realiz칩 mediante una interpolaci칩n areal simple del porcentaje de superposici칩n de cada 치rea de peligro de inundaci칩n con los asentamientos informales. Este enfoque presenta dos problemas fundamentales que este estudio busca abordar.

El primer problema es que la interpolaci칩n areal es inherentemente imprecisa, ya que asume lo que se conoce como el [problema de la unidad areal modificable](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/modifiable-areal-unit-problem) y presupone que la poblaci칩n se distribuye uniformemente en el espacio. Estudios confirman que cuando se asume distribuci칩n uniforme de poblaci칩n en 치reas extensas (como datos de censo a nivel de secci칩n), las estimaciones de exposici칩n a inundaciones son inexactas, requiriendo datos de mayor resoluci칩n que no asuman distribuci칩n uniforme [@smith2019]. La poblaci칩n, de hecho, no se distribuye uniformemente en el espacio; frecuentemente los edificios se agrupan ya sea alej치ndose de las zonas de peligro de inundaci칩n o concentr치ndose en zonas de alto peligro de inundaci칩n. Por tanto, es fundamental comprender con estimaciones m치s precisas d칩nde vive realmente la gente.

El segundo problema radica en que los propios datos del RENABAP, seg칰n nuestro an치lisis aqu칤 presentado, parecen contar dram치ticamente de forma incorrecta, frecuentemente por un factor de dos o m치s, el n칰mero de familias que aparentemente viven en un asentamiento informal bas치ndose en el n칰mero de edificios. Esto probablemente se debe a errores de proyecci칩n acumulados a lo largo del tiempo y a la dificultad de mantener actualizados los datos de asentamientos informales.

Esta es una de las grandes ventajas de las huellas de edificios globales derivadas de sat칠lite que han surgido en los 칰ltimos a침os de Google-Microsoft-OSM, entre otros. Uno de los objetivos principales de este an치lisis es demostrar que estos datos de huellas de edificios pueden utilizarse para estimar la exposici칩n de manera m치s precisa, tanto en t칠rminos de precisi칩n metodol칩gica como en t칠rminos de mejora sobre conjuntos de datos nacionales existentes como el RENABAP.

Por tanto, en este estudio utilizamos el n칰mero de edificios que intersectan con las diferentes zonas de peligro de inundaci칩n como medida de exposici칩n, utilizando espec칤ficamente los datos de peligrosidad generados para el escenario de Precipitaci칩n M치xima Probable (PMP). Aunque los datos del RENABAP estiman aproximadamente 1,1 familias por edificio, medimos la exposici칩n en t칠rminos del n칰mero comparativo de edificios, lo cual es suficiente para demostrar las limitaciones del RENABAP y proporcionar estimaciones razonablemente buenas de exposici칩n.

Bas치ndonos en conversaciones con planificadores acad칠micos y municipales, asumimos que la mayor칤a de edificios en asentamientos informales son residenciales de uno a dos pisos, creando una correspondencia estrecha entre n칰mero de edificios y familias. Esta suposici칩n es v치lida para este contexto espec칤fico, aunque no aplicar칤a a asentamientos formales densos.

```{python}

# Definir orden de prioridad de peligro y simplificar
hazard_priority = {"alta": 2, "media": 1}
peligro_simple = peligro_la_plata.dissolve(by="PELIGROSID").reset_index()

# Construir 칤ndices espaciales para operaciones m치s r치pidas
buildings_proj.sindex
renabap_pba_intersect.sindex
peligro_simple.sindex

# Filtrar edificios a solo aquellos que podr칤an intersectar con barrios
# usando intersecci칩n de cajas delimitadoras primero (mucho m치s r치pido que intersecci칩n geom칠trica)
# Crear una uni칩n de todas las cajas delimitadoras individuales de barrios


# Obtener cajas delimitadoras individuales para cada barrio
barrio_boxes = []
for _, barrio in renabap_pba_intersect.iterrows():
    bounds = barrio.geometry.bounds
    barrio_boxes.append(box(bounds[0], bounds[1], bounds[2], bounds[3]))

# Crear una uni칩n de todas las cajas delimitadoras de barrios


barrios_union = unary_union(barrio_boxes)

# Filtrar edificios a solo aquellos que intersectan con cualquier caja delimitadora de barrio
buildings_candidates = buildings_proj[buildings_proj.geometry.intersects(barrios_union)]

# Ahora hacer el join espacial en el dataset filtrado mucho m치s peque침o
buildings_with_barrios = gpd.sjoin(
    buildings_candidates,
    renabap_pba_intersect[
        ["id_renabap", "nombre_barrio", "familias_aproximadas", "geometry"]
    ],
    how="inner",
    predicate="within",
)

buildings_with_barrios = buildings_with_barrios.drop(columns=["index_right"]).copy()

# Etapa 1: Obtener edificios que est치n claramente dentro de zonas de peligro (r치pido)
buildings_within_hazards = gpd.sjoin(
    buildings_with_barrios,
    peligro_simple[["PELIGROSID", "geometry"]],
    how="inner",
    predicate="within",
)

# Etapa 2: Encontrar edificios que est치n cerca de los l칤mites de peligro pero no dentro
# Usar un peque침o buffer alrededor de las zonas de peligro para encontrar casos l칤mite potenciales
hazard_buffered = peligro_simple.copy()
hazard_buffered["geometry"] = peligro_simple.geometry.buffer(5)  # buffer de 5 metros

buildings_near_hazards = gpd.sjoin(
    buildings_with_barrios,
    hazard_buffered[["PELIGROSID", "geometry"]],
    how="inner",
    predicate="within",
)

# Encontrar casos l칤mite (cerca de peligros pero no dentro de los peligros originales)
within_ids = set(buildings_within_hazards.index)
near_ids = set(buildings_near_hazards.index)
edge_case_ids = near_ids - within_ids

buildings_edge_cases = buildings_with_barrios.loc[list(edge_case_ids)]

# Etapa 3: Usar intersects solo en los casos l칤mite
buildings_edge_cases_with_hazard = gpd.sjoin(
    buildings_edge_cases,
    peligro_simple[["PELIGROSID", "geometry"]],
    how="left",
    predicate="intersects",
)

# Combinar resultados
buildings_with_peligro_barrio = pd.concat(
    [buildings_within_hazards, buildings_edge_cases_with_hazard], ignore_index=True
)


# Resolver duplicados y contar
buildings_barrio_final = buildings_with_peligro_barrio.dropna(
    subset=["PELIGROSID"]
).copy()
buildings_barrio_final.loc[:, "prioridad"] = buildings_barrio_final["PELIGROSID"].map(
    hazard_priority
)
buildings_barrio_unique = buildings_barrio_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_barrio_final.geometry.name, keep="first")

# Calcular exposici칩n por barrio
edificios_por_barrio_peligro = (
    buildings_barrio_unique.groupby(["id_renabap", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_barrio = (
    buildings_with_barrios.groupby("id_renabap")
    .size()
    .reset_index(name="total_edificios")
)

exposure_barrio = edificios_por_barrio_peligro.merge(
    total_edificios_barrio, on="id_renabap"
)
exposure_barrio["proporcion"] = (
    exposure_barrio["edificios_expuestos"] / exposure_barrio["total_edificios"]
)

familias_barrio = renabap_pba_intersect[
    ["id_renabap", "nombre_barrio", "familias_aproximadas"]
].drop_duplicates()
final_exposure_barrio = exposure_barrio.merge(familias_barrio, on="id_renabap")
final_exposure_barrio["fam_expuestas"] = (
    final_exposure_barrio["proporcion"] * final_exposure_barrio["familias_aproximadas"]
)

resultado_exposicion_barrio = final_exposure_barrio[
    [
        "id_renabap",
        "nombre_barrio",
        "PELIGROSID",
        "edificios_expuestos",
    ]
].rename(columns={"PELIGROSID": "peligrosidad"})

# === AN츼LISIS POR CUENCA ===
# Usar edificios ya en barrios para an치lisis de cuenca
buildings_in_settlements = buildings_with_barrios.copy()

# Spatial joins para cuenca
buildings_with_cuenca = gpd.sjoin(
    buildings_in_settlements,
    cuencas[["Cuenca", "eje", "geometry"]],
    how="left",
    predicate="within",
)
buildings_with_cuenca = buildings_with_cuenca.drop(columns=["index_right"]).copy()

buildings_with_peligro_cuenca = gpd.sjoin(
    buildings_in_settlements,
    peligro_simple[["PELIGROSID", "geometry"]],
    how="left",
    predicate="within",
)

# Combinar y filtrar
buildings_cuenca_final = buildings_in_settlements.copy()
buildings_cuenca_final.loc[:, "Cuenca"] = buildings_with_cuenca["Cuenca"]
buildings_cuenca_final.loc[:, "eje"] = buildings_with_cuenca["eje"]
buildings_cuenca_final.loc[:, "PELIGROSID"] = buildings_with_peligro_cuenca[
    "PELIGROSID"
]
buildings_cuenca_final = buildings_cuenca_final.dropna(
    subset=["Cuenca", "PELIGROSID"]
).copy()

# Resolver duplicados y calcular exposici칩n por cuenca
buildings_cuenca_final.loc[:, "prioridad"] = buildings_cuenca_final["PELIGROSID"].map(
    hazard_priority
)
buildings_cuenca_unique = buildings_cuenca_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_cuenca_final.geometry.name, keep="first")

edificios_por_cuenca_peligro = (
    buildings_cuenca_unique.groupby(["Cuenca", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_cuenca = (
    buildings_with_cuenca.dropna(subset=["Cuenca"])
    .groupby("Cuenca")
    .size()
    .reset_index(name="total_edificios")
)

exposure_cuenca = edificios_por_cuenca_peligro.merge(
    total_edificios_cuenca, on="Cuenca"
)
exposure_cuenca["proporcion"] = (
    exposure_cuenca["edificios_expuestos"] / exposure_cuenca["total_edificios"]
)

familias_cuenca = (
    settle_hazard_cuencas.drop_duplicates("id_renabap")
    .groupby("Cuenca")["familias_aproximadas"]
    .sum()
    .reset_index()
)

final_exposure_cuenca = exposure_cuenca.merge(familias_cuenca, on="Cuenca")
final_exposure_cuenca["fam_expuestas"] = (
    final_exposure_cuenca["proporcion"] * final_exposure_cuenca["familias_aproximadas"]
)

resultado_exposicion_cuenca = final_exposure_cuenca[
    ["Cuenca", "PELIGROSID", "edificios_expuestos"]
].rename(columns={"PELIGROSID": "peligrosidad"})

# === AN츼LISIS POR EJE ===
# Usar los edificios ya procesados con cuenca y peligro
buildings_eje_final = buildings_cuenca_final.dropna(subset=["eje"]).copy()

# Resolver duplicados por prioridad de peligro
buildings_eje_final.loc[:, "prioridad"] = buildings_eje_final["PELIGROSID"].map(
    hazard_priority
)
buildings_eje_unique = buildings_eje_final.sort_values(
    "prioridad", ascending=False
).drop_duplicates(subset=buildings_eje_final.geometry.name, keep="first")

# Calcular exposici칩n por eje y peligrosidad
edificios_por_eje_peligro = (
    buildings_eje_unique.groupby(["eje", "PELIGROSID"])
    .size()
    .reset_index(name="edificios_expuestos")
)

total_edificios_eje = (
    buildings_with_cuenca.dropna(subset=["eje"])
    .groupby("eje")
    .size()
    .reset_index(name="total_edificios")
)

exposure_eje = edificios_por_eje_peligro.merge(total_edificios_eje, on="eje")
exposure_eje["proporcion"] = (
    exposure_eje["edificios_expuestos"] / exposure_eje["total_edificios"]
)

familias_por_eje = (
    settle_hazard_cuencas.drop_duplicates("id_renabap")
    .groupby("eje")["familias_aproximadas"]
    .sum()
    .reset_index()
)

final_exposure_eje = exposure_eje.merge(familias_por_eje, on="eje")
final_exposure_eje["fam_expuestas"] = (
    final_exposure_eje["proporcion"] * final_exposure_eje["familias_aproximadas"]
)

resultado_exposicion_eje = final_exposure_eje[
    ["eje", "PELIGROSID", "edificios_expuestos"]
].rename(columns={"PELIGROSID": "peligrosidad"})

```

### Limitaciones de los datos del RENABAP

Los datos del RENABAP presentan limitaciones importantes que justifican el uso de huellas de edificios como alternativa m치s precisa. Los datos m치s recientes del RENABAP de 2023 subestiman significativamente el n칰mero total de familias por asentamiento informal. Estos datos se basan en proyecciones derivadas del censo de 2010, lo que ha resultado en estimaciones considerablemente desactualizadas.

```{python}
# | label: fig-error-renabap
# | fig-cap: "Distribuci칩n del error porcentual en las estimaciones del RENABAP comparado con estimaciones basadas en edificios"


# =============================================================================
# ANALYTICAL PROCESSING: RENABAP DATA VALIDATION
# =============================================================================

# Calcular familias estimadas basadas en edificios (1,1 familias por edificio)
ratio_fam_edif = (
    buildings_with_barrios.groupby(["id_renabap", "familias_aproximadas"])
    .size()
    .reset_index(name="total_edificios")
)

ratio_fam_edif["familias_estimadas_edificios"] = ratio_fam_edif["total_edificios"] * 1.1
# Calcular el error porcentual: (RENABAP - Edificios) / Edificios * 100
ratio_fam_edif["error_porcentual"] = (
    (
        ratio_fam_edif["familias_aproximadas"]
        - ratio_fam_edif["familias_estimadas_edificios"]
    )
    / ratio_fam_edif["familias_estimadas_edificios"]
) * 100

# =============================================================================
# GRAPHICS: RENABAP ERROR ANALYSIS
# =============================================================================

# Crear histograma
plt.figure(figsize=(12, 6))
plt.hist(
    ratio_fam_edif["error_porcentual"],
    bins=30,
    edgecolor="none",
    color=PELIGROSIDAD_COLORS["media"],
)

# Personalizar el gr치fico
plt.title(
    "Error de Estimaci칩n de RENABAP vs Estimaci칩n por Edificios",
    fontsize=16,
    fontweight="bold",
)
plt.xlabel("Error Porcentual (%)", fontsize=12)
plt.ylabel("Frecuencia (N칰mero de Barrios)", fontsize=12)

# Agregar l칤neas de referencia
mean_error = ratio_fam_edif["error_porcentual"].mean()
median_error = ratio_fam_edif["error_porcentual"].median()

# Rango de personas no contabilizadas (3-5 personas por vivienda)
personas_min_faltantes = round(viviendas_faltantes * 3, -3)  # Round to nearest thousand
personas_max_faltantes = round(viviendas_faltantes * 5, -3)  # Round to nearest thousand

plt.axvline(
    mean_error,
    color="black",
    linestyle="--",
    linewidth=2,
    label=f"Error promedio: {mean_error:.1f}%",
)
plt.axvline(
    median_error,
    color="black",
    linestyle="dotted",
    linewidth=2,
    label=f"Error mediano: {median_error:.1f}%",
)


plt.legend()
plt.tight_layout()
plt.show()

```

Nuestro an치lisis comparativo entre los datos del RENABAP y el conteo de huellas de edificios revela que el RENABAP subestima el n칰mero de estructuras habitacionales en un promedio del `{python} format_number(int(abs(mean_error)))`%. A nivel agregado, esto se traduce en aproximadamente `{python} format_number(viviendas_faltantes)` viviendas faltantes que no est치n contabilizadas en las estad칤sticas oficiales del RENABAP. Considerando un rango razonable de 3 a 5 personas por vivienda, esta subestimaci칩n representa entre `{python} format_number(personas_min_faltantes)` y `{python} format_number(personas_max_faltantes)` personas que podr칤an estar no contabilizadas en los asentamientos informales. Esta discrepancia masiva demuestra claramente las limitaciones cr칤ticas del RENABAP para la evaluaci칩n precisa de la exposici칩n a riesgos de inundaci칩n y la planificaci칩n de pol칤ticas p칰blicas.

Tambi칠n podemos examinar im치genes satelitales de un asentamiento informal de muestra con las huellas de edificios superpuestas para tener una idea de la veracidad de los datos. Aqu칤 est치 un barrio llamado Los Pinos, en el cual mapeamos la extensi칩n del RENABAP del barrio y las huellas de los edificios dentro de 칠l. Las estimaciones del RENABAP dicen que este asentamiento informal tiene solo 72 familias. Nuestros datos cuentan 519 edificios. Si usamos la estimaci칩n del RENABAP de aproximadamente 1,1 familias por edificio, que es lo que calculan en sus datos originales, estamos hablando de un total de 570 familias, que es casi ocho veces m치s de lo que los datos del RENABAP contabilizan.

```{python}
# | label: fig-ejemplo-barrio
# | fig-cap: "Ejemplo de discrepancia en los datos del RENABAP: el barrio Los Pinos con l칤mites oficiales y edificios detectadas"

# Filtrar para obtener solo el barrio con id_renabap 5688
barrio_5688 = renabap_pba_intersect[renabap_pba_intersect["id_renabap"] == 5688].copy()
if len(barrio_5688) == 0:
    print("No se encontr칩 el barrio con id_renabap 5688")
else:
    # Obtener edificios en este barrio
    buildings_5688 = buildings_with_barrios[
        buildings_with_barrios["id_renabap"] == 5688
    ].copy()
    # Convertir a Web Mercator
    barrio_5688_3857 = barrio_5688.to_crs(WEB_MERCATOR_CRS)
    buildings_5688_3857 = buildings_5688.to_crs(WEB_MERCATOR_CRS)
    # Crear el mapa
    fig, ax = plt.subplots(figsize=DEFAULT_FIGSIZE)
    # Configurar l칤mites basados en el barrio
    bounds = barrio_5688_3857.total_bounds
    margin = 50  # metros
    ax.set_xlim(bounds[0] - margin, bounds[2] + margin)
    ax.set_ylim(bounds[1] - margin, bounds[3] + margin)
    # Agregar basemap de contextily
    cx.add_basemap(ax, crs=WEB_MERCATOR_CRS, source=cx.providers.Esri.WorldImagery, attribution="Datos: RENABAP (2023), VIDA (2023) | Mapa base: Esri (2025), Carto (2025)")
    # Plot de edificios con contorno naranja (sin fill)
    buildings_5688_3857.plot(
        ax=ax, facecolor="none", edgecolor=PELIGROSIDAD_COLORS["media"], linewidth=1
    )
    # Plot del l칤mite del barrio con estilo consistente
    barrio_5688_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor="white",  # White for satellite imagery visibility
        linewidth=3,
        linestyle="--",
        zorder=10,
    )

    cx.add_basemap(ax, crs=WEB_MERCATOR_CRS, source=cx.providers.CartoDB.PositronOnlyLabels, attribution="")


    scale_bar(
        ax=ax,
        location="upper left",
        style="ticks",
        bar={
            "projection": "axis",
            "minor_type": "none",
            "tickcolors": "white",
            "basecolors": "white",
            "max": 100,
        },
        labels={"style": "first_last", "textcolors": ["white"], "stroke_width": 0},
        units={"label": "m", "textcolor": "white", "stroke_width": 0},
    )

    north_arrow(
        ax,
        location="upper right",
        scale=0.3,  # Small size
        rotation={"degrees": 0},
        base={"facecolor": "none", "edgecolor": "white", "linewidth": 1},
        fancy=True,
        shadow=True,
        label=False,  # Hide the "N" text
    )

    # Limpiar el mapa
    barrio_nombre = barrio_5688["nombre_barrio"].iloc[0]
    familias_renabap = int(barrio_5688["familias_aproximadas"].iloc[0])
    total_edificios = len(buildings_5688)

    # T칤tulo principal usando suptitle
    fig.suptitle(
        f"Barrio {barrio_nombre} - L칤mites y edificios",
        fontsize=16,
        fontweight="bold",
        y=0.98,
    )

    # Subt칤tulo usando title
    ax.set_title(
        f"RENABAP: {familias_renabap} familias | Edificios detectados: {total_edificios}",
        fontsize=12,
        style="italic",
        pad=30,
    )
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xlabel("")
    ax.set_ylabel("")
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)
    ax.spines["left"].set_visible(False)
    # Agregar leyenda simple
    legend_elements = [
        plt.Line2D([0], [0], color="white", linewidth=3, label="L칤mite del barrio"),
        plt.Line2D(
            [0],
            [0],
            color=PELIGROSIDAD_COLORS["media"],
            linewidth=1,
            label="edificios",
        ),
    ]
    ax.legend(handles=legend_elements, loc="lower right", bbox_to_anchor=(1.0, 0.02))
    plt.tight_layout()
    plt.show()

```

Al examinar otros ejemplos de barrios con las mayores discrepancias entre las huellas de edificios detectadas y los datos oficiales del RENABAP, observamos que frecuentemente encontramos 칩rdenes de magnitud m치s edificios que familias estimadas, representando miles de familias no contabilizadas.

```{python}
# | layout-ncol: 2
# | label: fig-ejemplos-barrios-adicionales

# IDs de los barrios a visualizar
barrio_ids = [4577, 65, 6541, 17]

for i, barrio_id in enumerate(barrio_ids):
    # Filtrar para obtener el barrio espec칤fico
    barrio_data = renabap_pba_intersect[
        renabap_pba_intersect["id_renabap"] == barrio_id
    ].copy()

    if len(barrio_data) == 0:
        print(f"No se encontr칩 el barrio con id_renabap {barrio_id}")
        continue

    # Obtener edificios en este barrio
    buildings_data = buildings_with_barrios[
        buildings_with_barrios["id_renabap"] == barrio_id
    ].copy()

    # Convertir a Web Mercator
    barrio_3857 = barrio_data.to_crs(WEB_MERCATOR_CRS)
    buildings_3857 = buildings_data.to_crs(WEB_MERCATOR_CRS)

    # Crear el mapa individual
    fig, ax = plt.subplots(figsize=DEFAULT_FIGSIZE)

    # Configurar l칤mites basados en el barrio
    bounds = barrio_3857.total_bounds
    margin = 50  # metros
    ax.set_xlim(bounds[0] - margin, bounds[2] + margin)
    ax.set_ylim(bounds[1] - margin, bounds[3] + margin)

    # Agregar basemap de contextily
    cx.add_basemap(
        ax, crs=WEB_MERCATOR_CRS, source=cx.providers.Esri.WorldImagery, attribution="Datos: RENABAP (2023), VIDA (2023) | Mapa base: Esri (2025)"
    )

    # Plot de edificios con contorno naranja (sin fill)
    buildings_3857.plot(
        ax=ax, facecolor="none", edgecolor=PELIGROSIDAD_COLORS["media"], linewidth=1
    )

    # Plot del l칤mite del barrio con estilo consistente
    barrio_3857.plot(
        ax=ax,
        facecolor="none",
        edgecolor="white",
        linewidth=3,
        linestyle="--",
        zorder=10,
    )


    cx.add_basemap(ax, crs=WEB_MERCATOR_CRS, source=cx.providers.CartoDB.PositronOnlyLabels, attribution="")

    scale_bar(
        ax=ax,
        location="upper left",
        style="ticks",
        bar={
            "projection": "axis",
            "minor_type": "none",
            "tickcolors": "white",
            "basecolors": "white",
            "max": 200,
        },
        labels={"style": "first_last", "textcolors": ["white"], "stroke_width": 0},
        units={"label": "m", "textcolor": "white", "stroke_width": 0},
    )

    # Agregar flecha del norte
    north_arrow(
        ax,
        location="upper right",
        scale=0.3,
        rotation={"degrees": 0},
        base={"facecolor": "none", "edgecolor": "white", "linewidth": 1},
        fancy=True,
        shadow=True,
        label=False,
    )

    # Obtener informaci칩n del barrio
    barrio_nombre = barrio_data["nombre_barrio"].iloc[0]
    familias_renabap = int(barrio_data["familias_aproximadas"].iloc[0])
    total_edificios = len(buildings_data)

    # T칤tulo principal usando suptitle
    fig.suptitle(f"Barrio {barrio_nombre}", fontsize=16, fontweight="bold", y=0.98)

    # Subt칤tulo usando title
    ax.set_title(
        f"RENABAP: {familias_renabap} familias | Edificios detectados: {total_edificios}",
        fontsize=12,
        style="italic",
        pad=30,
    )

    # Limpiar el mapa
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xlabel("")
    ax.set_ylabel("")
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)
    ax.spines["left"].set_visible(False)

    plt.tight_layout()
    plt.show()


```

## Procesamiento y resultados

```{python}

# =============================================================================
# EXPOSICI칍N POR BARRIO
# =============================================================================
# Preparar datos - solo alta y media
exposure_data = resultado_exposicion_barrio[
    resultado_exposicion_barrio["peligrosidad"].isin(["alta", "media"])
].copy()

# Merge con geometr칤as para obtener centroides
exposure_gdf = exposure_data.merge(
    renabap_pba_intersect[["id_renabap", "geometry"]], on="id_renabap"
)
exposure_gdf = gpd.GeoDataFrame(exposure_gdf, geometry="geometry", crs=USE_CRS)

# Convertir a Web Mercator para el plotting
exposure_gdf_3857 = exposure_gdf.to_crs(WEB_MERCATOR_CRS)
la_plata_3857 = la_plata.to_crs(WEB_MERCATOR_CRS)


# Filtrar exposici칩n alta y media por nombre de barrio (excluyendo "Sin Nombre")
barrios_alta_data = (
    resultado_exposicion_barrio[
        (resultado_exposicion_barrio["peligrosidad"] == "alta")
        & (resultado_exposicion_barrio["nombre_barrio"] != "Sin Nombre")
    ]
    .groupby("nombre_barrio")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
    .head(10)
)

barrios_media_data = (
    resultado_exposicion_barrio[
        (resultado_exposicion_barrio["peligrosidad"] == "media")
        & (resultado_exposicion_barrio["nombre_barrio"] != "Sin Nombre")
    ]
    .groupby("nombre_barrio")["edificios_expuestos"]
    .sum()
    .reset_index()
)

# Merge para tener ambos niveles
barrios_combined = barrios_alta_data.merge(
    barrios_media_data, on="nombre_barrio", how="left", suffixes=("_alta", "_media")
)
barrios_combined["edificios_expuestos_media"] = barrios_combined[
    "edificios_expuestos_media"
].fillna(0)

# =============================================================================
# EXPOSICI칍N POR CUENCA Y EJE
# =============================================================================

cuenca_alta_data = (
    resultado_exposicion_cuenca[resultado_exposicion_cuenca["peligrosidad"] == "alta"]
    .groupby("Cuenca")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
)

cuenca_media_data = (
    resultado_exposicion_cuenca[resultado_exposicion_cuenca["peligrosidad"] == "media"]
    .groupby("Cuenca")["edificios_expuestos"]
    .sum()
    .reset_index()
)

# Merge para tener ambos niveles
cuenca_combined = cuenca_alta_data.merge(
    cuenca_media_data, on="Cuenca", how="left", suffixes=("_alta", "_media")
)
cuenca_combined["edificios_expuestos_media"] = cuenca_combined[
    "edificios_expuestos_media"
].fillna(0)

# === GR츼FICO DE EJES ===
# Filtrar exposici칩n alta y media por eje
eje_alta_data = (
    resultado_exposicion_eje[resultado_exposicion_eje["peligrosidad"] == "alta"]
    .groupby("eje")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
)

eje_media_data = (
    resultado_exposicion_eje[resultado_exposicion_eje["peligrosidad"] == "media"]
    .groupby("eje")["edificios_expuestos"]
    .sum()
    .reset_index()
)

# Merge para tener ambos niveles
eje_combined = eje_alta_data.merge(
    eje_media_data, on="eje", how="left", suffixes=("_alta", "_media")
)
eje_combined["edificios_expuestos_media"] = eje_combined[
    "edificios_expuestos_media"
].fillna(0)

# =============================================================================
# CALCULAR ESTAD칈STICAS RESUMEN PARA EL TEXTO
# =============================================================================

# Totales de edificios expuestos (sin duplicados)
# Los edificios que intersectan con ambos peligros ya est치n resueltos por prioridad en buildings_barrio_unique
total_buildings_high_hazard = int(buildings_barrio_unique[buildings_barrio_unique["PELIGROSID"] == "alta"].shape[0])
total_buildings_medium_hazard = int(buildings_barrio_unique[buildings_barrio_unique["PELIGROSID"] == "media"].shape[0])
total_buildings_exposed = total_buildings_high_hazard + total_buildings_medium_hazard

# Total de edificios en barrios
total_buildings_in_barrios = len(buildings_with_barrios)
percentage_exposed = float(round((total_buildings_exposed / total_buildings_in_barrios) * 100, 1))

# Top 5 barrios por exposici칩n a peligro alto
top_5_barrios_alta = (
    resultado_exposicion_barrio[
        (resultado_exposicion_barrio["peligrosidad"] == "alta") & 
        (resultado_exposicion_barrio["nombre_barrio"] != "Sin Nombre")
    ]
    .groupby("nombre_barrio")["edificios_expuestos"]
    .sum()
    .reset_index()
    .sort_values("edificios_expuestos", ascending=False)
    .head(5)
    .merge(
        buildings_with_barrios.groupby("nombre_barrio").size().reset_index(name="total_edificios_barrio"),
        on="nombre_barrio"
    )
    .assign(porcentaje=lambda x: (x["edificios_expuestos"] / x["total_edificios_barrio"] * 100).round(1).astype(float))
)

# Top 5 cuencas con desglose por peligrosidad usando pivot
top_5_cuencas = (
    resultado_exposicion_cuenca
    .pivot_table(
        index="Cuenca", 
        columns="peligrosidad", 
        values="edificios_expuestos", 
        aggfunc="sum", 
        fill_value=0
    )
    .reset_index()
    .assign(edificios_expuestos_total=lambda x: x["alta"] + x["media"])
    .rename(columns={"alta": "edificios_expuestos_alta", "media": "edificios_expuestos_media"})
    .merge(
        total_edificios_cuenca, 
        on="Cuenca"
    )
    .sort_values("edificios_expuestos_total", ascending=False)
    .head(5)
)

```

En los barrios populares de La Plata se identifican `{python} format_number(total_buildings_exposed)` edificios expuestas a peligros de inundaci칩n bajo el escenario de Precipitaci칩n M치xima Probable (PMP), lo que representa el `{python} format_number(percentage_exposed, 1)`% del total de edificios en asentamientos informales. De estas, `{python} format_number(total_buildings_high_hazard)` edificios se encuentran en zonas de peligro alto (`{python} format_number(round(total_buildings_high_hazard / total_buildings_exposed * 100, 1), 1)`%) y `{python} format_number(total_buildings_medium_hazard)` en zonas de peligro medio (`{python} format_number(round(total_buildings_medium_hazard / total_buildings_exposed * 100, 1), 1)`%).

La exposici칩n se concentra principalmente en los alrededores del casco urbano de La Plata, con una distribuci칩n caracter칤stica donde pocos barrios presentan exposici칩n muy alta, seguidos por un grupo de exposici칩n media. `{python} top_5_barrios_alta.iloc[0]['nombre_barrio']` lidera con `{python} format_number(int(top_5_barrios_alta.iloc[0]['edificios_expuestos']))` edificios expuestas a peligro alto (`{python} format_number(float(top_5_barrios_alta.iloc[0]['porcentaje']), 1)`% del barrio), seguido por `{python} top_5_barrios_alta.iloc[1]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[1]['edificios_expuestos']))` edificios (`{python} format_number(float(top_5_barrios_alta.iloc[1]['porcentaje']), 1)`%), `{python} top_5_barrios_alta.iloc[2]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[2]['edificios_expuestos']))` (`{python} format_number(float(top_5_barrios_alta.iloc[2]['porcentaje']), 1)`%), `{python} top_5_barrios_alta.iloc[3]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[3]['edificios_expuestos']))` (`{python} format_number(float(top_5_barrios_alta.iloc[3]['porcentaje']), 1)`%), y `{python} top_5_barrios_alta.iloc[4]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[4]['edificios_expuestos']))` edificios (`{python} format_number(float(top_5_barrios_alta.iloc[4]['porcentaje']), 1)`%).

A nivel de cuencas hidrogr치ficas, `{python} top_5_cuencas.iloc[0]['Cuenca']` concentra la mayor exposici칩n con `{python} format_number(int(top_5_cuencas.iloc[0]['edificios_expuestos_total']))` edificios expuestas (`{python} format_number(round(top_5_cuencas.iloc[0]['edificios_expuestos_total'] / top_5_cuencas.iloc[0]['total_edificios'] * 100, 1), 1)`% del total de edificios en asentamientos informales de la cuenca; `{python} format_number(int(top_5_cuencas.iloc[0]['edificios_expuestos_alta']))` a peligro alto y `{python} format_number(int(top_5_cuencas.iloc[0]['edificios_expuestos_media']))` a peligro medio), principalmente debido a la presencia de `{python} top_5_barrios_alta.iloc[0]['nombre_barrio']` y otros asentamientos importantes. Le sigue `{python} top_5_cuencas.iloc[1]['Cuenca']` con `{python} format_number(int(top_5_cuencas.iloc[1]['edificios_expuestos_total']))` edificios (`{python} format_number(round(top_5_cuencas.iloc[1]['edificios_expuestos_total'] / top_5_cuencas.iloc[1]['total_edificios'] * 100, 1), 1)`% del total; `{python} format_number(int(top_5_cuencas.iloc[1]['edificios_expuestos_alta']))` alta, `{python} format_number(int(top_5_cuencas.iloc[1]['edificios_expuestos_media']))` media) y `{python} top_5_cuencas.iloc[2]['Cuenca']` con `{python} format_number(int(top_5_cuencas.iloc[2]['edificios_expuestos_total']))` edificios (`{python} format_number(round(top_5_cuencas.iloc[2]['edificios_expuestos_total'] / top_5_cuencas.iloc[2]['total_edificios'] * 100, 1), 1)`% del total; `{python} format_number(int(top_5_cuencas.iloc[2]['edificios_expuestos_alta']))` alta, `{python} format_number(int(top_5_cuencas.iloc[2]['edificios_expuestos_media']))` media). 

### Comparaci칩n metodol칩gica

Una comparaci칩n entre el enfoque tradicional de interpolaci칩n areal (basado en datos RENABAP) y nuestro an치lisis a nivel de edificio revela diferencias significativas en las estimaciones de exposici칩n. Utilizando interpolaci칩n areal, donde se asume que las familias se distribuyen uniformemente en los asentamientos informales, se estima que `{python} format_number(int(round(total_familias * (barrios_pct_peligro_alta + barrios_pct_peligro_media) / 100)))` familias estar칤an expuestas a peligros de inundaci칩n (`{python} format_number(round((total_familias * (barrios_pct_peligro_alta + barrios_pct_peligro_media) / 100) / total_familias * 100, 1), 1)`% del total de familias seg칰n RENABAP), con `{python} format_number(int(round(total_familias * barrios_pct_peligro_alta / 100)))` familias en zonas de peligro alto y `{python} format_number(int(round(total_familias * barrios_pct_peligro_media / 100)))` en zonas de peligro medio.

En contraste, nuestro an치lisis a nivel de edificio identifica `{python} format_number(int(round((total_buildings_high_hazard + total_buildings_medium_hazard) * 1.1)))` familias expuestas (`{python} format_number(round(((total_buildings_high_hazard + total_buildings_medium_hazard) * 1.1) / (len(buildings_in_barrios) * 1.1) * 100, 1), 1)`% del total de familias seg칰n nuestro an치lisis), representando `{python} format_number(int(round(total_buildings_high_hazard * 1.1)))` familias en peligro alto y `{python} format_number(int(round(total_buildings_medium_hazard * 1.1)))` en peligro medio. Esta diferencia se debe principalmente a la identificaci칩n de aproximadamente el doble de edificios en asentamientos informales de lo que sugieren los datos oficiales del RENABAP.

Sin embargo, cuando se analiza la proporci칩n de exposici칩n relativa, nuestro an치lisis a nivel de edificio muestra una exposici칩n proporcional menor (`{python} format_number(percentage_exposed, 1)`% vs `{python} format_number(round((barrios_pct_peligro_alta + barrios_pct_peligro_media), 1), 1)`%), lo que demuestra que la interpolaci칩n areal sobrestima la exposici칩n relativa al asumir una distribuci칩n uniforme de la poblaci칩n. Nuestro enfoque basado en edificios individuales retorna un mayor n칰mero total de poblaci칩n expuesta debido a la identificaci칩n de aproximadamente el doble de edificios que los datos oficiales del RENABAP, pero una menor proporci칩n de exposici칩n relativa debido a que no asume que la poblaci칩n se distribuye uniformemente en el espacio, sino que refleja la distribuci칩n real de los edificios.

### Exposici칩n por barrio

```{python}
# | label: fig-exposicion-barrios
# | fig-cap: "Mapa de exposici칩n de barrios populares por nivel de peligrosidad de inundaci칩n"

# Crear el mapa
fig, ax = plt.subplots(figsize=DEFAULT_FIGSIZE)

# Configurar l칤mites
bounds = la_plata_3857.total_bounds
margin = 2000  # metros
ax.set_xlim(bounds[0] - margin, bounds[2] + margin)
ax.set_ylim(bounds[1] - margin, bounds[3] + margin)

# Agregar basemap de contextily
cx.add_basemap(
    ax, crs=WEB_MERCATOR_CRS, source=cx.providers.CartoDB.PositronNoLabels, alpha=0.7, attribution="Datos: RENABAP (2023), VIDA (2023) | Mapa base: Carto (2025)"
)

# Plot de puntos con jitter
np.random.seed(42)
plotting_order = ["media", "alta"]

for peligrosidad in plotting_order:
    level_data = exposure_gdf_3857[exposure_gdf_3857["peligrosidad"] == peligrosidad]
    for _, row in level_data.iterrows():
        centroid = row["geometry"].centroid
        jitter_x = np.random.uniform(-200, 200)
        jitter_y = np.random.uniform(-200, 200)
        x_pos = centroid.x + jitter_x
        y_pos = centroid.y + jitter_y
        color = PELIGROSIDAD_COLORS[row["peligrosidad"]]
        size = max(10, row["edificios_expuestos"] * 0.5 + 15)
        ax.scatter(
            x_pos,
            y_pos,
            s=size,
            color=color,
            alpha=0.9,
            edgecolors="white",
            linewidth=1.0,
        )

# Leyenda de peligrosidad
legend_elements_peligro = [
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor=PELIGROSIDAD_COLORS["alta"],
        markersize=8,
        label="Alta",
    ),
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor=PELIGROSIDAD_COLORS["media"],
        markersize=8,
        label="Media",
    ),
]

# Leyenda de tama침o
building_values = [100, 500, 1000]
legend_elements_size = []
for val in building_values:
    size = max(10, val * 0.5 + 15)
    legend_elements_size.append(
        plt.Line2D(
            [0],
            [0],
            marker="o",
            color="w",
            markerfacecolor="gray",
            markersize=np.sqrt(size / 10),
            label=f"{val} edificios",
        )
    )

# Crear leyendas lado a lado en bottom right
legend1 = ax.legend(
    handles=legend_elements_peligro,
    title="Nivel de peligrosidad",
    loc="lower right",
    bbox_to_anchor=(0.85, 0),
)
ax.add_artist(legend1)

legend2 = ax.legend(
    handles=legend_elements_size,
    title="Edificios expuestos",
    loc="lower right",
    bbox_to_anchor=(1.0, 0),
)


add_boundary_outline(ax, la_plata_3857)

# Agregar escala y flecha norte para consistencia
add_scale_bar_and_north_arrow(ax, length=0.20)

# Limpiar el mapa - quitar bordes, ticks, etc.
ax.set_title(
    "Exposici칩n de Barrios Populares por Nivel de Peligrosidad",
    fontsize=14,
    fontweight="bold",
    pad=20,
)
ax.set_axis_off()

plt.tight_layout()
plt.show()



# Crear el gr치fico de barras
fig, ax = plt.subplots(figsize=(12, 8))
x = np.arange(len(barrios_combined))
width = 0.35

bars1 = ax.bar(
    x - width / 2,
    barrios_combined["edificios_expuestos_alta"],
    width,
    label="Peligro Alto",
    color=PELIGROSIDAD_COLORS["alta"],
)
bars2 = ax.bar(
    x + width / 2,
    barrios_combined["edificios_expuestos_media"],
    width,
    label="Peligro Medio",
    color=PELIGROSIDAD_COLORS["media"],
)

ax.set_xlabel("Barrios", fontsize=12)
ax.set_ylabel("Edificios Expuestos", fontsize=12)
ax.set_title("Top 10 Barrios por Edificios Expuestos", fontsize=14, fontweight="bold")
ax.set_xticks(x)
ax.set_xticklabels(barrios_combined["nombre_barrio"], rotation=45, ha="right")
ax.legend(loc="upper right")

# Agregar valores en las barras
for bar in bars1:
    height = bar.get_height()
    if height > 0:
        ax.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 5,
            f"{int(height)}",
            ha="center",
            va="bottom",
            fontsize=10,
        )

for bar in bars2:
    height = bar.get_height()
    if height > 0:
        ax.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 5,
            f"{int(height)}",
            ha="center",
            va="bottom",
            fontsize=10,
        )

plt.tight_layout()
plt.show()

show(resultado_exposicion_barrio)
```

### Exposici칩n por cuenca y eje

```{python}
# | layout-ncol: 2
# | label: fig-exposicion-cuencas-ejes
# | fig-cap: "Exposici칩n por cuencas hidrogr치ficas y ejes territoriales"
# | fig-subcap:
# |   - "Cuencas por edificios expuestas"
# |   - "Ejes por edificios expuestas"



# Crear gr치fico de cuencas
fig1, ax1 = plt.subplots(figsize=DEFAULT_FIGSIZE)
x = np.arange(len(cuenca_combined))
width = 0.35

bars1 = ax1.bar(
    x - width / 2,
    cuenca_combined["edificios_expuestos_alta"],
    width,
    label="Peligro Alto",
    color=PELIGROSIDAD_COLORS["alta"],
)
bars2 = ax1.bar(
    x + width / 2,
    cuenca_combined["edificios_expuestos_media"],
    width,
    label="Peligro Medio",
    color=PELIGROSIDAD_COLORS["media"],
)

ax1.set_xlabel("Cuencas", fontsize=12)
ax1.set_ylabel("Edificios Expuestos", fontsize=12)
ax1.set_title("Cuencas por edificios Expuestas", fontsize=14, fontweight="bold")
ax1.set_xticks(x)
ax1.set_xticklabels(cuenca_combined["Cuenca"], rotation=45, ha="right")
ax1.legend(loc="upper right")

# Agregar valores en las barras
for bar in bars1:
    height = bar.get_height()
    if height > 0:
        ax1.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 20,
            f"{int(height)}",
            ha="center",
            va="bottom",
            fontsize=10,
        )

for bar in bars2:
    height = bar.get_height()
    if height > 0:
        ax1.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 20,
            f"{int(height)}",
            ha="center",
            va="bottom",
            fontsize=10,
        )

plt.tight_layout()
plt.show()



# Crear gr치fico de ejes
fig2, ax2 = plt.subplots(figsize=DEFAULT_FIGSIZE)
x = np.arange(len(eje_combined))
width = 0.35

bars1 = ax2.bar(
    x - width / 2,
    eje_combined["edificios_expuestos_alta"],
    width,
    label="Peligro Alto",
    color=PELIGROSIDAD_COLORS["alta"],
)
bars2 = ax2.bar(
    x + width / 2,
    eje_combined["edificios_expuestos_media"],
    width,
    label="Peligro Medio",
    color=PELIGROSIDAD_COLORS["media"],
)

ax2.set_xlabel("Ejes", fontsize=12)
ax2.set_ylabel("Edificios Expuestos", fontsize=12)
ax2.set_title("Ejes por edificios Expuestas", fontsize=14, fontweight="bold")
ax2.set_xticks(x)
ax2.set_xticklabels(eje_combined["eje"], rotation=45, ha="right")
ax2.legend(loc="upper right")

# Agregar valores en las barras
for bar in bars1:
    height = bar.get_height()
    if height > 0:
        ax2.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 10,
            f"{int(height)}",
            ha="center",
            va="bottom",
            fontsize=10,
        )

for bar in bars2:
    height = bar.get_height()
    if height > 0:
        ax2.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 10,
            f"{int(height)}",
            ha="center",
            va="bottom",
            fontsize=10,
        )

plt.tight_layout()
plt.show()

```

### Comparativa de periodos de retorno

La implementaci칩n de diferentes pol칤ticas de gesti칩n de riesgo depende de la evaluaci칩n del potencial de exposici칩n, y el escenario de precipitaci칩n m치xima probable (PMP) se utiliza como el m치ximo probable de precipitaci칩n para los c치lculos del modelo hidrol칩gico que requieren priorizaci칩n. Para pol칤ticas que requieren priorizaci칩n, como la relocalizaci칩n de residentes en asentamientos informales, es importante elegir un per칤odo de retorno que sea apropiado para la pol칤tica que se est치 considerando. En este an치lisis, hemos mostrado diferencias significativas entre la exposici칩n de edificios dependiendo de si se utiliza el escenario PMP, el per칤odo de retorno de 25 a침os, o el per칤odo de retorno de 100 a침os para calcular el riesgo.
```{python}
# | cache: true
# | layout-ncol: 3
# | label: fig-escenarios-maldonado
# | fig-cap: "Escenarios de peligrosidad en Cuenca Maldonado"
# | fig-subcap:
# |   - "PMP (Precipitaci칩n M치xima Probable)"
# |   - "R100 (Per칤odo de retorno 100 a침os)"
# |   - "R25 (Per칤odo de retorno 25 a침os)"
# | lightbox:
# |   group: escenarios-maldonado


# =============================================================================
# GRAPHICS: RETURN PERIOD COMPARISON
# =============================================================================

# Preparar datos de cuenca Maldonado para clipping
cuenca_maldonado = cuencas[cuencas["Cuenca"] == "Cuenca A춿 Maldonado"].copy()


# Rutas de archivos
r100_path = "/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R100_polig.shp"
r25_path = "/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/raster verctorizados/Peligrosidad_R25_polig.shp"

# Color mapping para R100 y R25
color_mapping = {
    "Medio": PELIGROSIDAD_COLORS["media"],
    "Alto": PELIGROSIDAD_COLORS["alta"],
}

# === MAPA PMP ===
peligro_pmp_maldonado = gpd.clip(peligro_la_plata, cuenca_maldonado)
peligro_pmp_maldonado = peligro_pmp_maldonado[
    peligro_pmp_maldonado["PELIGROSID"].isin(["alta", "media"])
]
peligro_pmp_maldonado_3857 = peligro_pmp_maldonado.to_crs(WEB_MERCATOR_CRS)

fig1, ax1 = create_consistent_map(
    "PMP (Precipitaci칩n M치xima Probable)", crs=USE_CRS, boundary_gdf=cuenca_maldonado, attribution="Datos: Romanazzi et al. (2019), DIPSOH (2025) | Mapa base: Carto (2025)", scalebar_length=0.2
)
peligro_pmp_maldonado_3857.plot(
    ax=ax1,
    color=peligro_pmp_maldonado_3857["PELIGROSID"].map(PELIGROSIDAD_COLORS),
    alpha=0.75,
    zorder=5,
)
ax1.legend(handles=PELIGROSIDAD_LEGEND, loc="lower right")
plt.tight_layout()
plt.show()

# === MAPA R100 ===
pelig_100_maldonado = gpd.read_file(r100_path).to_crs(USE_CRS)
pelig_100_maldonado = pelig_100_maldonado[
    pelig_100_maldonado["peli"].isin(["Alto", "Medio"])
]
pelig_100_maldonado_clipped_3857 = gpd.clip(
    pelig_100_maldonado, cuenca_maldonado
).to_crs(WEB_MERCATOR_CRS)

fig2, ax2 = create_consistent_map(
    "R100 (Per칤odo de retorno 100 a침os)", crs=USE_CRS, boundary_gdf=cuenca_maldonado, attribution="Datos: Carner et al.. (en prensa), DIPSOH (2025) | Mapa base: Carto (2025)", scalebar_length=0.2
)
pelig_100_maldonado_clipped_3857.plot(
    ax=ax2,
    color=pelig_100_maldonado_clipped_3857["peli"].map(color_mapping),
    alpha=0.75,
    zorder=5,
)
ax2.legend(handles=PELIGROSIDAD_LEGEND, loc="lower right")
plt.tight_layout()
plt.show()

# === MAPA R25 ===
pelig_25_maldonado = gpd.read_file(r25_path).to_crs(USE_CRS)
pelig_25_maldonado = pelig_25_maldonado[
    pelig_25_maldonado["peli"].isin(["Alto", "Medio"])
]
pelig_25_maldonado_clipped_3857 = gpd.clip(pelig_25_maldonado, cuenca_maldonado).to_crs(
    WEB_MERCATOR_CRS
)

fig3, ax3 = create_consistent_map(
    "R25 (Per칤odo de retorno 25 a침os)", crs=USE_CRS, boundary_gdf=cuenca_maldonado, attribution="Datos: Carner et al.. (en prensa), DIPSOH (2025) | Mapa base: Carto (2025)", scalebar_length=0.2
)
pelig_25_maldonado_clipped_3857.plot(
    ax=ax3,
    color=pelig_25_maldonado_clipped_3857["peli"].map(color_mapping),
    alpha=0.75,
    zorder=5,
)
ax3.legend(handles=PELIGROSIDAD_LEGEND, loc="lower right")
plt.tight_layout()
plt.show()


# =============================================================================
# ANALYTICAL PROCESSING: RETURN PERIOD DATA
# =============================================================================

# Helper function para procesar datos de peligro
def process_hazard_data(file_path, buildings):
    pelig_data = gpd.read_file(file_path).to_crs(USE_CRS)
    pelig_filtered = pelig_data[pelig_data["peli"].isin(["Alto", "Medio"])].copy()
    pelig_simple = pelig_filtered.dissolve(by="peli").reset_index()

    buildings_with_peligro = gpd.sjoin(
        buildings, pelig_simple[["peli", "geometry"]], how="left", predicate="within"
    )
    buildings_exposed = buildings_with_peligro.dropna(subset=["peli"]).copy()

    hazard_priority = {"Alto": 3, "Medio": 2}
    buildings_exposed.loc[:, "prioridad"] = buildings_exposed["peli"].map(
        hazard_priority
    )
    buildings_unique = buildings_exposed.sort_values(
        "prioridad", ascending=False
    ).drop_duplicates(subset=buildings_exposed.geometry.name, keep="first")

    exposicion = (
        buildings_unique.groupby("peli").size().reset_index(name="edificios_expuestos")
    )
    result = {}
    for _, row in exposicion.iterrows():
        peligro_name = "alta" if row["peli"] == "Alto" else "media"
        result[peligro_name] = row["edificios_expuestos"]
    return result


buildings_maldonado = buildings_with_barrios.copy()

# === DATOS DE LOS TRES ESCENARIOS ===
# PMP
maldonado_pmp = resultado_exposicion_cuenca[
    resultado_exposicion_cuenca["Cuenca"] == "Cuenca A춿 Maldonado"
].copy()
pmp_data = (
    {
        row["peligrosidad"]: int(row["edificios_expuestos"])
        for _, row in maldonado_pmp.iterrows()
    }
    if len(maldonado_pmp) > 0
    else {}
)

# R25 y R100
r25_data = process_hazard_data(r25_path, buildings_maldonado)
r100_data = process_hazard_data(r100_path, buildings_maldonado)

# =============================================================================
# GRAPHICS: FINAL COMPARISON VISUALIZATION
# =============================================================================

# === VISUALIZACI칍N COMPARATIVA ===
escenarios = ["PMP", "R100", "R25"]
alta_values = [
    pmp_data.get("alta", 0),
    r100_data.get("alta", 0),
    r25_data.get("alta", 0),
]
media_values = [
    pmp_data.get("media", 0),
    r100_data.get("media", 0),
    r25_data.get("media", 0),
]
```

Nuestro an치lisis de exposici칩n a nivel de edificio en la Cuenca Maldonado bajo los diversos per칤odos de retorno muestra el impacto del per칤odo de retorno elegido sobre la poblaci칩n expuesta calculada. Bajo el escenario de precipitaci칩n m치xima probable (PMP), observamos `{python} format_number(pmp_data.get('alta', 0))` edificios expuestos a peligro alto y `{python} format_number(pmp_data.get('media', 0))` edificios expuestos a peligro medio, mientras que bajo el per칤odo de retorno de 100 a침os encontramos `{python} format_number(r100_data.get('alta', 0))` edificios en peligro alto y `{python} format_number(r100_data.get('media', 0))` en peligro medio, y bajo el per칤odo de retorno de 25 a침os se identifican `{python} format_number(r25_data.get('alta', 0))` edificios en peligro alto y `{python} format_number(r25_data.get('media', 0))` en peligro medio. 

En t칠rminos comparativos, la exposici칩n bajo PMP es `{python} format_number(round(pmp_data.get('alta', 0) / max(r100_data.get('alta', 1), 1), 1))` veces mayor que bajo R100 para peligro alto y `{python} format_number(round(pmp_data.get('media', 0) / max(r100_data.get('media', 1), 1), 1))` veces mayor para peligro medio. Comparando PMP con R25, la exposici칩n es `{python} format_number(round(pmp_data.get('alta', 0) / max(r25_data.get('alta', 1), 1), 1))` veces mayor para peligro alto y `{python} format_number(round(pmp_data.get('media', 0) / max(r25_data.get('media', 1), 1), 1))` veces mayor para peligro medio. Incluso entre R100 y R25, la exposici칩n es `{python} format_number(round(r100_data.get('alta', 0) / max(r25_data.get('alta', 1), 1), 1))` veces mayor para peligro alto y `{python} format_number(round(r100_data.get('media', 0) / max(r25_data.get('media', 1), 1), 1))` veces mayor para peligro medio. Estos resultados demuestran las diferencias significativas en las estimaciones de exposici칩n que resultan de la elecci칩n del per칤odo de retorno para el c치lculo del riesgo.

```{python}


x = np.arange(len(escenarios))
width = 0.35

fig, ax = plt.subplots(figsize=(10, 6))
bars1 = ax.bar(
    x - width / 2,
    alta_values,
    width,
    label="Peligro Alto",
    color=PELIGROSIDAD_COLORS["alta"],
)
bars2 = ax.bar(
    x + width / 2,
    media_values,
    width,
    label="Peligro Medio",
    color=PELIGROSIDAD_COLORS["media"],
)

ax.set_xlabel("Escenario de Precipitaci칩n", fontsize=12)
ax.set_ylabel("Edificios Expuestos", fontsize=12)
ax.set_title(
    "Exposici칩n en Cuenca Maldonado por Escenario de Precipitaci칩n",
    fontsize=14,
    fontweight="bold",
)
ax.set_xticks(x)
ax.set_xticklabels(escenarios)
ax.legend(loc="upper right")


def add_value_labels(bars):
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height + 20,
                f"{int(height)}",
                ha="center",
                va="bottom",
                fontsize=10,
            )


add_value_labels(bars1)
add_value_labels(bars2)
plt.tight_layout()
plt.show()
```

## Conclusiones

Los datos de huellas de edificios nos permiten realizar evaluaciones significativamente m치s precisas de la exposici칩n en asentamientos informales en todo el partido y revelan una subestimaci칩n cr칤tica en los datos oficiales. Este an치lisis identifica aproximadamente `{python} format_number(viviendas_faltantes)` viviendas faltantes que no est치n contabilizadas en los datos del RENABAP, lo que representa potencialmente entre `{python} format_number(personas_min_faltantes)` y `{python} format_number(personas_max_faltantes)` personas no contabilizadas en los asentamientos informales (usando un rango razonable de 3 a 5 personas por vivienda). Esta discrepancia tiene implicaciones profundas para la planificaci칩n de gesti칩n de riesgo y la asignaci칩n de recursos.

En los barrios populares de La Plata se identifican `{python} format_number(total_buildings_exposed)` edificios expuestas a peligros de inundaci칩n bajo el escenario de Precipitaci칩n M치xima Probable (PMP), lo que representa el `{python} format_number(percentage_exposed, 1)`% del total de edificios en asentamientos informales. De estas, `{python} format_number(total_buildings_high_hazard)` edificios se encuentran en zonas de peligro alto (`{python} format_number(round(total_buildings_high_hazard / total_buildings_exposed * 100, 1), 1)`%) y `{python} format_number(total_buildings_medium_hazard)` en zonas de peligro medio (`{python} format_number(round(total_buildings_medium_hazard / total_buildings_exposed * 100, 1), 1)`%). La exposici칩n se concentra principalmente en los alrededores del casco urbano de La Plata, con una distribuci칩n caracter칤stica donde pocos barrios presentan exposici칩n muy alta, seguidos por un grupo de exposici칩n media. `{python} top_5_barrios_alta.iloc[0]['nombre_barrio']` lidera con `{python} format_number(int(top_5_barrios_alta.iloc[0]['edificios_expuestos']))` edificios expuestas a peligro alto (`{python} format_number(float(top_5_barrios_alta.iloc[0]['porcentaje']), 1)`% del barrio), seguido por `{python} top_5_barrios_alta.iloc[1]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[1]['edificios_expuestos']))` edificios (`{python} format_number(float(top_5_barrios_alta.iloc[1]['porcentaje']), 1)`%), `{python} top_5_barrios_alta.iloc[2]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[2]['edificios_expuestos']))` (`{python} format_number(float(top_5_barrios_alta.iloc[2]['porcentaje']), 1)`%), `{python} top_5_barrios_alta.iloc[3]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[3]['edificios_expuestos']))` (`{python} format_number(float(top_5_barrios_alta.iloc[3]['porcentaje']), 1)`%), y `{python} top_5_barrios_alta.iloc[4]['nombre_barrio']` con `{python} format_number(int(top_5_barrios_alta.iloc[4]['edificios_expuestos']))` edificios (`{python} format_number(float(top_5_barrios_alta.iloc[4]['porcentaje']), 1)`%). A nivel de cuencas hidrogr치ficas, `{python} top_5_cuencas.iloc[0]['Cuenca']` concentra la mayor exposici칩n con `{python} format_number(int(top_5_cuencas.iloc[0]['edificios_expuestos_total']))` edificios expuestas (`{python} format_number(round(top_5_cuencas.iloc[0]['edificios_expuestos_total'] / top_5_cuencas.iloc[0]['total_edificios'] * 100, 1), 1)`% del total de edificios en asentamientos informales de la cuenca; `{python} format_number(int(top_5_cuencas.iloc[0]['edificios_expuestos_alta']))` a peligro alto y `{python} format_number(int(top_5_cuencas.iloc[0]['edificios_expuestos_media']))` a peligro medio), principalmente debido a la presencia de `{python} top_5_barrios_alta.iloc[0]['nombre_barrio']` y otros asentamientos importantes. Le sigue `{python} top_5_cuencas.iloc[1]['Cuenca']` con `{python} format_number(int(top_5_cuencas.iloc[1]['edificios_expuestos_total']))` edificios (`{python} format_number(round(top_5_cuencas.iloc[1]['edificios_expuestos_total'] / top_5_cuencas.iloc[1]['total_edificios'] * 100, 1), 1)`% del total; `{python} format_number(int(top_5_cuencas.iloc[1]['edificios_expuestos_alta']))` alta, `{python} format_number(int(top_5_cuencas.iloc[1]['edificios_expuestos_media']))` media) y `{python} top_5_cuencas.iloc[2]['Cuenca']` con `{python} format_number(int(top_5_cuencas.iloc[2]['edificios_expuestos_total']))` edificios (`{python} format_number(round(top_5_cuencas.iloc[2]['edificios_expuestos_total'] / top_5_cuencas.iloc[2]['total_edificios'] * 100, 1), 1)`% del total; `{python} format_number(int(top_5_cuencas.iloc[2]['edificios_expuestos_alta']))` alta, `{python} format_number(int(top_5_cuencas.iloc[2]['edificios_expuestos_media']))` media). 

Adem치s, el an치lisis comparativo de tasas de exposici칩n de edificios para la Cuenca Maldonado bajo diferentes per칤odos de retorno, incluyendo la precipitaci칩n m치xima probable (PMP) utilizada en el resto del estudio versus per칤odos de retorno de 100 a침os y 25 a침os, revela que la elecci칩n del per칤odo de retorno genera diferencias significativas en las tasas de exposici칩n. Encontramos que bajo la PMP se exponen 칩rdenes de magnitud m치s edificios que bajo los per칤odos de retorno de 25 y 100 a침os, lo cual es fundamental considerar al determinar qu칠 치reas priorizar para la reubicaci칩n de residentes en asentamientos informales.

La comparaci칩n metodol칩gica entre interpolaci칩n areal y an치lisis a nivel de edificio demuestra que nuestro enfoque basado en edificios individuales retorna un mayor n칰mero total de poblaci칩n expuesta (debido a la identificaci칩n de aproximadamente el doble de edificios que los datos oficiales del RENABAP) pero una menor proporci칩n de exposici칩n relativa (`{python} format_number(percentage_exposed, 1)`% vs `{python} format_number(round((barrios_pct_peligro_alta + barrios_pct_peligro_media), 1), 1)`%), lo que demuestra que la interpolaci칩n areal sobrestima la exposici칩n relativa al asumir una distribuci칩n uniforme de la poblaci칩n. Nuestro m칠todo es m치s confiable porque refleja la distribuci칩n real de los edificios en lugar de asumir distribuci칩n uniforme, proporcionando evaluaciones de riesgo m치s precisas.

Este enfoque basado en edificios no solo proporciona estimaciones m치s precisas y actualizadas que los m칠todos tradicionales de interpolaci칩n areal, sino que tambi칠n demuestra la necesidad urgente de actualizar los registros oficiales de asentamientos informales. Los datos globales de huellas de edificios representan una herramienta esencial para comprender la verdadera magnitud de la poblaci칩n en riesgo y para la planificaci칩n efectiva de pol칤ticas de reducci칩n de riesgo de inundaci칩n.
