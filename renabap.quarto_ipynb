{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RENABAP\n",
        "\n",
        "## Objectivos\n",
        "\n",
        "## Fuentes de datos\n",
        "\n",
        "### Datos\n",
        "\n",
        "#### RENABAP\n",
        "\n",
        "#### Censo Argentino\n",
        "\n",
        "#### GHSL\n",
        "\n",
        "#### Google-Microsoft Open Buildings\n",
        "\n",
        "### Metodología\n",
        "\n",
        "#### Interpolación por area\n",
        "\n",
        "#### Mapeo dasymetrico\n",
        "\n",
        "## Metodología y procesamiento\n"
      ],
      "id": "c685b071"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "import boto3\n",
        "import duckdb\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import contextily as ctx\n",
        "\n",
        "import numpy as np\n",
        "import s2sphere\n",
        "from botocore.config import Config\n",
        "from rasterstats import zonal_stats\n",
        "\n",
        "from io import BytesIO\n",
        "from owslib.wfs import WebFeatureService\n",
        "from shapely.geometry import box\n",
        "\n",
        "\n",
        "USE_CRS = \"EPSG:5349\"\n",
        "\n",
        "# Generic mapping functions\n",
        "def setup_base_map(figsize=(12, 10), bounds=None, padding_x=500, padding_y=500):\n",
        "    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n",
        "    if bounds is None:\n",
        "        bounds = renabap_pba_intersect.total_bounds\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.set_xlim(bounds[0] - padding_x, bounds[2] + padding_x)\n",
        "    ax.set_ylim(bounds[1] - padding_y, bounds[3] + padding_y)\n",
        "    return fig, ax\n",
        "\n",
        "def add_basemap(ax, zoom=13):\n",
        "    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n",
        "    # Convert to Web Mercator for basemap\n",
        "    ax_web_mercator = ax.figure.add_axes(ax.get_position(), projection='EPSG:3857')\n",
        "    ax_web_mercator.set_xlim(ax.get_xlim())\n",
        "    ax_web_mercator.set_ylim(ax.get_ylim())\n",
        "    \n",
        "    ctx.add_basemap(\n",
        "        ax_web_mercator,\n",
        "        source=ctx.providers.CartoDB.PositronNoLabels,\n",
        "        zorder=0,\n",
        "        zoom=zoom,\n",
        "    )\n",
        "    \n",
        "    # Copy basemap to original axes\n",
        "    ax.imshow(ax_web_mercator.get_images()[0], extent=ax.get_xlim() + ax.get_ylim(), zorder=0)\n",
        "    ax.figure.delaxes(ax_web_mercator)\n",
        "    \n",
        "    return ax\n",
        "\n",
        "def add_north_arrow(ax, x=0.95, y=0.95, width=0.05, height=0.05):\n",
        "    \"\"\"Add a north arrow to the map.\"\"\"\n",
        "    # Convert to axes coordinates\n",
        "    trans = ax.transAxes\n",
        "    \n",
        "    # North arrow\n",
        "    arrow_x = [x, x, x + width/2, x, x - width/2]\n",
        "    arrow_y = [y - height, y, y + height, y, y + height]\n",
        "    \n",
        "    ax.fill(arrow_x, arrow_y, transform=trans, color='black', zorder=1000)\n",
        "    ax.text(x, y + height + 0.02, 'N', transform=trans, \n",
        "            ha='center', va='bottom', fontweight='bold', fontsize=12, zorder=1000)\n",
        "\n",
        "def create_consistent_map(title, bounds=None):\n",
        "    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n",
        "    fig, ax = setup_base_map(bounds=bounds)\n",
        "    \n",
        "    # Add basemap\n",
        "    add_basemap(ax)\n",
        "    \n",
        "    # Add north arrow\n",
        "    add_north_arrow(ax)\n",
        "    \n",
        "    # Set title\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
        "    \n",
        "    # Remove axes\n",
        "    ax.set_axis_off()\n",
        "    \n",
        "    return fig, ax\n",
        "\n",
        "### import data\n",
        "\n",
        "response = requests.get(\n",
        "    \"https://www.argentina.gob.ar/sites/default/files/renabap-2023-12-06.geojson\"\n",
        ")\n",
        "renabap = gpd.read_file(StringIO(response.text))\n",
        "renabap_pba = renabap[renabap[\"provincia\"] == \"Buenos Aires\"]\n",
        "renabap_pba = renabap_pba.to_crs(USE_CRS)\n",
        "\n",
        "peligro_path = \"/home/nissim/Documents/dev/fulbright/ciut-riesgo/notebooks/data/la_plata_pelig_2023_datos_originales.geojson\"\n",
        "peligro = gpd.read_file(peligro_path)\n",
        "peligro = peligro.to_crs(USE_CRS)\n",
        "\n",
        "peligro_bounds = peligro.total_bounds\n",
        "peligro_bbox = box(*peligro_bounds)\n",
        "\n",
        "renabap_pba_intersect = renabap_pba[\n",
        "    renabap_pba.geometry.intersects(peligro_bbox)\n",
        "].copy()\n",
        "\n",
        "\n",
        "\n",
        "def wfs_to_gdf(wfs_url: str, layer_name: str, srs: str = \"EPSG:4326\") -> gpd.GeoDataFrame:\n",
        "    \"\"\"\n",
        "    Descarga una capa WFS y la devuelve como GeoDataFrame.\n",
        "    \n",
        "    Args:\n",
        "        wfs_url (str): URL del servicio WFS.\n",
        "        layer_name (str): Nombre de la capa (typename).\n",
        "        srs (str): Código EPSG del sistema de referencia de coordenadas.\n",
        "    \n",
        "    Returns:\n",
        "        gpd.GeoDataFrame: Capa descargada como GeoDataFrame.\n",
        "    \"\"\"\n",
        "    wfs = WebFeatureService(url=wfs_url, version=\"2.0.0\")\n",
        "    response = wfs.getfeature(typename=layer_name, srsname=srs)\n",
        "    gdf = gpd.read_file(BytesIO(response.read()))\n",
        "    return gdf\n",
        "\n",
        "partidos = wfs_to_gdf(\n",
        "     wfs_url=\"https://geo.arba.gov.ar/geoserver/idera/wfs\",\n",
        "     layer_name=\"idera:Departamento\",\n",
        "     srs=\"EPSG:5347\"\n",
        ")\n",
        "\n",
        "partidos = partidos.to_crs(USE_CRS)\n",
        "\n",
        "la_plata = partidos[partidos['fna'] == 'Partido de La Plata']\n",
        "\n",
        "# Get common bounds for all maps\n",
        "common_bounds = renabap_pba_intersect.total_bounds\n",
        "\n",
        "### Mapa 1: Asentamientos RENABAP en La Plata\n",
        "\n",
        "```{python}\n",
        "# Map 1: RENABAP settlements overlaid on La Plata partido\n",
        "fig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", common_bounds)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "255e94ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapa 2: Datos de población GHSL\n"
      ],
      "id": "b55ba2b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Map 2: GHSL population data\n",
        "fig2, ax2 = create_consistent_map(\"Datos de población GHSL\", common_bounds)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "9b985b44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Map 1: RENABAP settlements overlaid on La Plata partido\n",
        "fig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", common_bounds)\n",
        "\n",
        "# Add La Plata partido boundary\n",
        "la_plata.boundary.plot(ax=ax1, color='darkblue', linewidth=2, zorder=5, label='Partido de La Plata')\n",
        "\n",
        "# Add RENABAP settlements as outlines\n",
        "renabap_pba_intersect.boundary.plot(ax=ax1, color='red', linewidth=1, zorder=6, label='Asentamientos RENABAP')\n",
        "\n",
        "ax1.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "406d8c11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpolación por area\n"
      ],
      "id": "5381f082"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensure both GeoDataFrames have the same CRS\n",
        "if renabap_pba_intersect.crs != peligro.crs:\n",
        "    peligro = peligro.to_crs(renabap_pba_intersect.crs)\n",
        "\n",
        "# Get unique hazard levels\n",
        "hazard_levels = peligro[\"PELIGROSID\"].unique()\n",
        "\n",
        "# Initialize result columns\n",
        "renabap_with_porciones = renabap_pba_intersect.copy()\n",
        "for level in hazard_levels:\n",
        "    renabap_with_porciones[f\"porcion_{level}\"] = 0.0\n",
        "\n",
        "# Calculate total area of each barrio\n",
        "renabap_with_porciones['total_area'] = renabap_with_porciones.geometry.area\n",
        "\n",
        "# For each barrio, calculate intersection with each hazard level\n",
        "for idx, barrio in renabap_with_porciones.iterrows():\n",
        "    barrio_geom = barrio.geometry\n",
        "    barrio_total_area = barrio_geom.area\n",
        "    \n",
        "    if barrio_total_area == 0:\n",
        "        continue\n",
        "        \n",
        "    for level in hazard_levels:\n",
        "        hazard_subset = peligro[peligro[\"PELIGROSID\"] == level]\n",
        "        \n",
        "        if hazard_subset.empty:\n",
        "            continue\n",
        "        \n",
        "        # Calculate intersection area\n",
        "        intersection_area = 0\n",
        "        for _, hazard_row in hazard_subset.iterrows():\n",
        "            try:\n",
        "                intersection = barrio_geom.intersection(hazard_row.geometry)\n",
        "                if not intersection.is_empty:\n",
        "                    intersection_area += intersection.area\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating intersection for {barrio.get('nombre_barrio', idx)}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Calculate proportion\n",
        "        proportion = intersection_area / barrio_total_area if barrio_total_area > 0 else 0\n",
        "        renabap_with_porciones.at[idx, f\"porcion_{level}\"] = proportion\n",
        "\n",
        "# Create tidy format dataframe\n",
        "renabap_tidy = []\n",
        "\n",
        "for idx, row in renabap_with_porciones.iterrows():\n",
        "    for level in hazard_levels:\n",
        "        familias_expuestas = row[f\"porcion_{level}\"] * row[\"familias_aproximadas\"]\n",
        "        \n",
        "        renabap_tidy.append({\n",
        "            \"id_renabap\": row[\"id_renabap\"],\n",
        "            \"nombre_barrio\": row[\"nombre_barrio\"],\n",
        "            \"peligrosidad\": level,\n",
        "            \"fam_expuestas_areal\": familias_expuestas\n",
        "        })\n",
        "\n",
        "renabap_tidy = pd.DataFrame(renabap_tidy)"
      ],
      "id": "eee23eb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cuenta de edificios\n"
      ],
      "id": "5c220da6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "def fetch_buildings(geodataframe, temp_file=\"buildings_filtered.parquet\"):\n",
        "    \"\"\"Fetch building data for a given GeoDataFrame region\"\"\"\n",
        "\n",
        "    # Get S2 cell and bounds\n",
        "    center = geodataframe.to_crs(\"epsg:3857\").union_all().centroid\n",
        "    center_wgs84 = (\n",
        "        gpd.GeoDataFrame(geometry=[center], crs=\"EPSG:3857\")\n",
        "        .to_crs(epsg=4326)\n",
        "        .geometry.iloc[0]\n",
        "    )\n",
        "    cell = s2sphere.CellId.from_lat_lng(\n",
        "        s2sphere.LatLng.from_degrees(center_wgs84.y, center_wgs84.x)\n",
        "    ).parent(10)\n",
        "    bounds = geodataframe.to_crs(\"epsg:4326\").total_bounds\n",
        "\n",
        "    # Find matching S2 partition\n",
        "    s3 = boto3.client(\n",
        "        \"s3\",\n",
        "        endpoint_url=\"https://data.source.coop\",\n",
        "        aws_access_key_id=\"\",\n",
        "        aws_secret_access_key=\"\",\n",
        "        config=Config(s3={\"addressing_style\": \"path\"}),\n",
        "    )\n",
        "\n",
        "    partitions = {\n",
        "        obj[\"Key\"].split(\"/\")[-1].replace(\".parquet\", \"\")\n",
        "        for obj in s3.list_objects_v2(\n",
        "            Bucket=\"vida\",\n",
        "            Prefix=\"google-microsoft-open-buildings/geoparquet/by_country_s2/country_iso=ARG/\",\n",
        "        ).get(\"Contents\", [])\n",
        "    }\n",
        "\n",
        "    parent_id = next(\n",
        "        str(cell.parent(level).id())\n",
        "        for level in range(10, 0, -1)\n",
        "        if str(cell.parent(level).id()) in partitions\n",
        "    )\n",
        "\n",
        "    # Setup DuckDB and query\n",
        "    con = duckdb.connect()\n",
        "    for cmd in [\n",
        "        \"INSTALL spatial\",\n",
        "        \"LOAD spatial\",\n",
        "        \"INSTALL httpfs\",\n",
        "        \"LOAD httpfs\",\n",
        "        \"SET s3_region='us-east-1'\",\n",
        "        \"SET s3_endpoint='data.source.coop'\",\n",
        "        \"SET s3_use_ssl=true\",\n",
        "        \"SET s3_url_style='path'\",\n",
        "    ]:\n",
        "        con.execute(cmd)\n",
        "\n",
        "    # Export and read back\n",
        "    query = f\"\"\"\n",
        "    COPY (SELECT * FROM 's3://vida/google-microsoft-open-buildings/geoparquet/by_country_s2/country_iso=ARG/{parent_id}.parquet'\n",
        "          WHERE bbox.xmax >= {bounds[0]} AND bbox.xmin <= {bounds[2]} AND\n",
        "                bbox.ymax >= {bounds[1]} AND bbox.ymin <= {bounds[3]}\n",
        "    ) TO '{temp_file}' (FORMAT PARQUET);\n",
        "    \"\"\"\n",
        "\n",
        "    con.execute(query)\n",
        "    df = pd.read_parquet(temp_file)\n",
        "    df[\"geometry\"] = gpd.GeoSeries.from_wkb(df[\"geometry\"])\n",
        "\n",
        "    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "\n",
        "\n",
        "# Usage:\n",
        "buildings = fetch_buildings(renabap_pba_intersect)"
      ],
      "id": "eae934b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapeo dasymetrico con datos GHSL\n"
      ],
      "id": "3f90ad88"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import rioxarray\n",
        "from shapely.geometry import box\n",
        "\n",
        "# Load GHSL data with dask chunking for memory efficiency\n",
        "ghsl = rioxarray.open_rasterio(\n",
        "    \"/home/nissim/Downloads/spatial/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13/GHS_POP_E2025_GLOBE_R2023A_54009_100_V1_0_R14_C13.tif\",\n",
        "    chunks={\"x\": 1024, \"y\": 1024},  # Adjust chunk size based on your memory constraints\n",
        ")\n",
        "\n",
        "# Reproject to your target CRS with streaming\n",
        "ghsl = ghsl.rio.reproject(dst_crs=USE_CRS)\n",
        "\n",
        "# Clip to renabap_pba_intersect bounding box using streaming\n",
        "bounding_box = box(\n",
        "    *renabap_pba_intersect.total_bounds\n",
        ")  # Create a box from the bounding box coordinates\n",
        "\n",
        "ghsl_clipped = ghsl.rio.clip(\n",
        "    [bounding_box],  # Use the bounding box as a geometry (wrapped in a list)\n",
        "    from_disk=True,  # Process from disk to avoid loading entire dataset into memory\n",
        ")\n",
        "\n",
        "\n",
        "import rasterstats\n",
        "\n",
        "# Step 1: Calculate the total GHSL population per barrio popular using zonal statistics\n",
        "\n",
        "# Convert to the format expected by rasterstats\n",
        "geometries = [geom for geom in renabap_pba_intersect.geometry]\n",
        "\n",
        "# Use rasterstats for vectorized zonal statistics\n",
        "stats = rasterstats.zonal_stats(\n",
        "    geometries,\n",
        "    ghsl_clipped.values[0],  # rasterstats expects 2D array\n",
        "    affine=ghsl_clipped.rio.transform(),\n",
        "    stats=[\"sum\"],\n",
        "    nodata=ghsl_clipped.rio.nodata,\n",
        ")\n",
        "\n",
        "# Extract the sum values\n",
        "ghsl_totals = [stat[\"sum\"] if stat[\"sum\"] is not None else 0 for stat in stats]\n",
        "\n",
        "# Add the GHSL population estimates as a new column\n",
        "renabap_pba_intersect[\"ghsl_pop_est\"] = ghsl_totals\n",
        "\n",
        "from rasterio.features import rasterize\n",
        "import numpy as np\n",
        "\n",
        "# Get the reference raster properties from GHSL data\n",
        "reference_raster = ghsl_clipped\n",
        "reference_transform = reference_raster.rio.transform()\n",
        "reference_crs = reference_raster.rio.crs\n",
        "reference_shape = reference_raster.shape[1:]  # Get 2D shape (height, width)\n",
        "\n",
        "\n",
        "# Prepare geometries and values for rasterization\n",
        "geometries_ghsl = [\n",
        "    (geom, value)\n",
        "    for geom, value in zip(\n",
        "        renabap_pba_intersect.geometry, renabap_pba_intersect[\"ghsl_pop_est\"]\n",
        "    )\n",
        "]\n",
        "geometries_familias = [\n",
        "    (geom, value)\n",
        "    for geom, value in zip(\n",
        "        renabap_pba_intersect.geometry, renabap_pba_intersect[\"familias_aproximadas\"]\n",
        "    )\n",
        "]\n",
        "\n",
        "# Create GHSL population raster\n",
        "ghsl_pop_raster = rasterize(\n",
        "    geometries_ghsl,\n",
        "    out_shape=reference_shape,\n",
        "    transform=reference_transform,\n",
        "    fill=0,\n",
        "    dtype=np.float32,\n",
        "    all_touched=False,\n",
        ")\n",
        "\n",
        "# Create familias aproximadas raster\n",
        "familias_raster = rasterize(\n",
        "    geometries_familias,\n",
        "    out_shape=reference_shape,\n",
        "    transform=reference_transform,\n",
        "    fill=0,\n",
        "    dtype=np.float32,\n",
        "    all_touched=False,\n",
        ")\n",
        "\n",
        "\n",
        "# Step 1: Divide original GHSL by the barrio-level GHSL to get fractional population\n",
        "# Use masking to avoid division on invalid cells\n",
        "mask = (ghsl_clipped.values[0] != -200) & (ghsl_pop_raster > 0.1)\n",
        "ghsl_fractional = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\n",
        "ghsl_fractional[mask] = ghsl_clipped.values[0][mask] / ghsl_pop_raster[mask]\n",
        "\n",
        "# Step 2: Multiply fractional population by familias aproximadas to get downscaled data\n",
        "mask2 = (ghsl_fractional != -200) & (familias_raster > 0)\n",
        "familias_downscaled = np.full_like(ghsl_clipped.values[0], -200, dtype=np.float64)\n",
        "familias_downscaled[mask2] = ghsl_fractional[mask2] * familias_raster[mask2]\n",
        "\n",
        "# Verify the results - exclude -200 from range calculations\n",
        "ghsl_valid = ghsl_clipped.values[0] != -200\n",
        "fractional_valid = ghsl_fractional != -200\n",
        "downscaled_valid = familias_downscaled != -200\n",
        "\n",
        "\n",
        "\n",
        "# Check that the sum of downscaled familias equals the original familias aproximadas\n",
        "total_original_familias = renabap_pba_intersect[\"familias_aproximadas\"].sum()\n",
        "total_downscaled_familias = np.sum(familias_downscaled[downscaled_valid])\n",
        "\n",
        "# Intersect settlements with hazard zones\n",
        "settlement_hazard = gpd.overlay(renabap_pba_intersect, peligro, how=\"intersection\")\n",
        "\n",
        "# Create GHSL tidy dataframe with matching structure\n",
        "ghsl_tidy = []\n",
        "\n",
        "for idx, row in settlement_hazard.iterrows():\n",
        "    stats = zonal_stats(\n",
        "        [row.geometry],\n",
        "        familias_downscaled,  # your numpy array\n",
        "        affine=reference_transform,  # get transform from your xarray\n",
        "        stats=[\"sum\"],\n",
        "        nodata=-200,  # use your actual nodata value\n",
        "    )[0]\n",
        "\n",
        "    ghsl_tidy.append(\n",
        "        {\n",
        "            \"id_renabap\": row[\"id_renabap\"],\n",
        "            \"peligrosidad\": row[\"PELIGROSID\"],\n",
        "            \"fam_expuestas_ghsl\": stats[\"sum\"] if stats[\"sum\"] is not None else 0,\n",
        "        }\n",
        "    )\n",
        "\n",
        "ghsl_tidy = pd.DataFrame(ghsl_tidy)\n",
        "\n",
        "### Mapa 3: Huellas de edificios\n",
        "\n",
        "```{python}\n",
        "# Map 3: Building footprints\n",
        "fig3, ax3 = create_consistent_map(\"Huellas de edificios\", common_bounds)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "a1c77200",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Map 2: GHSL population data\n",
        "fig2, ax2 = create_consistent_map(\"Datos de población GHSL\", common_bounds)\n",
        "\n",
        "# Plot GHSL data as raster\n",
        "ghsl_clipped.plot.imshow(ax=ax2, cmap='YlOrRd', zorder=5, add_colorbar=True, \n",
        "                         cbar_kwargs={'label': 'Población estimada'})\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "a584cf70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapeo dasymetrico con datos de edificios\n"
      ],
      "id": "4c9a5be4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reproject buildings to match the analysis CRS\n",
        "buildings_proj = buildings.to_crs(USE_CRS)\n",
        "\n",
        "# Step 1: Calculate buildings per settlement-hazard intersection\n",
        "buildings_hazard = gpd.overlay(buildings_proj, settlement_hazard, how=\"intersection\")\n",
        "\n",
        "# Count buildings per settlement-hazard combination\n",
        "buildings_per_hazard = (\n",
        "    buildings_hazard.groupby([\"id_renabap\", \"PELIGROSID\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"buildings_count\")\n",
        ")\n",
        "\n",
        "# Step 2: Calculate total buildings per settlement (barrio popular)\n",
        "buildings_settlement = gpd.overlay(\n",
        "    buildings_proj, renabap_pba_intersect, how=\"intersection\"\n",
        ")\n",
        "total_buildings_per_settlement = (\n",
        "    buildings_settlement.groupby(\"id_renabap\")\n",
        "    .size()\n",
        "    .reset_index(name=\"total_buildings\")\n",
        ")\n",
        "\n",
        "# Step 3: Merge and calculate ratios\n",
        "hazard_ratios = buildings_per_hazard.merge(\n",
        "    total_buildings_per_settlement, on=\"id_renabap\", how=\"left\"\n",
        ")\n",
        "hazard_ratios[\"building_ratio\"] = (\n",
        "    hazard_ratios[\"buildings_count\"] / hazard_ratios[\"total_buildings\"]\n",
        ")\n",
        "\n",
        "# Step 4: Get total population per settlement and apply ratios\n",
        "settlement_population = renabap_pba_intersect[\n",
        "    [\"id_renabap\", \"familias_aproximadas\"]\n",
        "].copy()\n",
        "\n",
        "# Merge with ratios and calculate population estimates\n",
        "population_estimates = hazard_ratios.merge(\n",
        "    settlement_population, on=\"id_renabap\", how=\"left\"\n",
        ")\n",
        "population_estimates[\"estimated_population_hazard\"] = (\n",
        "    population_estimates[\"building_ratio\"]\n",
        "    * population_estimates[\"familias_aproximadas\"]\n",
        ")\n",
        "\n",
        "# Step 5: Create final results with totals\n",
        "final_results = population_estimates[\n",
        "    [\"id_renabap\", \"PELIGROSID\", \"estimated_population_hazard\"]\n",
        "].copy()\n",
        "\n",
        "# Add total population rows (no hazard breakdown)\n",
        "total_pop_rows = settlement_population.copy()\n",
        "total_pop_rows[\"PELIGROSID\"] = \"total\"\n",
        "total_pop_rows[\"estimated_population_hazard\"] = total_pop_rows[\"familias_aproximadas\"]\n",
        "\n",
        "# Combine\n",
        "final_results = pd.concat(\n",
        "    [\n",
        "        final_results,\n",
        "        total_pop_rows[[\"id_renabap\", \"PELIGROSID\", \"estimated_population_hazard\"]],\n",
        "    ],\n",
        "    ignore_index=True,\n",
        ")\n",
        "\n",
        "# Create buildings tidy dataframe with matching structure\n",
        "buildings_tidy = final_results[\n",
        "    [\"id_renabap\", \"PELIGROSID\", \"estimated_population_hazard\"]\n",
        "].copy()\n",
        "\n",
        "# Rename columns to match the structure\n",
        "buildings_tidy = buildings_tidy.rename(\n",
        "    columns={\n",
        "        \"PELIGROSID\": \"peligrosidad\",\n",
        "        \"estimated_population_hazard\": \"fam_expuestas_edificios\",\n",
        "    }\n",
        ")\n",
        "\n",
        "# Filter out the 'total' rows since we only want hazard-specific data\n",
        "buildings_tidy = buildings_tidy[buildings_tidy[\"peligrosidad\"] != \"total\"].copy()\n",
        "\n",
        "### Mapa 3: Huellas de edificios\n",
        "\n",
        "```{python}\n",
        "# Map 3: Building footprints\n",
        "fig3, ax3 = create_consistent_map(\"Huellas de edificios\", common_bounds)\n",
        "\n",
        "# Plot building footprints\n",
        "buildings_proj.plot(ax=ax3, color='darkgreen', alpha=0.6, markersize=1, zorder=5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "af1b97c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def setup_base_map(figsize=(12, 10), bounds=None, padding_x=500, padding_y=500):\n",
        "    \"\"\"Create figure and set up basic map boundaries with padding.\"\"\"\n",
        "    if bounds is None:\n",
        "        bounds = renabap_pba_intersect.total_bounds\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.set_xlim(bounds[0] - padding_x, bounds[2] + padding_x)\n",
        "    ax.set_ylim(bounds[1] - padding_y, bounds[3] + padding_y)\n",
        "    return fig, ax\n",
        "\n",
        "def add_basemap(ax, zoom=13):\n",
        "    \"\"\"Add CartoDB basemap to the axes.\"\"\"\n",
        "    # Convert to Web Mercator for basemap\n",
        "    ax_web_mercator = ax.figure.add_axes(ax.get_position(), projection='EPSG:3857')\n",
        "    ax_web_mercator.set_xlim(ax.get_xlim())\n",
        "    ax_web_mercator.set_ylim(ax.get_ylim())\n",
        "    \n",
        "    ctx.add_basemap(\n",
        "        ax_web_mercator,\n",
        "        source=ctx.providers.CartoDB.PositronNoLabels,\n",
        "        zorder=0,\n",
        "        zoom=zoom,\n",
        "    )\n",
        "    \n",
        "    # Copy basemap to original axes\n",
        "    ax.imshow(ax_web_mercator.get_images()[0], extent=ax.get_xlim() + ax.get_ylim(), zorder=0)\n",
        "    ax.figure.delaxes(ax_web_mercator)\n",
        "    \n",
        "    return ax\n",
        "\n",
        "def add_north_arrow(ax, x=0.95, y=0.95, width=0.05, height=0.05):\n",
        "    \"\"\"Add a north arrow to the map.\"\"\"\n",
        "    # Convert to axes coordinates\n",
        "    trans = ax.transAxes\n",
        "    \n",
        "    # North arrow\n",
        "    arrow_x = [x, x, x + width/2, x, x - width/2]\n",
        "    arrow_y = [y - height, y, y + height, y, y + height]\n",
        "    \n",
        "    ax.fill(arrow_x, arrow_y, transform=trans, color='black', zorder=1000)\n",
        "    ax.text(x, y + height + 0.02, 'N', transform=trans, \n",
        "            ha='center', va='bottom', fontweight='bold', fontsize=12, zorder=1000)\n",
        "\n",
        "def create_consistent_map(title, bounds=None):\n",
        "    \"\"\"Create a map with consistent styling and basemap.\"\"\"\n",
        "    fig, ax = setup_base_map(bounds=bounds)\n",
        "    \n",
        "    # Add basemap\n",
        "    add_basemap(ax)\n",
        "    \n",
        "    # Add north arrow\n",
        "    add_north_arrow(ax)\n",
        "    \n",
        "    # Set title\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
        "    \n",
        "    # Remove axes\n",
        "    ax.set_axis_off()\n",
        "    \n",
        "    return fig, ax\n",
        "\n",
        "# Get common bounds for all maps\n",
        "common_bounds = renabap_pba_intersect.total_bounds\n",
        "\n",
        "# Map 1: RENABAP settlements overlaid on La Plata partido\n",
        "fig1, ax1 = create_consistent_map(\"Asentamientos RENABAP en La Plata\", common_bounds)\n",
        "\n",
        "# Add La Plata partido boundary\n",
        "la_plata.boundary.plot(ax=ax1, color='darkblue', linewidth=2, zorder=5, label='Partido de La Plata')\n",
        "\n",
        "# Add RENABAP settlements as outlines\n",
        "renabap_pba_intersect.boundary.plot(ax=ax1, color='red', linewidth=1, zorder=6, label='Asentamientos RENABAP')\n",
        "\n",
        "ax1.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Map 2: GHSL population data\n",
        "fig2, ax2 = create_consistent_map(\"Datos de población GHSL\", common_bounds)\n",
        "\n",
        "# Plot GHSL data as raster\n",
        "ghsl_clipped.plot.imshow(ax=ax2, cmap='YlOrRd', zorder=5, add_colorbar=True, \n",
        "                         cbar_kwargs={'label': 'Población estimada'})\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Map 3: Building footprints\n",
        "fig3, ax3 = create_consistent_map(\"Huellas de edificios\", common_bounds)\n",
        "\n",
        "# Plot building footprints\n",
        "buildings_proj.plot(ax=ax3, color='darkgreen', alpha=0.6, markersize=1, zorder=5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Map 4: Barrios por población expuesta estimada\n",
        "fig4, ax4 = create_consistent_map(\"Barrios por población expuesta estimada\", common_bounds)\n",
        "\n",
        "# Calculate total exposure per barrio (using area method as example)\n",
        "barrio_exposure = (\n",
        "    final_tidy[final_tidy[\"metodo\"] == \"area\"]\n",
        "    .groupby(\"id_renabap\")[\"fam_expuestas\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Merge with geometry\n",
        "barrio_exposure_map = renabap_pba_intersect.merge(\n",
        "    barrio_exposure, on=\"id_renabap\", how=\"left\"\n",
        ")\n",
        "\n",
        "# Plot choropleth\n",
        "barrio_exposure_map.plot(\n",
        "    column=\"fam_expuestas\", \n",
        "    ax=ax4, \n",
        "    legend=True, \n",
        "    legend_kwds={'label': 'Familias expuestas'},\n",
        "    cmap='Reds',\n",
        "    zorder=5\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "9973cc5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapa 4: Barrios por población expuesta estimada\n"
      ],
      "id": "edb65bdb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Map 4: Barrios por población expuesta estimada\n",
        "fig4, ax4 = create_consistent_map(\"Barrios por población expuesta estimada\", common_bounds)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "ee92326c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resultados y conclusiones\n"
      ],
      "id": "2cecdd34"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Join all three dataframes by id_renabap and peligrosidad\n",
        "final_df = renabap_tidy.merge(\n",
        "    ghsl_tidy, on=[\"id_renabap\", \"peligrosidad\"], how=\"outer\"\n",
        ")\n",
        "final_df = final_df.merge(\n",
        "    buildings_tidy, on=[\"id_renabap\", \"peligrosidad\"], how=\"outer\"\n",
        ")\n",
        "\n",
        "# Impute 0s for NA values in fam_expuestas columns\n",
        "fam_expuestas_columns = [col for col in final_df.columns if 'fam_expuestas' in col]\n",
        "final_df[fam_expuestas_columns] = final_df[fam_expuestas_columns].fillna(0)\n",
        "\n",
        "# Create long format dataframe with aggregation\n",
        "final_tidy = []\n",
        "\n",
        "# Add renabap data\n",
        "for _, row in renabap_tidy.iterrows():\n",
        "    final_tidy.append(\n",
        "        {\n",
        "            \"id_renabap\": row[\"id_renabap\"],\n",
        "            \"peligrosidad\": row[\"peligrosidad\"],\n",
        "            \"metodo\": \"area\",\n",
        "            \"fam_expuestas\": row[\"fam_expuestas_areal\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Add ghsl data\n",
        "for _, row in ghsl_tidy.iterrows():\n",
        "    final_tidy.append(\n",
        "        {\n",
        "            \"id_renabap\": row[\"id_renabap\"],\n",
        "            \"peligrosidad\": row[\"peligrosidad\"],\n",
        "            \"metodo\": \"ghsl\",\n",
        "            \"fam_expuestas\": row[\"fam_expuestas_ghsl\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Add buildings data\n",
        "for _, row in buildings_tidy.iterrows():\n",
        "    final_tidy.append(\n",
        "        {\n",
        "            \"id_renabap\": row[\"id_renabap\"],\n",
        "            \"peligrosidad\": row[\"peligrosidad\"],\n",
        "            \"metodo\": \"edificios\",\n",
        "            \"fam_expuestas\": row[\"fam_expuestas_edificios\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "final_tidy = pd.DataFrame(final_tidy)\n",
        "\n",
        "# Aggregate to get one observation per barrio per hazard level per method\n",
        "final_tidy = (\n",
        "    final_tidy.groupby([\"id_renabap\", \"peligrosidad\", \"metodo\"])[\"fam_expuestas\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Create complete combination of all barrios, hazard levels, and methods\n",
        "all_barrios = final_tidy[\"id_renabap\"].unique()\n",
        "all_hazard_levels = [\"alta\", \"baja\", \"media\"]\n",
        "all_methods = [\"area\", \"ghsl\", \"edificios\"]\n",
        "\n",
        "complete_combinations = pd.DataFrame([\n",
        "    {\"id_renabap\": barrio, \"peligrosidad\": hazard, \"metodo\": method}\n",
        "    for barrio in all_barrios\n",
        "    for hazard in all_hazard_levels\n",
        "    for method in all_methods\n",
        "])\n",
        "\n",
        "# Merge with actual data and fill missing values with 0\n",
        "final_tidy = complete_combinations.merge(\n",
        "    final_tidy, on=[\"id_renabap\", \"peligrosidad\", \"metodo\"], how=\"left\"\n",
        ")\n",
        "final_tidy[\"fam_expuestas\"] = final_tidy[\"fam_expuestas\"].fillna(0)\n",
        "\n",
        "# Calculate total exposure per hazard level per method\n",
        "summary = (\n",
        "    final_tidy.groupby([\"peligrosidad\", \"metodo\"])[\"fam_expuestas\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        "    .pivot(index=\"peligrosidad\", columns=\"metodo\", values=\"fam_expuestas\")\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter for high exposure (alta peligrosidad)\n",
        "alta_data = final_tidy[final_tidy[\"peligrosidad\"] == \"alta\"].copy()\n",
        "\n",
        "# Calculate total exposure per barrio across all methods\n",
        "total_exposure = (\n",
        "    alta_data.groupby(\"id_renabap\")[\"fam_expuestas\"]\n",
        "    .sum()\n",
        "    .sort_values(ascending=False)\n",
        ")\n",
        "top_25_barrios = total_exposure.head(25).index\n",
        "\n",
        "# Filter data for top 25 barrios\n",
        "top_25_data = alta_data[\n",
        "    alta_data[\"id_renabap\"].isin(top_25_barrios)\n",
        "].copy()\n",
        "\n",
        "# Create range plot showing min, max, and individual points\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Define colors for methods\n",
        "method_colors = {\"area\": \"blue\", \"ghsl\": \"red\", \"edificios\": \"green\"}\n",
        "\n",
        "for i, barrio in enumerate(top_25_barrios):\n",
        "    barrio_data = top_25_data[top_25_data[\"id_renabap\"] == barrio]\n",
        "    if len(barrio_data) > 0:\n",
        "        values = barrio_data[\"fam_expuestas\"].values\n",
        "        min_val = values.min()\n",
        "        max_val = values.max()\n",
        "\n",
        "        # Plot range line\n",
        "        plt.plot([min_val, max_val], [i, i], \"k-\", alpha=0.5, linewidth=2)\n",
        "\n",
        "        # Plot individual points colored by method\n",
        "        for _, row in barrio_data.iterrows():\n",
        "            color = method_colors[row[\"metodo\"]]\n",
        "            plt.plot(row[\"fam_expuestas\"], i, \"o\", color=color, markersize=6, alpha=0.8)\n",
        "\n",
        "plt.yticks(range(len(top_25_barrios)), top_25_barrios)\n",
        "plt.xlabel(\"Familias Expuestas\")\n",
        "plt.ylabel(\"Barrio ID\")\n",
        "plt.title(\"Range of High Exposure Estimates for Top 25 Barrios\", fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add legend\n",
        "legend_elements = [\n",
        "    plt.Line2D(\n",
        "        [0],\n",
        "        [0],\n",
        "        marker=\"o\",\n",
        "        color=\"w\",\n",
        "        markerfacecolor=color,\n",
        "        markersize=8,\n",
        "        label=method,\n",
        "    )\n",
        "    for method, color in method_colors.items()\n",
        "]\n",
        "plt.legend(handles=legend_elements, title=\"Método\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b1e8abf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapa 4: Barrios por población expuesta estimada\n"
      ],
      "id": "195aed2e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Map 4: Barrios por población expuesta estimada\n",
        "fig4, ax4 = create_consistent_map(\"Barrios por población expuesta estimada\", common_bounds)\n",
        "\n",
        "# Calculate total exposure per barrio (using area method as example)\n",
        "barrio_exposure = (\n",
        "    final_tidy[final_tidy[\"metodo\"] == \"area\"]\n",
        "    .groupby(\"id_renabap\")[\"fam_expuestas\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Merge with geometry\n",
        "barrio_exposure_map = renabap_pba_intersect.merge(\n",
        "    barrio_exposure, on=\"id_renabap\", how=\"left\"\n",
        ")\n",
        "\n",
        "# Plot choropleth\n",
        "barrio_exposure_map.plot(\n",
        "    column=\"fam_expuestas\", \n",
        "    ax=ax4, \n",
        "    legend=True, \n",
        "    legend_kwds={'label': 'Familias expuestas'},\n",
        "    cmap='Reds',\n",
        "    zorder=5\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "d8d91da2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Referencias"
      ],
      "id": "a12af482"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/nissim/Documents/dev/fulbright/ciut-riesgo/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}